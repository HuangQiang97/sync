

[toc]

 ### 网络

##### 五层模型

应用层：应用程序之间、报文、HTTP、FTP、DNS。

传输层：终端设备进程之间、端口号分用复用、TCP、UDP。

网络层：主机之间、IP数据报、路由选择、无连接、最大努力交付、独立路由、分级结构（网络号+设备号），根据子网路由、头部检错。ARP地址解析协议（查找下一跳的MAC地址，局域网内广播获取目标IP的MAC）、icmp(ping，连通性检测；traceroute路径获取)、NAT/NAPT

内部路由协议：RIP路由选择协议（相邻路由器交换已知的路由信息：目的地+距离（跳数）+下一跳路由器，跳数最少），OSPF（泛洪广播当前节点与哪些节点直接相连，每个路由器可以拿到完整网络拓扑图，最短路径算法获得路由转发关系，代价最低）

外部路由协议：BGP（自治系统选举发言人与其它自治系统交互）

数据链路层： IP 数据报组装成帧，mac、两个相邻节点间。点对点传输（PPP）、广播（CSMA）

物理层：相邻计算机节点之间、比特流。

复杂的系统需要分层，因为每一层都需要专注于一类事情。各层独立：屏蔽底层实现、透明、实现接口调用。灵活：每一层都可以使用最适合的技术来实现，功能以及暴露的接口的规则没有改变。分解：将复杂问题分解为许多比较小的、界线比较清晰简单的小问题来处理和解决。易于设计，实现和标准化。

##### TCP

面向连接的，单播，双工通信；可靠的（有序不丢不重，确认(ACK)、超时重传、差错控制、流量控制、拥塞控制）；基于字节不保留报文边界。

流量控制：滑动窗口保证接收能及时接收。发送窗口：字节为单位、发送窗口（连续ARQ协议）：已发送但未确认（重传）+可以发送未发送（可用窗口）、后沿：不动+前移，前沿：不动（无确认+接收窗大小不变、有确认+接收窗大小变小）+前移，可用窗口=0时超时（滑动均值）重传，零发送窗口窗口探测报文防死锁，发送窗口=min(接收窗口，拥塞窗口)，接收<拥塞：接收端能力、接收>拥塞：网络拥塞状况；接收窗口：未有序到达（独立路由）+空白，接受缓存=按序到达+接收窗口，及时读取否则接受窗=0；

拥塞控制：防止网络过载、全局过程、无拥塞：增大、拥塞/可能拥塞：减小、慢开始（init=1、报文段确认则加一、传输轮次（窗口发送+确认）后倍增）、拥塞避免（x2，门限、一次往返+1）、快重传（单个数据丢失导致误判超时、超时为拥塞标志（cawd=1,thre=cawd/2、慢开始、通信不通数据、ack无发传输），接收方受到任何数据都立即发送有序ack，3ack时发送端立即发送缺失数据，防止超时 cawd=1）和快恢复（3ack触发、个别丢失、thred=cawd=cawd/2、拥塞避免）；

头部：源端口、目的端口、序列号、确认号、(ACK、SYN、FIN、RST、URG)标志位、校验和，至少20字节大小。

三次握手：双方确认自己与对方的发送与接收是正常的。参数协商：双方知道对方的序列号(seq)同时让对方知道自己已经知道了对方的序列号(ack)。

- 第一次，本机将标识位 SYN 置为 1, seq = x发送给服务端。此时本机状态为**SYN-SENT**
    
- 第二次，服务器收到包之后，将状态切换为**SYN-RECEIVED**，并将标识位 SYN 和 ACK都置为1, seq = y, ack = x + 1, 并发送给客户端。
    
- 第三次，客户端收到包后，将状态切换为**ESTABLISHED**，并将标识位ACK置为1，seq = x + 1, ack = y + 1, 并发送给服务端。服务端收到包之后，也将状态切换为**ESTABLISHED**。
    
- （两次握手：第一次握手报文在连接释放后达到，B回复第二次握手报文后进入连接态，等待接收数据，A由于并未发送请求报文，所以不处理第二次报文，也无数据发送，而B则一直等待数据，三握手下A对第二个报文发送复位报文、B收到复位报文，不建立连接。）
    
    （第三个报文无确认：第三次丢失，A认为建立完成，B三次重发第二次握手报文，在一定时间内收不到第三个报文，不能建立连接，终止半连接状态，重新开始连接。若第三个报文中无数据，并且A在B等待期间发送数据传输报文，由于第三个无数据报文不消耗seq，第四个报文拥有和第三个报文一样的seq和ack，对B来说第四个报文就等价于第三个报文，只是该报文带数据而已，连接建立。）
    
- 标识位ACK置为1 （ACK=1，ack才有意义，连接建立后ACK=1）表示我已确认收到seq为x的包。而SYN（SYN=1表示为连接请求和连接接受报文）表示这是我第一次随机生成seq的序列x，此后我每次发送的包都会在上一次发送的基础增加。
    
- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号（缺少第二个序列号的确认）；
    
- 「四次握手」：三次握手就已经理论上最少可靠连接建立（A发送、B确认、B发送、A确认，其中B确认和B发送可以合并），所以不需要使用更多的通信次数。
    

四次挥手：全双工

1. A发送一个FIN置为1的包， seq = x ，此时A状态为 **FIN_WAIT_1**
    
2. B收到包后，状态切换为**CLOSE_WAIT**发送一个ack = x + 1。A收到包之后状态切换为**FNI_WAIT_2**。半关闭状态，B->A
    
3. B处理完任务后，向A发送一个 FIN包，seq = y; 同时将自己的状态置为**LAST_ACK**
    
4. A收到包后状态切换为**TIME_WAIT**，并向B发送A ack = y + 1，等待2MSL后关闭连接closed态(保证连接的可靠性，确保B收到ACK包，如果B没有收到这个ACK包，将会重发FIN包，A做出响应，若A不等待直接关闭，B将不断超时重发包，无法关闭。2MSL后保证本次连接的所有报文都从网络消失，防止干扰新的连接)。B收到包后连接关闭、closed态。
    

##### 建立连接丢包

1，客户端第一个「SYN」包丢了。

如果客户端第一个「SYN」包丢了，也就是服务端根本就不知道客户端曾经发过包，那么处理流程主要在客户端。在一定时间范围内，只要没有收到应答的「ACK」包，无论是请求包对方没有收到，还是对方的应答包自己没有收到，均认为是丢包了，会触发超时重传机制。所以此时会进入重传「SYN」包，会尝试三次，间隔时间分别是 5.8s、24s、48s。

2，服务端收到「SYN」并回复的「SYN,ACK」包丢了。

站在客户端的角度，会认为是最开始的那个「SYN」丢了，那么就继续重传，见1。

对服务端而言，如果发送的「SYN,ACK」包丢了，在超时时间内没有收到客户端发来的「ACK」包（第三次握手），也会触发重传，此时客户端处于 SYN_RCVD 状态，会依次等待 3s、6s、12s 后，重新发送「SYN,ACK」包。如果这个重试次数内，仍未收到「ACK」应答包，那么服务端会自动关闭这个连接。

3，客户端最后一次回复「SYN,ACK」的「ACK」包丢了。

如果最后一个「ACK」包丢了，服务端因为收不到「ACK」会走重传机制，而客户端此时进入 ESTABLISHED 状态。多数情况下，客户端进入 ESTABLISHED 状态后，则认为连接已建立，会立即发送数据。但是服务端因为没有收到最后一个「ACK」包，依然处于 SYN-RCVD 状态。若第三个报文中无数据，并且A在B等待期间发送数据传输报文，由于第三个无数据报文不消耗seq，第四个报文拥有和第三个报文一样的seq和ack，对B来说第四个报文就等价于第三个报文，只是该报文带数据而已，连接建立。若第三个报文中无数据无法建立连接。

4，客户端故意不发最后一次「SYN」包。

如果客户端是恶意的，在发送「SYN」包后，并收到「SYN,ACK」后就不回复了，那么服务端此时处于一种半连接的状态，虽然服务端会通过 tcp_synack_retries配置重试的次数，不会无限等待下去，但是这也是有一个时间周期的。如果短时间内存在大量的这种恶意连接，对服务端来说压力就会很大，这就是所谓的 SYN FLOOD 攻击。如果不断受到 SYN 攻击，就会导致 SYN 队列（半连接队列）被占满，从而导致无法在建立新的连接，通过计算出一个 `cookie` 值，再以 SYN + ACK 中的「序列号」返回客户端，服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。

##### 断开连接丢包

1. 断开连接的 FIN 包丢了。
    

如果一个包发出去，在一定时间内，只要没有收到对端的「ACK」回复，均认为这个包丢了，会触发超时重传机制。而不会关心到底是自己发的包丢了，还是对方的「ACK」丢了。直到触发重传的次数，直接关闭连接。

2. 服务端第一次回复的 ACK 丢了。
    

此时因为客户端没有收到「ACK」应答，会尝试重传之前的「FIN」请求，服务端收到后，又会立即再重传「ACK」。

而此时服务端已经进入 CLOSED-WAIT 状态，开始做断开连接前的准备工作。当准备好之后，会回复「FIN,ACK」（第三次挥手），第三次挥手拥有和第二次挥手报文相同的ack。只要这个消息没丢，客户端可以凭借「FIN,ACK」包中的响应序号，发送第四次挥手报文，直接从 FIN-WAIT-1 状态，进入 TIME-WAIT 状态，开始长达 2MSL 的等待。

3. 服务端发送的 FIN,ACK 丢了。
    

服务端在超时后会重传，此时客户端处于 FIN-WAIT-2 状态，会一直等待并响应第三次挥手报文；

4. 客户端最后回复的 ACK 丢了。
    

客户端在回复「ACK」后，会进入 TIME-WAIT 状态，开始长达 2MSL 的等待，服务端因为没有收到「ACK」的回复，会重试一段时间，收到客户端重发的第四次挥手报文后断开连接，或者直到服务端重试超时后主动断开。

##### UDP

无连接，一对多，多对多，多对一的方式，不可靠（没有拥塞控制、无流量控制），实时性好，头部开销小；面向报文，发送端无拆分，只是增加一个 UDP 头标识；

头部：源端口、目的端口、长度、检验和，占据8字节。

##### url->页面

- DNS 解析: 域名树(.->…->单台计算机)、递归查询的过程 ，本地域名服务器 -> 向根域名服务器（. ） -> com顶级域名服务器（.com. ）->google.com域名服务器（google.com.） ->… 找到后缓存到本地域名服务器。
    
    缓存机制：浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，域名服务器缓存。
    
    根域名服务器(.)收到请求后->返回这个(.com)顶级DNS服务器的IP->请求者（本地域名服务器）收到这台顶级DNS的服务器IP->向该服务器发起查询->.com服务器就会返回下一级的DNS服务器（google.com）的IP->请求者（本地域名服务器）继续查找，直到服务器找到([www.google.com](www.google.com))的主机。
    
    DNS负载均衡：又叫做DNS重定向，返回一个跟用户最接近的点的IP地址给用户。
    
- TCP 连接：三次握手：请求连接、同意连接、同意连接信号的确认。
    
- 发送 HTTP 请求：HTTPS：HTTP + SSL(or TLS)，非对称加密，对称加密。HTTP请求报文: 请求行（GET index.html HTTP/1.1）, 请求报头（附加信息）和请求正文（POST, PUT等方法需要客户端向服务器传递数据）。
    
- 服务器处理请求并返回 HTTP 报文：http版本，状态码, 响应报头和响应报文。缓存：Last-Modify(响应头) + If-Modified-Since（请求头），时间比对后若未修改返回304状态码，浏览器将从缓存中获取资源。反之返回200和资源内容。
    
- 浏览器解析渲染页面：WebKit渲染，边解析边渲染，复用持久连接（keep-alive）下载资源（图片）。
    
- 连接结束：TCP释放连接四次握手。
    

##### 状态码

- 1xx：指示信息–表示请求已接收，继续处理。
    
- 2xx：成功–表示请求已被成功接收、理解、接受。200=ok，206=Partial Content
    
- 3xx：重定向–告诉浏览器地址已经变了，麻烦使用新的URL再重新发送新请求。（转发是在Web服务器内部完成的，对浏览器来说，它只发出了一个HTTP请求）。301=Moved Permanently，304=Not Modified
    
- 4xx：客户端错误–请求有语法错误或请求无法实现。400=bad request, 401=Unauthorized, 403=Forbidden, 404= Not Found。
    
- 5xx：服务器端错误–服务器未能实现合法的请求, 500=Internal Server Error，501=Not Implemented
    

##### 状态保存

HTTP 无状态协议。

- cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上，用于告知服务端前后两个请求是否来自同一浏览器。本地保存别人可以分析存放在本地的COOKIE并进行COOKIE欺骗。
    
- session 是基于 cookie 实现的一种认证方式，主要作用就是通过服务端记录用户的状态。服务器端接受客户端请求后，建立一个session，并发送一个http响应到客户端，在响应中包含sessionId，客户以cookie的方式保存sessionId，在客户端发起的第二次请求时，浏览器会自动在请求头中带上cookie，服务器根据cookie找到session恢复数据环境。随着用户的增多，服务端压力增大。分布式下拓展性不强，粘性会话 Sticky Session：尽量让同一个用户的请求落到一台机器上。缺点：如果当前机器下线则用户的信息全部丢失。会话复制 Session Replication：将会话信息复制到所有机器上，无论用户请求落到哪台机器上都能取到之前的会话信息。缺点：复制需要成本，冗余过大，难以保证所有机器上会话信息一致。集中会话 Centralized Session：JDBC、Redis等集中保存信息，机器需要信息时到JDBC,Redis中取。
    
    CSRF（Cross-site request forgery）跨站请求伪造：攻击者诱导受害者进入第三方网站，在第三方网站中，向被攻击网站发送跨站请求。利用受害者在被攻击网站已经获取的注册凭证，绕过后台的用户验证，达到冒充用户对被攻击的网站执行某项操作的目的。
    
    受害者登录a.com，并保留了登录凭证（Cookie）->攻击者引诱受害者访问了b.com->b.com 向 a.com 发送了一个请求：a.com/act=xx->浏览器会默认携带a.com的Cookie->a.com接收到请求后，对请求进行验证，并确认是受害者的凭证，误以为是受害者自己发送的请求->a.com以受害者的名义执行了act=xx->攻击完成，攻击者在受害者不知情的情况下，冒充受害者，让a.com执行了自己定义的操作。
    
    解决方法：1，同源检测：CSRF大多来自第三方网站，那么就直接禁止外域（或者不受信任的域名）对我们发起请求。2，CSRF Token：攻击者无法直接窃取到用户的信息（Cookie，Header，网站内容等），仅仅是冒用Cookie中的信息。要求所有的用户请求都携带一个CSRF攻击者无法获取到的Token。服务器通过校验请求是否携带正确的Token，来把正常的请求和攻击的请求区分开，也可以防范CSRF的攻击。
    
- token：类似于无状态的临时的证书签名，由uid+time+sign[+固定参数]组成，服务端验证浏览器携带的用户名和密码，验证通过后生成用户令牌（token）并返回给浏览器，浏览器再次访问时携带token，服务端校验token并返回相关数据。服务端不用存放 token 数据，用解析 token 的计算时间换取 session 的存储空间，减轻服务器存储压力。安全性高，分布式系统下扩展性强。
    
- JWT：全称是JSON Web Token，用于在空间受限环境下安全传递“声明”，JWT跨语言支持、便于传输、易于扩展。JWT分成三部分，头部（header：声明的类型、声明的加密算法），第二部分是载荷（payload：存放有效信息，一般包含签发者、所面向的用户、接受方、过期时间、签发时间以及唯一身份标识，防篡改，不防泄露），第三部分是签名（signature：主要由头部、载荷以及秘钥组合加密而成）。
    
    缺点：用户状态变化（删除，禁用，注销等）影响到业务而Token仍然有效时，仍然能利用token完成认证，当token过期后需要用户重新登录，用户体验差。
    
    解决办法使用 accessToken （负责后端业务验证）+ refreshToken（负责续签验证）。认证后返回 accessToken + refreshToken，并保存在本地，服务端保存refreshToken，accessToken 失效时间应该设置较短，比如10分钟，refreshToken 失效时间可以长一点，比如 7 天。请求时只用 accessToken，客户端在 accessToken 在失效前主动发起请求用 refreshToken 返回一个新的 accessToken，或者在正常业务请求时判断access-token是否过期，过期了就顺带更新，用户无感提高用户体验。退出时客户端删除accessToken + refreshToken，服务端删除refresh-token。
    
    踢人下线：token+redis，redis中保存当前登录用户的有效access token集合，请求到来时先去redis查询，access token存在才放行。踢人时将redis中对应access token删除，拦截用户后续的认证，同时服务端将refresh token删除，防止用户利用reflesh token 更新access token。
    

- token重放攻击：解决重放的办法就是保证同样的请求只有一次生效。一般是随请求数据带一个唯一的字段（有时效性；一次性的 nonce），并使用客户端私钥进行签名，当请求到达服务端后，服务端发现过期，或者nonce 为已使用，那么当发生重放时请求就要被拒绝。
    
    服务端生成 nonce，然后发给客户端，客户端用这个 nonce 请求后，服务端删除对应的 nonce，这个这个 nonce 就只会被用一次了。使用客户端私钥进行签名，防止伪造过期标签和nonce值。
    

##### Socket

TCP：一个进程必须充当服务器端，它会主动监听某个指定的端口，另一个进程必须充当客户端，它必须主动连接服务器的IP地址和指定端口。
```java
public class Server {  
    public static void main(String[] args) throws IOException {  
        ServerSocket ss = new ServerSocket(6666); // 监听指定端口  
        System.out.println("server is running...);  
        // 无限循环来处理客户端的连接  
        for (;;) {  
            // 每当有新的客户端连接进来后，就返回一个Socket实例，这个Socket实例就是用来和刚连接的客户端进行通信的。由于客户端很多，要实现并发处理，我们就必须为每个新的Socket创建一个新线程来处理.  
            // 如果没有客户端连接进来，accept()方法会阻塞并一直等待  
            Socket sock = ss.accept();  
            System.out.println("connected from " + sock.getRemoteSocketAddress());  
            Thread t = new Handler(sock);  
            t.start();  
        }  
    }  
}  
​  
class Handler extends Thread {  
    Socket sock;  
​  
    public Handler(Socket sock) {  
        this.sock = sock;  
    }  
​  
    @Override  
    public void run() {  
        // 因为TCP是一种基于流的协议，因此，Java标准库使用InputStream和OutputStream来封装Socket的数据流  
        try (InputStream input = this.sock.getInputStream()) {  
            try (OutputStream output = this.sock.getOutputStream()) {  
                handle(input, output);  
            }  
        } catch (Exception e) {  
            try {  
                this.sock.close();  
            } catch (IOException ioe) {  
            }  
            System.out.println("client disconnected.);  
        }  
    }  
}  
​  
public class Client {  
    public static void main(String[] args) throws IOException {  
        // 接成功，将返回一个Socket实例，用于后续通信。  
        Socket sock = new Socket("localhost", 6666);   
        try (InputStream input = sock.getInputStream()) {  
            try (OutputStream output = sock.getOutputStream()) {  
                handle(input, output);  
            }  
        }  
        sock.close();  
        System.out.println("disconnected.);  
    }  
}
```

##### UDP

```java
// server  
DatagramSocket ds = new DatagramSocket(6666); // 监听指定端口  
for (;;) { // 无限循环  
    // 数据缓冲区:  
    byte[] buffer = new byte[1024];  
    DatagramPacket packet = new DatagramPacket(buffer, buffer.length);  
    ds.receive(packet); // 收取一个UDP数据包  
    // 收取到的数据存储在buffer中获得数据，packet.getData()获得数据，由packet.getOffset(), packet.getLength()指定起始位置和长度  
    // 发送数据:  
    byte[] data = "ACK".getBytes(StandardCharsets.UTF_8);  
    packet.setData(data);  
    ds.send(packet);  
}

// client  
DatagramSocket ds = new DatagramSocket();  
// 后续接收UDP包时，等待时间最多不会超过1秒，否则在没有收到UDP包时，客户端会无限等待下去。这一点和服务器端不一样，服务器端可以无限等待，因为它本来就被设计成长时间运行。  
ds.setSoTimeout(1000);  
// connect()方法不是真连接，它是为了在客户端的DatagramSocket实例中保存服务器端的IP和端口号，确保这个DatagramSocket实例只能往指定的地址和端口发送UDP包，不能往其他地址和端口发送。  
ds.connect(InetAddress.getByName("localhost), 6666); // 连接指定服务器和端口  
// 发送:  
byte[] data = "Hello".getBytes();  
DatagramPacket packet = new DatagramPacket(data, data.length);  
ds.send(packet);  
// 接收:  
byte[] buffer = new byte[1024];  
packet = new DatagramPacket(buffer, buffer.length);  
ds.receive(packet);  
// packet.getData()获得数据，由packet.getOffset(), packet.getLength()指定起始位置和长度  
// disconnect()也不是真正地断开连接，它只是清除了客户端DatagramSocket实例记录的远程服务器地址和端口号  
ds.disconnect();
```

##### 交换机、路由器

[https://www.jianshu.com/p/f05e8798e03c](https://www.jianshu.com/p/f05e8798e03c) 交换机工作在数据链路层，MAC地址寻址，主要用于组建局域网，实现了特定网络内的数据交换。 路由器工作在网络层，IP地址寻址，主要用于将局域网相互连接起来接入Internet，实现了不同网络之间的数据转发。

##### HTTP、 HTTPS、HTTP2

- HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，HTTPS协议是由SSL(位于TCP和HTTP之间)+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。
    
    > 混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。
    
    https协议需要到ca申请证书。http端口是80，https是443。http直接开始传输数据，https先通过非对称加密协商密钥，然后才是使用对称加密的数据传输。
    
- 客户使用https的URL访问Web服务器，要求与Web服务器建立SSL连接。
    
    [https://coolcao.com/2018/08/06/https/](https://coolcao.com/2018/08/06/https/)
    
    1，客户端请求 HTTPS 网址，然后连接到 server 的 443 端口，在 TCP 三次握手之后。
    
    2， SSL/TLS 的握手过程：通信双方相互确认，确立加密算法以及会话密钥 ，才可进入加密报文传输。
    
    > 客户端通过发送"client hello"消息向服务器发起握手请求，告诉服务器自己支持的协议版本，支持的加密算法及压缩算法，并生成一个随机数1；
    > 
    > 服务器发送"server hello"消息对客户端进行回应，会将网站的证书信息（证书中包含公钥）、服务器生成的随机数2传送一份给客户端；
    > 
    > 客户端解析证书并对其进行验证，首（服务器端需要先向CA机构申请证书，服务器向CA机构提供服务器的公钥，CA机构用自己的CA私钥对服务器的公钥进行签名，生成数字摘要，然后将服务器公钥和数字签名打进证书。客户端从服务器拿到证书后，根据证书上的CA签发机构，从内置的根证书里找到对应的CA机构公钥，用此公钥解开数字签名，得到摘要，根据此验证证书的合法性）客户端的生成随机数3，然后利用网站的公钥将随机数3加密，并传送给网站；
    > 
    > Web服务器利用自己的私钥解密出会话密钥，使用前面的三个随机数，生成对话密钥，用来加密接下来的整个对话过程；生成对话密钥需要三个随机数，但整个通话的安全，只取决于第三个随机数能不能被破解。由于SSL协议中证书是静态的，不管是客户端还是服务器，都需要随机数，随机数生成的密钥才不会每次都一样，确保连接的安全性和防止重放攻击。
    > 
    > 客户端发送经过密钥 加密过的"finished"信号；
    > 
    > 服务端发送经过密钥 加密过的"finished"信号；
    
    3，Web服务器利用会话密钥加密与客户端之间的通信。
    
    6，协商密钥使用非对称（RSA ，密钥不需要通过网络进行传输，计算量比较大），传输数据使用对称加密（AES高效，密钥的传输不安全）。
    
- HTTP/1.1 相比 HTTP/1.0
    
    1，使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 2，支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
    
    3，仍存在的问题：请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大；发送冗长的首部，每次互相发送相同的首部造成的浪费较多；请求只能从客户端开始，服务器只能被动响应；队头柱塞。
    
- HTTP/2 协议
    
    1，基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。
    
    2，HTTP/2 会压缩头（Header）如果同时发出多个请求，他们的头是一样的或是相似的，协议会消除重复的部分。
    
    3，HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）
    
    4，HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此可以并发不同的 Stream，防止队头柱塞。
    
    5，服务不再是被动地响应，也可以主动向客户端发送消息。
    

##### 加解密

1，base64：用64个Ascii字符来表示任意二进制数据的方法。优点：字符串适合不同平台、不同语言的传输；算法简单可逆， 解码很方便。缺点：编码后只会增加字节数。

2，签名：MD5、SHA、HMAC。数据->摘要->密钥加密->传输->重新生成摘要+公钥解密获得发送端摘要->对比。增强：加盐+多次计算摘要+换序+Bcrypt 算法（影响因子控制计算强度，决定破解密码所需要的资源和时间）。

3，对称性加密算法：AES、DES、3DES。

4，非对称性算法：RSA、DSA、ECC。

[https://zhuanlan.zhihu.com/p/48249182](https://zhuanlan.zhihu.com/p/48249182)

- RSA原理：对极大整数做因数分解的难度决定了RSA算法的可靠性。只要其钥匙的长度n足够长，用RSA加密的信息实际上是不能被解破的。
    
    选取质数`p,q`，得到`n=p*q`，计算n的欧拉函数（1~n内有多少数和n互为质数即不存在公约数）\Phi(n)=(p-1)*(q-1)，选取e使得1<e<\Phi(n)，且e与\Phi(n)互质，计算d使得(e*d)\%\Phi(n)=1。将n和e封装成公钥，n和d封装成私钥。
    
    在已知n和e的情况下，推导出d–>计算\Phi(n)–>计算p,q->对n做因数分解，现阶段只能对最多768个二进制位的n做分解。
    
    加密：c=(m^e)\%n，解密：m=(c^d)\%n
    

##### 队头阻塞

1，TCP队头阻塞：队在一个TCP分节丢失，后续分节将被接收端一直保持直到丢失的第一个分节被发送端重传并到达接收端为止，以确保接收应用进程能够按照发送端的发送顺序接收数据。假设在单个TCP连接上发送语义独立的消息，阻塞后续传递消息。

TCP中的队头阻塞的产生是由TCP自身的实现机制决定的，无法避免。QUIC在UDP协议的基础上实现了可靠传输，而UDP是面向数据报的协议，数据报之间不会有阻塞约束。

2，HTTP1.1 允许在持久连接上可选的使用请求管道。不必挨个发送等待响应后发送下一个，允许客户端在已发送的请求收到服务端的响应之前发送下一个请求，通过同时发送多个请求，可以降低网络的环回时间，提高性能。

管道化要求服务端按照请求发送的顺序返回响应（FIFO），因为HTTP请求和响应并没有序号标识，无法将乱序的响应与请求关联起来。如果一个响应返回延迟了，那么其后续的响应都会被延迟，直到队头的响应送达。

HTTP2不使用管道化的方式，而是引入了帧、消息和数据流等概念，每个请求/响应被称为消息，每个消息都被拆分成若干个帧进行传输，每个帧都分配一个序号。每个帧在传输是属于一个数据流，而一个连接上可以存在多个流，各个帧在流和连接上独立传输，到达之后在组装成消息，这样就避免了请求/响应阻塞。即使使用HTTP2，如果HTTP2底层使用的是TCP协议，仍可能出现TCP队头阻塞。

##### 中间人攻击

1，客户端询问目标网站的公钥。查询请求被中间人拦截，中间人伪装成目标网站，返回中间人的公钥，同时中间人也持有对应的私钥，中间人通过替换的中间人公钥以及对应的中间人私钥解开了交互密码。之后通信都会被中间人拦截，解密监听内容，同时中间人伪装成客户端与真正服务器发起正常的https通信，将获得的内容返回给客户端，保证客户端功能正常。

2，证书验证机制：对网站下发的公钥做一次哈希校验，然后与本机预先存储的证书信息做验证，如果一致说明对方的公钥是可信的。中间人攻击需要强制安装一个证书到“受信任”列表中，让客户端通过对中间人伪造证书的验证。

##### 请求、响应报文

- 请求报文由请求行（请求方法字段、URL字段和HTTP协议版本）、请求头部（关键字/值对组成，content-type，accept，keep-alive，语言，压缩方式，if-modifyed-since，agent）、空行和请求数据（POST、PIU）4个部分组成。
    
- 响应报文：状态行（状态代码、HTTP协议版本）、消息报头（语言，Last-Modified，数据类型、长度）、空行、响应正文。
    

##### UDP可靠传输

[https://cloud.tencent.com/developer/article/2008237](https://cloud.tencent.com/developer/article/2008237) 简单做法：把 TCP 可靠传输的特性（序列号、确认应答、超时重传、流量控制、拥塞控制）在应用层实现一遍。 但是TCP 天然支持可靠传输，UDP+应用层实现可靠传输是重复造轮子。

- 可靠传输：Packet Header 中的 Packet Number 是每个报文独一无二的编号，通过确认的方式保证可靠传输。它是严格递增的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。可以更加精确计算 RTT，没有 TCP 重传的歧义性问题；可以支持乱序确认，防止因为丢包重传将当前窗口阻塞在原地，避免队头柱塞。
    
    一个 Packet 报文中可以存放多个 QUIC Frame。framehead中包含：Stream ID 用于多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别；Offset 作用：类似于 TCP 协议中的 Seq 序号，保证数据的顺序性和可靠性。通过 Stream ID + Offset 字段信息实现数据的有序性，可以支持乱序确认而不影响数据包的正确组装。
    
- 避免队头柱塞： TCP 层为了保证数据的有序性，只有在处理完有序的数据后，滑动窗口才能往前滑动，否则就停留，会使得发送方无法继续发送数据，应用层无法读取新的数据。
    
    传输层队头柱塞：QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口。
    
    应用层队头柱塞： Packet Number +Stream ID + Offset 可以支持乱序确认，防止因为丢包重传将当前窗口阻塞在原地，避免队头柱塞。
    
- 流量控制
    
    Stream 级别的流量控制：每个 Stream 都有独立的滑动窗口。接收窗口的左边界取决于接收到的最大偏移字节数，接收窗口 = 最大窗口数 - 接收到的最大偏移数。
    

Connection 流量控制：限制连接中所有 Stream 相加起来的总字节数，其接收窗口大小就是各个 Stream 接收窗口大小之和。

- 拥塞控制
    
    默认使用TCP下的拥塞控制算法：慢开始、拥塞避免、快重传、快恢复策略。QUIC 是处于应用层的，应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持，传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，迭代速度慢。
    

##### 丢包

[https://www.zhihu.com/question/48889418](https://www.zhihu.com/question/48889418)

[https://www.51cto.com/article/710014.html](https://www.51cto.com/article/710014.html)

一个包从源出发可能经过：交换机、网关、路由器。在每一跳 packet 所途径的设备上有可能被接收端网络接口直接丢弃。

1. 物理层 (Physical Layer) 丢包原因：
 
 信号衰减：传输距离过远或链路质量差，导致信号衰减，接收端无法正确接收到数据。

 噪声干扰：电磁干扰（EMI）、无线信号干扰（如Wi-Fi、蓝牙冲突）会导致传输的信号变形或丢失。

 物理设备故障：硬件问题（如网线损坏、网卡故障、光纤断开等）会导致数据包在传输过程中丢失。

解决方法：
 
 使用高质量的网络传输介质，减少传输距离或加强信号放大。

 进行干扰排查，避免环境中不必要的信号源。

 定期检查和维护物理设备。


2. 数据链路层 (Data Link Layer)

丢包原因：
 
 碰撞和流量控制：在以太网等共享介质上，多个设备同时传输时可能会发生碰撞，导致数据包丢失。

 MAC地址冲突：在交换机、桥接设备上，网络中设备的MAC地址冲突或设置错误可能导致数据包无法正确转发。

 链路错误：链路上的错误（如CRC校验失败）也会导致数据包被丢弃。

解决方法：
 
 使用全双工模式，避免碰撞。

 采用适当的链路层协议和正确配置MAC地址。

 采用链路层的错误检测和纠正机制。


3. 网络层 (Network Layer)

丢包原因：
 
 路由选择错误：路由表配置错误或动态路由协议（如OSPF、BGP）出现问题，可能导致数据包选择错误路径，导致丢失。

 拥塞控制：路由器或网关的缓冲区满时会丢弃数据包，尤其在网络出现拥塞时。

 IP分片：在传输过程中，IP分片可能由于重组错误或某些设备不支持分片导致丢包。

解决方法：
 
 配置正确的路由协议和策略，避免路由环路。

 增加路由器的缓冲区或调整流量负载。

 进行IP分片重组的优化，确保数据包能够正确重组。


4. 传输层 (Transport Layer)

丢包原因：
 
 TCP流量控制：接收端的窗口大小不够，导致接收方无法及时处理数据，发送方在未得到确认前继续发送，可能会导致中间路由器或设备丢弃数据包。

 TCP拥塞控制：在网络出现拥塞时，TCP协议会启动拥塞控制机制（如慢启动、拥塞避免），这可能导致传输速率降低，进一步增加丢包概率。

 UDP无确认机制：UDP协议没有数据确认机制，发送方无法获知数据是否到达接收方，因此容易出现丢包。

解决方法：
 
 调整TCP的窗口大小和拥塞控制策略，优化网络流量。

 如果丢包对应用有重要影响，考虑使用TCP代替UDP，或在UDP之上添加应用级重传机制。


5. 会话层 (Session Layer)

丢包原因：
 
 会话管理错误：会话管理不当，导致连接断开或会话丢失，进而影响数据包的传输。

解决方法：
 
 确保会话协议（如SSL/TLS）的健壮性，防止会话中断。

 检查应用层会话的超时设置，防止因超时导致的数据丢失。


6. 表示层 (Presentation Layer)

丢包原因：
 
 数据编码问题：数据格式不兼容或编码错误，可能导致接收方无法正确解析数据，产生丢包。

解决方法：
 
 确保传输的数据格式标准化，应用数据编码和解码的一致性。


7. 应用层 (Application Layer)

丢包原因：
 
 应用协议设计问题：应用协议可能由于设计问题（如数据包大小过大、无重传机制等）导致丢包。

 应用层重传机制缺失：在UDP协议下，应用层没有实现适当的重传机制，导致丢包发生后无法恢复。

 应用超时：应用在超时后放弃重试，直接导致数据丢失。

解决方法：
 
 优化应用协议的设计，确保有效的数据包大小和合理的重传策略。

 实现应用层的可靠性机制，尤其是当UDP用于需要高可靠性的场景时。


##### websocket

[万字长文，一篇吃透WebSocket：概念、原理、易错常识、动手实践 - 腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/1887095)

浏览器需要不断的向服务器发出请求，然而 HTTP 请求与响应可能会包含较长的头部，其中真正有效的数据可能只是很小的一部分，所以这样会消耗很多带宽资源。WebSocket 与 HTTP 和 HTTPS 使用相同的 TCP 端口，在单个 TCP 连接上进行全双工通信，允许服务端主动向客户端推送数据，位于 OSI 模型的应用层。

- 较少的控制开销：在连接创建后，服务器和客户端之间交换数据时，用于协议控制的数据包头部相对较小；
    
- 更强的实时性：由于协议是全双工的，所以服务器可以随时主动给客户端下发数据。相对于 HTTP 请求需要等待客户端发起请求服务端才能响应，延迟明显更少；
    
- 保持连接状态：与 HTTP 不同的是，WebSocket 需要先创建连接，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息；
    

WebSocket 协议属于应用层协议，它依赖于传输层的 TCP 协议。WebSocket 通过 HTTP/1.1 协议的 101 状态码进行握手。让 WebSocket 与现有 HTTP 基础设施兼容，使得 WebSocket 服务器可以运行在 80 和 443 端口上，这通常是对客户端唯一开放的端口；让我们可以重用并扩展 HTTP 的 `Connection: Upgrade,Upgrade: websocket`升级到 WebSocket 协议，为其添加自定义的 WebSocket 首部，以完成协商。

长轮询的本质还是基于 HTTP 协议，它仍然是请求 响应的模式，只是响应事件推迟了而已。而 WebSocket 在握手成功后，就是全双工的 TCP 通道，数据可以主动从服务端发送到客户端。

 起始字节 (Fin, RSV, Opcode)

|字段|长度|说明|
|---|---|---|
|**FIN**|1 bit|是否是最后一个帧。1 表示这是消息的最后一帧，0 表示还有后续帧。|
|**RSV1, RSV2, RSV3**|1 bit 每个|这三个字段是保留字段，用于未来的扩展，通常值为 0。|
|**Opcode**|4 bits|表示数据帧的类型。常见的值有：|
|||- `0x0`：继续帧（Continuation frame）|
|||- `0x1`：文本数据帧（Text frame）|
|||- `0x2`：二进制数据帧（Binary frame）|
|||- `0x8`：连接关闭帧（Close frame）|
|||- `0x9`：ping 帧（Ping frame）|
|||- `0xA`：pong 帧（Pong frame）|

 掩码和数据长度 (Mask, Payload Length)

|字段|长度|说明|
|---|---|---|
|**Mask**|1 bit|该字段指示数据是否被掩码。客户端发送的数据必须加密并掩码，服务器可以选择性地进行掩码操作。掩码字段的值为 1 表示有掩码，0 表示没有。|
|**Payload Length**|7 bits (或 7+16+64 bits)|数据负载的长度。对于小于 125 字节的消息，长度使用 7 位字段表示；对于较长的消息，长度使用扩展字段（2 字节或 8 字节）。|
|**Extended Payload Length**|16 bits 或 64 bits|如果 Payload Length 为 126 或 127，使用这两个字段来表示负载长度（分别是 2 字节或 8 字节）。|

数据负载 (Payload Data)

|字段|长度|说明|
|---|---|---|
|**Payload Data**|可变长度|实际的数据内容（即 WebSocket 消息的负载数据）。对于文本帧，它是 UTF-8 编码的数据；对于二进制帧，它是二进制数据。|
|**Masking Key**|4 bytes|如果掩码为 1，则该字段提供 4 字节的掩码密钥，用于对数据进行掩码。掩码密钥将按位异或（XOR）操作用于负载数据。|

**HTTP/2**：基于多路复用的协议，通过流的概念来并行处理请求和响应，允许在一个连接上同时进行多个请求和响应，模拟双工通信，但仍基于请求-响应模型。

**HTTP/3 (QUIC)**：基于 UDP，支持低延迟、双向通信，通过流的多路复用提供更快速的双工数据交换。

**MQTT**：轻量级发布/订阅协议，使用发布/订阅模型，客户端和服务器通过 Broker 实现异步的双向通信，支持客户端与服务器的双向通信，常用于物联网（IoT）。

**WebRTC**：支持浏览器间点对点的音视频和数据传输，提供低延迟、双向实时通信。

**XMPP**：基于 XML 的协议，广泛应用于即时消息系统，支持客户端和服务器的双向通信。

**AMQP**：面向消息的协议，支持可靠的双向通信，适用于企业级应用。
CoAP：为低功耗设备设计的协议，支持双向通信，常用于物联网。

---

### 操作系统

##### 进程、线程、协程

一个应用程序一般对应一个进程，一个进程一般有一个主线程，还有若干个辅助线程，线程之间是平行运行的，在线程里面可以开启协程，让程序在特定的时间内运行。

* 进程：进程控制块（process control block，PCB）数据结构来描述进程的，包括进程标识符、用户标识符、优先级、进程状态、寄存器。执行的程序、资源分配、由程序+数据集合+进程控制块组成，每一个进程都有它自己的地址空间，独立的堆栈、由操作系统调度（抢占式调度）、切换开销大(栈、寄存器、虚拟内存、文件句柄等)、稳定安全、进程间通信。

  ![700|700](%E9%9D%A2%E7%BB%8F.assets/image-20220914125140687.png)

* 线程：多任务，线程是进程当中的一条执行流程、调度和分派、独立的栈和程序计数器和共享的代码段、数据段、打开的文件等资源、地址空间等，由操作系统调度（抢占式调度）、共享进程资源，线程使用公共变量或者内存的时候需要同步机制，使用共享内存进行通信、上下文切换很快，资源开销较少、不够稳定容易丢失数据、多核并行高性能、适合IO密集型、通信不需要OS干预、

  内核线程：在内核中实现的线程，是由内核管理的线程、用户线程（轻量级进程）由内核线程支持，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等；一对一模型（真正的并发、独立、数量有限、调度开销大）、多对一模型（由用户态切换、阻塞；如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行）、多对多模型。
  线程的创建时间比进程快，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；
  线程的终止时间比进程快，因为线程释放的资源相比进程少很多；
  同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），不需要切换页表。
  由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，数据交互效率更高了；

  空间+切换+通信==>线程更轻量

* 协程：基于线程之上，协程是组织好的代码流程，比线程更加轻量级、存在用户态的轻量级线程、用户控制调度（对内核透明，内存占用小、单线程进程、无陷入和上下文切换、难以实现强制的 CPU 控制权切换，主动出让控制权）、适用于被阻塞大量并发的场景、不适用于大量计算的多线程。

##### Linux进程状态

* 可执行状态：正在 CPU 上执行的进程定义为 RUNNING 状态、而将可执行但是尚未被调度执行的进程定义为 READY 状态（获得了除了处理器之外的一切所需资源），linux 下统一为 TASK_RUNNING 状态。

* 可中断的睡眠状态：等待事件的发生（比如等待信号量、对应事件的等待队列中、事件发生进程被唤醒），而被挂起。

* 不可中断的睡眠状态：进程处于睡眠状态，进程是不可中断的（不响应异步信号，内核的某些处理流程是不能被打断的，比如IO操作与对应的物理设备进行交互）。

* 暂停状态或跟踪状态：收到SIGSTOP信号。

* 退出状态（EXIT_ZOMBIE）：僵尸进程、所有资源将被回收，除了 task_struct 结构（保存了进程的退出码，父进程逻辑判断）、内核通知父进程回收（父进程结束则被收养）。

* 退出状态（ EXIT_DEAD）：即将被销毁、彻底释放。

* 进程的初始状态：将调用进程（fork、clone、vfork）复制一份，得到子进程、独立。

  ![700|475](%E9%9D%A2%E7%BB%8F.assets/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.png)

##### 进程通信

* 匿名管道：单工、FIFO、柱塞式、亲缘进程（因为管道没有实体，特殊文件只存在于内存，没有存在于文件系统中，只能通过 fork 来复制父进程 fd 文件描述符，通信的数据是无格式的流并且大小受限）、本质为内核缓冲区。有名管道（磁盘文件、非亲缘，因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。）
* 信号：sigterm、sigkill、中断机制的一种模拟，异步通信方式（阻塞），来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）、三种处理方式： 1. 执行默认操作、2. 捕捉信号、3. 忽略信号。
* 消息队列：内核中的消息链表、特定的格式、FIFO、存在用户态与内核态之间的数据拷贝开销，
* 共享内存：直接读写同一块内存空间、将其映射到进程的私有地址空间（内存逻辑地址）无拷贝、不需要陷入内核态或者系统调用，多进程竞争同个共享资源会造成数据的错乱，需要同步机制。
* 信号量：资源计数器、进程间同步、创建等待释放、等待队列、原子操作（P、V原语）、进程的线程间共享。
* 互斥量：临界区视为资源、原语加锁解锁、等待队列、管程（封装、wait、signal、synchronized方法）
* 套接字：IP+Port、远程、TCP/UDP。

##### 线程冲突

由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（critical section），它是访问共享资源的代码片段，应该是互斥（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区。

每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，所谓同步，就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。

同步强调先后顺序；互斥强调不能同时进行。

##### 进程锁、线程锁

线程锁:主要用来给方法、代码块加锁。当某个方法或者代码块使用锁时，那么在同一时刻至多仅有有一个线程在执行该段代码。当有多个线程访问同一对象的加锁方法/代码块时，同一时间只有一个线程在执行，其余线程必须要等待当前线程执行完之后才能执行该代码段。但是，其余线程是可以访问该对象中的非加锁代码块的。

进程锁:也是为了控制同一操作系统中多个进程访问一个共享资源，只是因为程序的独立性，各个进程是无法控制其他进程对资源的访问的，但是可以使用本地系统的信号量控制（操作系统基本知识）。

线程锁，进程锁，分布式锁的作用都是一样的，区别在于锁放在哪，放在私有的进程空间还是放在多进程共享的空间，作用的范围大小。范围大小:分布式锁>进程锁>线程锁。

##### 线程通信

1，锁机制：互斥锁提供了以排他方式防止数据结构被并发修改的方法，条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。 wait/notify 等待，生产者、消费者模型。

2，Volatile 内存变量，CountDownLatch 并发工具。

3，信号量机制(Semaphore)。

4，消息队列（rabbitMQ）:当不需要立即获得结果,异步处理：写入消息队列后立即返回客户端,无需等待；限流削峰：请求先入消息队列，而不是由业务处理系统直接处理，做了一次缓冲, 极大地减少了业务处理系统的压力。

5，哲学家进餐：用信号量的方式，也就是 PV 操作来尝试解决它，进餐前获取两边筷子，吃完后释放，极端的问题：假设五位哲学家同时拿起左边的叉子，死锁；在拿叉子前，加个互斥信号量进入临界区，返回叉子后退出临界区，只要有一个哲学家进入了「临界区」，也就是准备要拿叉子时，其他哲学家都不能动，只有这位哲学家用完叉子了，才能轮到下一个哲学家进餐，效率低；即让偶数编号的哲学家「先拿左边的叉子后拿右边的叉子」，奇数编号的哲学家「先拿右边的叉子后拿左边的叉子」，让相邻哲学家的竞争在拿一个叉子的时候就发生，避免获得第一个叉子后，竞争第二个叉子失败，白白持有第一个叉子而浪费资源，即不会出现死锁，也可以两人同时进餐。

##### 内存分段、分页

逻辑地址（模拟完整连续内存方便使用、进程隔离、更大内存）；物理地址（非连续）；地址转换。

* 段：内存块单元、逻辑完整（保护、共享）、代码、堆栈、段号+偏移量、大小可变、段表（段号-> 物理地址）、适合处理复杂系统的逻辑分区。外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；swap每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上，内存交换效率低。

* 分页：大小固定（4KB）、物理连续、页表（进程不共享，页号-> 物理块号）、页号（块号）+偏移量、缓存（局部性原理）、

  多级页表（逻辑地址大->页表太长+进程页表独立->占据空间大），页表的页表、多级索引，理论上二级分页占用空间确实是更大了，局部性原理：如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表，通过节省占大头的二级页表节省内存）、适合管理物理内存、释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存，利用率高。swap:一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。

* 段页：先将程序划分为多个有逻辑意义的段，接着再把每个段划分为多个页先、段号+页号+偏移、段表（段号->页表地址）、页表（页号->物理页号）

* 为什么4KB：https://draveness.me/whys-the-design-linux-default-page/

##### 内存调度

* 当 CPU 访问的页面不在物理内存时（逻辑地址），便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，最后把正在访问的页面装入到这个物理页中。

* 最佳页面置换算法（*OPT*）：置换在「未来」最长时间不访问的页面。因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间，最佳页面置换算法作用是为了衡量你的算法的效率。

* 先进先出置换算法（*FIFO*）：选择在内存驻留时间很长的页面进行中置换。

* 最近最久未使用的置换算法（*LRU*）：选择最长时间没有被访问的页面进行置换， LRU 则是通过「历史」的使用情况来推测要淘汰的页面，近似最优置换算法。代价很高：为了完全实现 LRU，需要在内存中维护一个所有页面的链表。

* 时钟页面置换算法（*Lock*）：把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面：如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；如果访问位是 1 就清除访问位改为0，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

* 最不常用置换算法（*LFU*）：当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。成本高：要增加一个计数器来实现。记忆力太好：比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。

  $O(1)$复杂度实现：
  
  [O(1) 复杂度的 LFU 实现 | 伴鱼技术团队 (ipalfish.com)](https://tech.ipalfish.com/blog/2020/03/25/lfu/)
  
  ![600|400](%E9%9D%A2%E7%BB%8F.assets/image-20221129223728887.png)

##### DMA

https://www.cnblogs.com/xiaolincoding/p/13719610.html

![600|450](%E9%9D%A2%E7%BB%8F.assets/image-20221129224657987.png)

- CPU 发出对应的指令给磁盘控制器，然后返回；
- 磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断；
- CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。

![600|475](%E9%9D%A2%E7%BB%8F.assets/image-20221129224712267.png)

- 用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；
- 操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；
- DMA 进一步将 I/O 请求发送给磁盘；
- 磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；
- DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务；
- 当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；
- CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；

##### 零拷贝

* `mmap()` 系统调用函数会直接把内核缓冲区里的数据映射到用户空间，省去一次将数据从内核缓存区拷贝到内存的操作。
* `sendfile()`在内核缓冲区中操作数据，不需要cpu参与。
* 全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。



##### 磁盘调度

* 多层盘片，盘片中的每一层分为多个磁道，每个磁道分多个扇区。磁盘选择（电子）+磁道选择（机械）+扇区选择(转速)。通过优化磁盘的访问请求顺序来做到的提高磁盘的访问性能。
* 先来先服务算法：如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。
* 最短寻道时间优先算法：优先选择从当前磁头位置所需寻道时间最短的请求，后续请求距离较小，导致某些请求的饥饿。
* 扫描算法算法：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。不会产生饥饿现象，但是中间部分相比其他部分响应的频率会比较多，每个磁道的响应频率存在差异。
* 循环扫描算法：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。响应频率相对比较平均
* LOOK ：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。
* C-LOOK：磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。

##### 进程调度

* 先来先服务调度算法：当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。
* 最短作业优先调度算法：优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。长作业饥饿。
* 高响应比优先调度算法：每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行。优先级=(已等待事件+要求服务时间)/要求服务时间。这样短作业的进程容易被选中运行；对于长作业当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会。
* 时间片轮转调度算法：每个进程被分配一个时间段，如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
* 最高优先级调度算法：从就绪队列中选择最高优先级的进程进行运行，
* 多级反馈队列调度算法：多个队列，每个队列优先级从高到低，同时优先级越高时间片越短，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成。如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了。
* O(1)、CFS。
1. - 每个进程（`Process`）有`vruntime`属性，表示该进程的虚拟运行时间。
    - `weight`是进程的权重，通常由进程的静态优先级决定。权重越大，进程的`vruntime`增长越慢，调度时优先级越高。
2. **调度队列**：
    - 使用一个**红黑树**（`RedBlackTree`）来维护进程的就绪队列，红黑树根据进程的`vruntime`排序，确保每次调度选择`vruntime`最小的进程。
3. **调度过程**：
    - 调度器的核心函数是`schedule()`，它从红黑树中提取出`vruntime`最小的进程，也就是下一个要执行的进程。
    - 进程执行后，调度器更新其`vruntime`，并将其重新放入队列中。
    - 调度器会不断循环，调度下一个最小`vruntime`的进程直到没有进程。
4. **`vruntime`的更新**：
    - `vruntime`的计算方式是通过进程的执行时间（`time_spent`）与进程的权重（`weight`）相乘。进程执行时间越长，其`vruntime`增长越多，因此会在下一次调度时排到较低的优先级。

```python
class Process:
    def __init__(self, pid, priority):
        self.pid = pid  # 进程ID
        self.vruntime = 0  # 进程的虚拟运行时间
        self.weight = 1024  # 权重（与优先级相关，通常通过静态优先级计算）

class Scheduler:
    def __init__(self):
	    # 就绪队列，按vruntime排序
        self.ready_queue = RedBlackTree()  
    def enqueue(self, process):
        # 将进程插入到就绪队列中
        self.ready_queue.insert(process)
    def dequeue(self):
        # 从就绪队列中移除进程
        return self.ready_queue.extract_min()
    def update_vruntime(self, process, time_spent):
        # 更新进程的vruntime
        process.vruntime += time_spent * process.weight
    def run(self):
        # 模拟调度循环
        while True:
            process = self.dequeue()  # 获取下一个要调度的进程
            self.switch_to_process(process)  # 切换到目标进程执行
            time_spent = self.get_execution_time(process)
            self.update_vruntime(process, time_spent)  # 更新进程的vruntime
            self.enqueue(process)  # 将进程重新加入就绪队列
```
##### 进程切换

* 进程切换：必然陷入内核态需要切换内核态堆栈，PCB（用于描述控制进程的运行）的切换，切换页表（进程间虚拟内存独立），刷新TLB。
1，CPU寄存器的内容

通用寄存器：例如eax、ebx、ecx等（x86架构）或r0到r15（ARM架构）。这些寄存器用于存储进程运行时的局部数据和计算结果，必须在切换进程时保存。
程序计数器（PC, Program Counter）：即当前进程正在执行的指令的地址。在进程切换时，程序计数器需要保存，以便下次恢复时从正确的位置继续执行。
堆栈指针（SP, Stack Pointer）：指示当前进程栈的顶部，用于管理函数调用和局部变量。堆栈指针是进程切换时必须保存的重要内容。
基址寄存器和数据段寄存器：这些寄存器用于进程的内存管理和数据访问。特别是在多任务系统中，保存和恢复内存映射至关重要。

2，内存管理信息

页表指针：用于虚拟内存管理的页表指针（在支持虚拟内存的系统中）。进程切换时需要保存当前进程的页表指针，因为不同进程可能有不同的虚拟地址空间。
内存段寄存器：包括代码段寄存器（CS）、数据段寄存器（DS）等，在一些操作系统中也需要保存，以便恢复时可以访问正确的内存段。

3，进程状态

进程的调度信息：如进程的优先级、状态（如就绪、等待、运行等），用于管理进程的调度队列。
定时器状态：如果当前进程正在使用定时器或硬件中断处理器，可能需要保存定时器的状态，以便恢复时正确继续处理。

4，文件描述符和I/O状态

文件描述符表：如果进程正在进行文件操作或I/O操作，需要保存文件描述符表。这个表记录着进程打开的文件、网络连接等资源。
I/O操作状态：如果进程正在等待I/O操作完成，切换时需要记录进程的I/O请求和状态。

##### 线程切换
线程共享资源，所以不需要切页表。一个线程执行至少需要寄存器和堆栈，线程切换本质就是堆栈的切换。
(1) CPU寄存器的内容

通用寄存器：如eax、ebx、ecx等（x86架构），或者r0到r15（ARM架构）。这些寄存器用于保存线程的局部数据、临时计算结果等，必须在切换时保存。
程序计数器（PC, Program Counter）：指示当前线程正在执行的指令地址。在进行线程切换时，必须保存当前线程的程序计数器，以便恢复时从正确的位置继续执行。
堆栈指针（SP, Stack Pointer）：指示当前线程的栈的顶部。线程的栈用于管理局部变量、函数调用、返回地址等信息，因此堆栈指针需要保存。
基址寄存器和数据段寄存器：在一些架构上，可能需要保存这些寄存器，用于恢复线程的内存访问。

(2) 线程的状态信息

线程的状态：线程的当前状态（如就绪、运行、阻塞等）需要在切换时保存。这个信息通常保存在线程控制块（TCB, Thread Control Block）中。
调度信息：如线程的优先级等，决定该线程在调度队列中的位置。通常由操作系统维护，并在上下文切换时保存和恢复。

* 每个进程都有自己的虚拟地址空间，进程内的所有线程共享进程的虚拟地址空间，进程切换涉及虚拟地址空间的切换而线程不会。使用Cache（TLB）来缓存常用的地址映射，这样可以加速页表查找，由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低,表现出来的就是程序运行会变慢。

##### 用户态、内核态

系统调用将 Linux 整个体系分为用户态和内核态；内核态：控制计算机的硬件资源、稳定安全；用户态：提供应用程序运行的空间、系统调用（os接口）、库函数对系统调用进行封装；给不同的操作给与不同的 “权限”、切换方式（系统调用、异常、外设中断）

##### 调度

（饥饿、长短作业公平性、优先级）先来先服务、短作业优先、时间片轮转、多级队列（新进程优先级高、优先级高时间片越短、抢占式、级别降低）。

##### Linux调度

内核线程、调度基于线程，nice值越低优先级越高

* O(1)：常数时间、数组+链表、活动队列+过期队列、多级队列140优先级、高优先级长时间片、优先级调度、时间片用完加入过期队列（防止饿死）、活动队列空交换多动、过期队列、核心间队列独立、队列维护bitmap指示那些优先级还有任务（寻找最高优先级任务=寻找bitmap中最高位为1 的bit，cpu指令优化O(1),然后数组支持随机访问=>O(1)）、交互任务性能差
* CFS：红黑树（增删查log(N)）、不直接根据优先级分配时间、依据vruntime（nice因子大时间流逝快）决定优先级、vruntime插入红黑树、左下角vruntime最小（优先被调度）、定期将运行任务阿vruntime与左下角比较（抢占）、选择O(1)、插入O(log(N))

##### 死锁

前提：互斥资源、请求新资源、不可抢占、等待关系闭环。

死锁检测：单资源：单向有向图环检测（以每个节点为起点，深度优先、重复）。多资源：银行家算法判断是否存在让所有进程运行完毕的分配序列。

死锁恢复：抢占所需要的资源（用完归还）、杀死环中进程（选择副作用小的进程）。

死锁避免：安全前提（存在非死锁序列）下分配资源（银行家算法），判断是否存在让所有进程运行完毕的分配序列。。

死锁预防：非独占（假脱机打印）、非占有等待（一次请求全部资源）、破坏不可抢占（请求失败释放占有资源）。破坏等待（资源编号、请求资源序号升序、无环产生）
```java
class DeadlockDetection {
    // 表示进程
    static class Process {
        String name;
        // 持有资源
        Set<String> allocatedResources;
        // 请求资源
        Set<String> requestedResources;
        Process(String name) {
            this.name = name;
            this.allocatedResources = new HashSet<>();
            this.requestedResources = new HashSet<>();
        }
        void allocateResource(String resource) {
            allocatedResources.add(resource);
        }
        void requestResource(String resource) {
            requestedResources.add(resource);
        }
        boolean isWaitingFor(Process other) {
            // 判断该进程是否等待其他进程的资源
            for (String resource : requestedResources) {
                if (other.allocatedResources.contains(resource)) {
                    return true;
                }
            }
            return false;
        }
    }
    // 死锁检测算法
    public boolean detectDeadlock(List<Process> processes) {
        // 构建等待-for图，类似邻接表
        Map<String, Set<String>> waitForGraph = new HashMap<>();
        // 构建图：如果进程P1等待P2的资源，就在图中添加P1 -> P2
        for (Process p1 : processes) {
            for (Process p2 : processes) {
                if (p1 != p2 && p1.isWaitingFor(p2)) {
                    waitForGraph
                            .computeIfAbsent(p1.name, k -> new HashSet<>())
                            .add(p2.name);
                }
            }
        }
        // 已访问
        Set<String> visited = new HashSet<>();
        // 当前访问路径
        Set<String> recStack = new HashSet<>();
        for (String processName : waitForGraph.keySet()) {
            if (!visited.contains(processName)) {
                if (hasCycle(waitForGraph, processName, visited, recStack)) {
                    return true; // 找到环，发生死锁
                }
            }
        }
        return false; // 没有环，无死锁
    }
    // DFS 检测环
    private boolean hasCycle(Map<String, Set<String>> graph, String node, Set<String> visited, Set<String> recStack) {
        visited.add(node);
        recStack.add(node);
        for (String neighbor : graph.getOrDefault(node, Collections.emptySet())) {
            if (!visited.contains(neighbor)) {
                // 未访问，dfs处理
                if (hasCycle(graph, neighbor, visited, recStack)) {
                    return true;
                }
                // 已访问，且在当前路径中，说明有环
            } else if (recStack.contains(neighbor)) {
                return true; // 找到环
            }
        }
        recStack.remove(node);
        return false;
    }
}

```

##### 尾递归

传统递归在递归返回后好需要继续运算，保留栈帧；空间O(N);尾递归在递归返回后无后续运算，当前递归结果已被收集（二叉查找树的左右子节点为参数），无需保留栈帧，空间O(1)

##### CAS

乐观锁；根据地址v取值A=get(v)->B=f(A)->A=get(v)->成立则将B写入v,失败则不断重复至成功；重复读取get(v)，单变量原子性（封装），ABA问题（版本号比较）




##### 阻塞非阻塞与同步异步

https://www.cnblogs.com/loveer/p/11479249.html

IO分两阶段1.数据准备阶段，2.内核空间复制数据到用户进程缓冲区（用户空间）阶段

* 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态，对同一个线程来说的，阻塞IO和非阻塞IO的区别在于第一步发起IO请求是否会被阻塞。阻塞调用是指调用结果返回之前，主动挂起自己的操作，进程转变为“等待”的状态，调用线程只有在得到结果之后（同步：监测，异步：通知）才会返回。非阻塞调用指被调用后立即返回一个状态值，无需等I/O操作彻底完成，根据返回的状态，线程可以自行其它任务，（同步：轮询，异步：通知）。
* 同步和异步对应于调用者与被调用者，它们是线程之间的关系，关注的是消息通知的机制。同步IO和异步IO的区别就在于第二个步骤是否阻塞，如果不阻塞，发起I/O请求后仍需要继续执行，返回时不一定知道结果，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数，操作系统帮你做完IO操作再将结果返回给你，那么就是异步IO。同步IO即调用者需要等待被调用者返回结果，由处理消息者自己去等待消息是否被触发，之后才会进行下一步操作（需要等待或者轮询内核I/O操作完成后才能继续执行）。
* 阻塞与非阻塞与是否同步异步无关。
* 一个非阻塞I/O 系统调用 read() 操作立即返回的是任何可以立即拿到的数据，可以是完整的结果，也可以是不完整的结果，还可以是一个空值。而异步I/O系统调用 read（）结果必须是完整的， 但是这个操作完成的通知可以延迟到将来的一个时间点。
- **阻塞同步**：I/O 操作和执行同步，程序在等待完成时被阻塞。
- **非阻塞异步**：I/O 操作异步进行，程序继续执行其他任务，完成后通过回调或事件处理。
- **阻塞异步**：尽管 I/O 操作是异步的，但程序仍然被阻塞，直到完成。
- **非阻塞同步**：I/O 操作同步进行，但程序不被阻塞，继续处理其他任务。

##### I/O多路复用

通过一种机制，可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作，没有就绪事件时，就会阻塞交出cpu。多路是指多个链接，复用指的是复用同一线程。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。

https://developer.aliyun.com/article/763247

https://juejin.cn/post/6931543528971436046

* select：时间复杂度O(n)，通过设置或者检查存放fd标志位的数据结构（fd数组为整型数组，用于保存文件描述符）来进行下一步处理，它仅仅知道有I/O事件发生了，却并不知道是哪那几个流，只能无差别轮询所有流，找出能读出数据，或者写入数据的流，效率较低。单个进程可监视的fd数量被限制，即能监听端口的大小有限。内核需要将消息传递到用户空间时需要内核拷贝动作，每次调用select，都需要把fd集合从用户态拷贝到内核态。

  1，用户线程调用select，将fd_set从用户空间拷贝到内核空间 2. 内核在内核空间对fd_set遍历一遍，检查是否有就绪的socket描述符，如果没有的话，就会进入休眠，直到有就绪的socket描述符 3. 内核返回select的结果给用户线程，即就绪的文件描述符数量 4. 用户拿到就绪文件描述符数量后，再次对fd_set进行遍历，找出就绪的文件描述符 5. 用户线程对就绪的文件描述符进行读写操作。

* poll：时间复杂度O(n)，本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。但是它没有最大连接数的限制，原因是它是基于链表来存储fd的。每次调用poll，都需要把fd集合从用户态拷贝到内核态。

  1,用户线程调用poll系统调用，并将文件描述符链表拷贝到内核空间。2，内核对文件描述符遍历一遍，如果没有就绪的描述符，则内核开始休眠，直到有就绪的文件描述符。3，返回给用户线程就绪的文件描述符数量。4，用户线程再遍历一次文件描述符链表，找出就绪的文件描述符。5，用户线程对就绪的文件描述符进行读写操作。

* epoll：时间复杂度O(1)，epoll可以理解为event poll，给每个fd注册一个回调函数，当fd对应的设备发生IO事件时，就会调用这个回调函数，将该fd放到一个链表中，然后唤醒在epoll_wait中进入睡眠的进程，最后只要判断一下就绪链表是否为空就行了，非空就从该链表中取出一个fd，以此达到O（1）的时间复杂度。效率提升，不是轮询的方式；根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，而跟连接总数无关，会随着fd数量上升而效率下降。使用内存映射(mmap)，不需要从用户空间频繁拷贝fd数据到内核空间。

  mmap，是将文件/设备映射到内存中，进程可以通过读写内存的方式，实现对被mmap文件的操作。进程通过mmap映射相同的文件，实现共享内存方式的通信。对于大量频繁读写的文件，mmap相对read/write的方式，避免了内核空间->用户空间的数据传输和切换（epoll）。

  具体实现：对应着有三个函数：

  **epoll_create**：epoll_create相当于在内核中创建一个存放fd的数据结构。在select和poll方法中，内核都没有为fd准备存放其的数据结构，只是简单粗暴地把数组或者链表复制进来；而epoll则不一样，epoll_create会在内核建立一颗专门用来存放fd结点的红黑树，储监控的文件描述符，后续如果有新增的fd结点，都会注册到这个epoll红黑树上。

  **epoll_ctr**：select和poll会一次性将监听的所有fd都复制到内核中，而epoll不一样，当需要添加一个新的fd时，会调用epoll_ctr，给这个fd注册一个回调函数，然后将该fd结点注册到内核中的红黑树中。当该fd对应的设备活跃时，会调用该fd上的回调函数，将该结点存放在一个就绪链表（存储就绪的文件描述符）中。这也解决了在内核空间和用户空间之间进行来回复制的问题。
  
  **epoll_wait**：epoll_wait的做法也很简单，其实直接就是从就绪链表中取结点，这也解决了轮询的问题，时间复杂度变成O(1)
  
  Level和Edge指的就是触发点，Level为只要处于水平，那么就一直触发，而Edge则为上升沿和下降沿的时候触发。当缓冲区有数据可取的时候，ET会触发一次事件，之后就不会再触发，而LT只要我们没有取完缓冲区的数据，就会一直触发。

多路复用一样会阻塞用户线程，使用多路复用一次可以处理多个文件描述符，而且付出的代价是仅需要创建一个线程。

##### NIO

https://tech.meituan.com/2016/11/04/nio.html

https://xie.infoq.cn/article/fb524c4992beea6bb4487af87

https://www.cnblogs.com/loveer/p/11479887.html

是一种同步非阻塞的 I/O 模型，在等待就绪阶段都是非阻塞的，真正的 I/O 操作是同步阻塞。是 I/O 多路复用的基础，成为解决高并发与大量连接、I/O 处理问题的有效方式。

服务器端同步阻塞 I/O 处理:socket.accept()、socket.read()、socket.write() 三个主要函数都是同步阻塞的，当一个连接在处理 I/O 的时候，系统是阻塞的，所以使用多线程时，就可以让 CPU 去处理更多的事情。低并发下结合线程池使得创建和回收成本相对较低，并且编程模型简单。创建和销毁都是重量级的系统函数，线程本身占用较大内存，线程的切换成本是很高的，无法应对百万级连接。

所有的系统 I/O 都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。NIO 里用户最关心” 我可以读了”。NIO的读写函数可以立刻返回而不是柱塞，如果一个连接不能读写（socket.read()返回0或者socket.write()返回0），我们可以把这件事记下来，将用于传输的通道全部注册到选择器上，选择器监控通道，当某一通道就绪后连接继续进行读写，没有必要开启多线程。没有线程切换，只是拼命的读、写、选择事件。单线程轮询。

![400|575](%E9%9D%A2%E7%BB%8F.assets/77752ed5.jpg)

Java NIO 实际读写时的核心在于：通道（Channel）和缓冲区（Buffer），选择器。通道表示打开到 IO 设备（文件流、套接字）的连接，对原 I/O 包中的流的模拟，负责传输；缓冲区用于容纳数据，负责存储，Channel的读写必须通过buffer对象，然后操作缓冲区，对数据进行处理。缓存区是双向的，既可以往缓冲区写入数据，也可以从缓冲区读取数据：缓冲区<->然后缓冲区通过通道进行传输<->从缓冲区取数据。选择器：把Channel通道注册到Selector中，通过Selecotr监听Channel中的事件状态，这样就不需要阻塞等待客户端的连接，从主动等待客户端的连接，变成了通过事件驱动，通过事件驱动实现单线程管理多个Channel的目的。

![700|450](%E9%9D%A2%E7%BB%8F.assets/0ece5d16ec1345a5b4dc2149cb5a8b40_tplv-k3u1fbpfcp-zoom-in-crop-mark_1304_0_0_0.webp)

缓冲区根据数据类型的不同，可以进行划分ByteBuffer、CharBuffer等。根据工作方式分：直接缓冲区(磁盘->内核地址空间中->用户地址空间中->读取到应用程序)与非直接缓冲区(将缓冲区建立在物理内存之中,读写数据直接通过物理内存进行)，

##### 上下文切换

https://zhuanlan.zhihu.com/p/52845869

* CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。

* 就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

* 进程上下文切换 ：所谓“进程上下文”，就是一个进程在执行的时候，CPU的所有寄存器中的值、进程的状态以及堆栈上的内容。进程是由内核来管理和调度的，进程的切换只能发生在内核态，进程的切换只能发生在内核态，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。（用户态-内核态-用户态）

* 线程上下文切换：当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

* 中断上下文切换：中断上下文”就是硬件通过触发信号，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。了快速响应硬件的事件，中断处理会打断进程的正常调度和执行，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

  ![700|400](%E9%9D%A2%E7%BB%8F.assets/2002319-20210104192307356-868531778.png)

##### 进程内存布局

* 程序段(Text):程序代码在内存中的映射，存放函数体的二进制代码。
* 初始化过的数据(Data):在程序运行初已经对变量进行初始化的数据。
* 未初始化过的数据(BSS):在程序运行初未对变量进行初始化的数据。
* 栈(Stack):存储局部、临时变量，函数调用时，存储函数的返回指针，用于控制函数的调用和返回。调用一个方法或函数会将一个新的栈帧（stack frame）压入到栈中，这个栈帧会在函数返回时被清理掉。由于栈中数据严格的遵守FIFO的顺序，这个简单的设计意味着不必使用复杂的数据结构来追踪栈中的内容，只需要一个简单的指针指向栈的顶端即可。在程序块开始时自动分配内存,结束时自动释放内存，其操作方式类似于数据结构中的栈。
* 堆 (Heap):堆用于存储那些生存期与函数调用无关的数据，存储动态内存分配,需要程序员手工分配,手工释放，需要精细的算法来应付我们程序中杂乱的分配模式，优化速度和内存使用效率。分配方式类似于链表，会产生内存碎片。

##### fork

* fork函数用于创建子进程，典型的调用一次，返回两次的函数，其中返回子进程的PID和0，其中调用进程返回了子进程的PID，而子进程则返回了0。

* 写时拷贝是一种可以推迟甚至避免拷贝数据的技术，资源的复制是在需要写入的时候才会进行（具体的操作大小是按着页控制的，只拷贝需要的页面），在此之前只有以只读方式共享，两者的虚拟空间不同，但其对应的物理空间是同一个。fork()的实际开销就是复制父进程的页表以及给子进程创建一个进程描述符。

  ![700|350](%E9%9D%A2%E7%BB%8F.assets/image-20220910231405571.png)



* fork：创造的子进程是父进程的完整副本，复制了父亲进程的资源，包括内存的内容task_struct内容
  vfork：创建的子进程共享了父进程的虚拟空间与父进程共享数据段，变量同步变化。子进程将先于父进程运行，子进程运行完毕才能运行父进程。
  clone：fork()是全部复制，vfork()是共享内存，而clone()是则可以将父进程资源有选择地复制给子进程，而没有复制的数据结构则通过指针的复制让子进程共享。

##### 操作系统功能

1、进程管理，其工作主要是进程调度，在单用户单任务的情况下，处理器仅为一个用户的一个任务所独占， 进程管理的工作十分简单。但在多道程序或多用户的情况 下，组织多个作业或任务时，就要解决处理器的调度、 分配和回收等问题 。

2、存储管理分为几种功能：存储分配、存储共享、存储保护 、存储扩张。

3、设备管理分为以下功能：设备分配、设备传输控制 、设备独立性。

4、文件管理：文件存储空间的管理、目录管理 、文件操作管理、文件保护。

5、作业管理是负责处理用户提交的任何要求。

##### 写文件

https://zhuanlan.zhihu.com/p/478988259

##### 用户态内核态切换

https://www.cnblogs.com/wangshaowei/p/14358774.html

##### 内核空间和用户空间

https://juejin.cn/post/6990237426903957540

##### 内存访问效率

利用好缓存：https://www.cnblogs.com/xiaolincoding/p/13836230.html
字节对齐：https://www.php.cn/faq/439694.html

* 数据缓存：遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处。
* 指令缓存：分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快。比如先排序再遍历(遍历中包含基于值得if判断)会快于先遍历再排序。
  
##### 高效利用缓存

https://blog.shuaijunlan.cn/2019/01/17/cpu-cache/

https://www.csdn.net/tags/NtTaUg5sMjYwMDMtYmxvZwO0O0OO0O0O.html

##### 顺序读、随机读

https://www.huoban.com/news/post/528.html

---

### Linux

##### 命令行

* 查看容器在宿主机上pid：docker container top container-id

* 查看端口占用：lsof -i，特定端口占用：lsof -i：port_num

* 查看进程：ps -aux,查看特定进程：ps -aux|grep keywords

* 内存：free：查看系统内存总体使用情况。top:用于实时显示进程的动态。/proc/meminfo: 查看RAM详细使用情况

* rwx:0-7,[拥有者，拥有者同组用户、其他用户]

* touch、tree、head、tail	;tar、mv、cp;chmod

* `df -h`:磁盘空间

* ls -lh:显示文件大小


----

### 数据库

##### 关系型非关系型

https://blog.nowcoder.net/n/cc0ee076fe7844acb0232381a18bf857

https://www.zhihu.com/question/350187680

##### 三范式

* 确保每列保持原子性。

  数据库表中的所有字段值都是不可分解的原子值：省份+城市+街道===>省份|城市|街道

* 确保表中的每列都和主键相关。

  确保数据库表中的每一列都和主键相关，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。

* 确保每列都和主键列直接相关,而不是间接相关。

  订单表种将客户编号和商品编号作为一个外键建立相应的关系。而不可以在订单表中添加关于客户和商品的具体信息。

##### 流程

![700|575](%E9%9D%A2%E7%BB%8F.assets/1066538-20201016015745814-1815633939.png)

* 连接器：负责与客户端的通信；验证请求用户的账户和密码是否正确。
* 分析器的：解析sql语句的语法和语义，检查语法错误、表、字段是否存在，并进行关键词和非关键词进行提取、解析，并组成一个解析树。
* 优化器：根据执行计划进行最优的选择,匹配合适的索引,选择最佳的执行方案（最左匹配条件换序、where上移）
* 执行器：调用存储引擎的API，执行语句。
* undo log：记录每行数据事务执行前的数据。主要作用是用于实现MVCC版本控制，保证事务隔离级别的读已提交和读未提交级别。
* 两阶段提交

##### ACID

原子性（ Atomicity ）、一致性（ Consistency ）、隔离性（ Isolation ）和持续性（ Durability ）。事务中的所有操作要么全部执行，要么都不执行。⑴ 原子性：全部成功/全部失败回滚⑵ 数据库的完整性不会因为事务的执行而受到破坏，一致性一致性状态变换到另一个一致性状态(2000+3000=1000+4000)。⑶ 隔离性并发多事务间无干扰（T1/T2=>T1+T2，T2+T1）⑷ 持久性：事务提交改变永久。

##### 隔离特性

* 脏读：一个事务处理过程里读取了另一个未提交的事务中的数据、注意回滚。读取了另一个事务未提交的脏数据。不加锁，直接读取最新的数据。

  不可重复读：一个事务范围内多次查询却返回了不同的数据值。读取了前一事务提交的数据。重点是修改数据。

  幻读：读取了另一条已经提交的事务。幻读就是没有读到的记录，以为不存在，但其实是可以更新成功的，并且更新成功后，再次读取，就出现了。重点是增加数据。

* 串行化：可避免脏读、不可重复读、幻读的发生，读加共享锁，写加排它锁，避免并行访问。

  可重复读：可避免脏读、不可重复读的发生，MySQL默认级别，事务一开始就构建要用到的数据的视图。InnoDB 通过next-key lock 锁（行锁和间隙锁的组合）来锁住记录之间的“间隙”和记录本身，防止其他事务在这个记录之间插入新的记录，这样就避免了幻读现象。

  读已提交： 允许读取并发事务已经提交的数据，可避免脏读的发生。每次执行sql语句的时候都重新生成视图。

  读未提交：允许读取尚未提交的数据，最低级别，任何情况都无法保证，无视图，直接到数据库中读取。

* 快照读取规则：当前事务内的更新，可以读到；版本未提交，不能读到；版本已提交，但是却在快照创建后提交的，不能读到；版本已提交，且是在快照创建前提交的，可以读到；

##### 分布式事务

https://zhuanlan.zhihu.com/p/183753774

https://juejin.cn/post/6844903647197806605

CAP：一致、可达、分区容错。分区通信失败无法避免，P总是成立：当节点和节点之间的通信出现了问题，就称当前的分布式存储系统出现了分区，布式存储系统还能够继续运行。C：节点A修改后其它节点B读出来的也是新值，对此A 必须在写操作时，锁定B的读操作和写操作，只有数据同步后，才能重新开放B读写。锁定期间，B 不能读写，没有可用性。A：节点都可访问，为保证B的可用性，那么势必不能锁定 B，所以一致性不成立。

BASE ：Basically Available(基本可用)、Soft state(软状态)和 Eventually consistent (最终一致性)。是对CAP中AP的一个扩展

1. 基本可用:分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。
2. 软状态:允许系统中存在中间状态，这个状态不影响系统可用性，这里指的是CAP中的不一致。
3. 最终一致:最终一致是指经过一段时间后，所有节点数据都将会达到一致。




* 两阶段提交

  第一阶段（prepare）：即所有的参与者准备执行事务并锁住需要的资源。参与者ready时，向管理者报告已准备就绪。第二阶段 (commit/rollback)：当事务管理者确认所有参与者都ready后，向所有参与者发送commit命令。如果有任何一个参与者prepare失败，那么管理者会通知所有完成prepare的参与者进行回滚。

  单点问题:事务管理器如果其宕机，造成资源管理器就会一直阻塞，导致数据库无法使用。同步阻塞:在准备就绪之后，资源管理器中的资源一直处于阻塞，直到提交完成，释放资源。数据不一致:两阶段提交协议虽然为分布式数据强一致性所设计，但仍然存在数据不一致性的可能，比如在第二阶段中，假设协调者发出了事务commit的通知，但是因为网络问题该通知仅被一部分参与者所收到并执行了commit操作，其余的参与者则因为没有收到通知一直处于阻塞状态，这时候就产生了数据的不一致性。

  尽量保证强一致性的分布式事务，因此它是同步阻塞的，而同步阻塞就导致长久的资源锁定问题，总体而言效率低，并且存在单点故障问题，在极端条件下存在数据不一致的风险。适用于数据库层面的分布式事务场景，无法做到业务层面事务。

* 三阶段提交：3PC 包含了三个阶段，分别是准备阶段、预提交阶段和提交阶段。准备阶段协调者只是询问参与者的自身状况，是否满足业务需求，避免使得在某些资源不可用的情况下所有参与者都阻塞着。预提交阶段自行事务但是不提交。提交阶段用于提交事务。

  引入了超时机制：如果是等待提交命令超时，那么参与者就会提交事务了；如果是等待预提交命令超时，本身未执行操作，不进行任何处理。

  多引入一个阶段也多一个交互，因此性能会差一些，而且绝大部分的情况下资源应该都是可用的，这样等于每次明知可用执行还得询问一次。超时机制也会带来数据不一致的问题，在等待提交命令时候超时了，参与者默认执行的是提交事务操作，但是有可能执行的是回滚操作，这样一来数据就不一致了。

  强一致性事务，适用于数据库层面的分布式事务场景，无法做到业务层面事务。

  



![700|325](%E9%9D%A2%E7%BB%8F.assets/bVcTlFw.webp)

* TCC

  Try阶段：尝试执行,完成所有业务检查（一致性）,预留必须业务资源（准隔离性）

  Confirm阶段：确认执行真正执行业务，不作任何业务检查，只使用Try阶段预留的业务资源，Confirm操作满足幂等性。要求具备幂等设计，Confirm失败后需要进行重试。

  Cancel阶段：取消执行，释放Try阶段预留的业务资源 Cancel操作满足幂等性Cancel阶段的异常和Confirm阶段异常处理方案基本上一致。

  协调者单点：业务活动管理器也变成多点，引入集群。同步阻塞:引入超时，超时后进行补偿，并且不会锁定整个资源，粒度变小。 数据一致性，有了补偿机制之后，由业务活动管理器控制一致性。

  适合一些强隔离性，严格一致性要求的活动业务。执行时间较短的业务。TCC 是业务层面的分布式事务。

  ![700|400](%E9%9D%A2%E7%BB%8F.assets/image-20221003003214030.png)

* 本地消息表

  将需要分布式处理的任务通过消息日志的方式来异步执行。将业务的执行和将消息放入消息表中的操作放在同一个事务中，保证消息放入本地表中业务肯定是执行成功的，消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试（定时扫描未成功处理的消息，进行重新发送；接到消息之后，首先判断是否是重复的，防止重复消费）

  本地消息队列是BASE理论，是最终一致模型，适用于对一致性要求不高的。实现这个模型时需要注意重试的幂等。

  

  ![700|450](%E9%9D%A2%E7%BB%8F.assets/image-20221003003254530.png)

* MQ事务：是对本地消息表的一个封装，将本地消息表移动到了MQ内部。先给 Broker 发送事务消息即半消息，半消息对消费者来说不可见，然后发送成功后发送方再执行本地事务，再根据本地事务的结果向 Broker 发送 Commit 或者 RollBack 命令。如果是 Commit 那么订阅方就能收到这条消息，然后再做对应的操作，做完了之后再消费这条消息即可。如果是 RollBack 那么订阅方收不到这条消息，等于事务就没执行过。

  属于最终一致性事务，因此适用于一些对时间不敏感的业务。

  ![700|450](%E9%9D%A2%E7%BB%8F.assets/image-20221003010811250.png)

* Saga事务：将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。每个Ti 都有对应的补偿动作Ci，补偿动作用于撤销Ti造成的结果（T1, T2, T3, ..., Tn；

  T1, T2, ..., Tj, Cj,..., C2, C1）。这里的每个T都是一个本地事务。 和TCC相比，Saga没有“预留 try”动作，它的Ti就是直接提交到库，不能保证隔离性，因为没有锁住资源（可以在业务层面通过预先冻结资源的方式隔离这部分资源）。

  



##### 引擎

* MyISAM：不支持事务，不支持外键，访问速度快，B+Tree 作为索引结构，索引和数据文件是分离的，能加载更多索引；支持表级锁，并发度有限；可以没有主键；存储表的元数据如总行数（row），查询快速。
* InnoDB：对事务的完整性有比较高的要求，更新密集的表，适合处理多重并发的更新请求；事务，默认的事务隔离级别为可重复读（REPEATABLE-READ），通过MVCC（并发版本控制）来实现；支持在线热备，有很成熟的在线热备解决方案；外键约束；支持自动增加列AUTO_INCREMENT属性；B+树构建索引，主键索引的叶子节点就是数据文件；支持表、行级锁，可以支持更高的并发；必须有唯一索引（如主键）；DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除。
* Memory：用在那些内容变化不频繁的代码表，或者作为统计操作的临时中间结果表，将数据存在内存，为了提高数据的访问速度，不支持事务，支持的数据类型有限制，不支持TEXT、VARCHAR；支持的锁粒度为表级锁。由于数据是存放在内存中，数据断电丢失；默认使用hash索引；对表的大小有要求，不能建立太大的表。


##### 外键

使两张表形成关联，外键只能引用外表中的主键的值。触发限制: 删除、更新。

##### 事务

日志文件 (redo log 和 undo log)，锁技术以及 MVCC

* 为了提升性能不会把每次的修改都实时同步到磁盘，然后使用后台线程去做缓冲池和磁盘之间的同步。更新数据到内存中->写redo log，prepare态->写bin log->事务提交 redo log变为commit态->写入磁盘。两阶段提交保证两份日志保持一致，当在写binlog之前崩溃时重启恢复后发现没有commit，回滚。当在commit之前崩溃,重启虽没有commit，但满足prepare和binlog完整，所以重启后会自动commit。系统对binlog定期做整库备份，崩溃时读取binlog进行恢复。用于保障已提交事务的持久化特性。
* undo log 提供了回滚和多个行版本控制（MVCC），对记录做变更操作时不仅会产生 redo 记录，也会产生 undo 记录，存放数据被修改前的值,用于在发生错误时才可以回滚。mvcc当读取的某一行被其他事务锁定时，它可以根据事务id从 undo log 中获取该行记录以前的数据是什么，从而提供该行版本信息。读写锁：读锁是可以共享的，写锁会排斥其他所有获取锁的请求。
* 事务的原子性是通过 undo log 来实现的；事务的持久性性是通过 redo log 来实现的；事务的隔离性是通过 (读写锁 + MVCC) 来实现的；事务的一致性是通过原子性，持久性，隔离性来实现的。

##### MVCC

Read View 有四个重要的字段：

![700|450](%E9%9D%A2%E7%BB%8F.assets/11a65cbc2e97f6855d7692a265dc2651.png)

索引记录中都包含下面两个隐藏列：trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里；roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。

如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。

如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中：如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。

read uncommitted可以直接读脏数据，读版本链最开始的记录就可以了，不需要读旧版本信息，不需要MVCC。读已提交每次读取生成视图，遍历你是记录，读取生成视图时的已提交数据。重复度下一直使用启动事务时的视图，保证之后读取的数据和启动事务时一致。serializable需要对读加锁，版本链最开始的记录就是需要的数据，不需要应用多版本信息。

##### 幻读解决

MySQL 里除了普通查询是快照度，其他都是当前读，比如update、insert、delete，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。所以可重复读下更新数据是当前度，会读取其它事务提交的数据。

Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了 next-key 锁，就是记录锁和间隙锁的组合。记录锁，锁的是记录本身；间隙锁，锁的就是两个值之间的空隙，以防止其他事务在这个空隙间插入新的数据，从而避免幻读现象。

##### 锁

全局锁、表级锁和行锁三类

1，全局锁：整个数据库就处于只读状态了，这时其他线程执行数据的增删改、表的增删改操作，都会被阻塞。全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。

如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。

2，表级锁：

表锁：共享锁，也就是读锁；独占锁，也就是写锁；表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。表锁的颗粒度太大，会影响并发性能。读-读共享，读-写、写-写互斥。

元数据锁：当我们对数据库表进行操作时，会自动给这个表加上 MDL：对一张表进行 CRUD 操作时，加的是 MDL 读锁；对一张表做结构变更操作的时候，加的是 MDL 写锁；MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。读-读共享，读-写、写-写互斥。长事务A获得读锁，事务B更改表结构尝试获得写锁被阻塞，后续即使是只获取读锁的事务也会被阻塞，因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。

意向锁：当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。

3，行锁：对记录加锁时，加锁的基本单位是 next-key lock，它是由记录锁和间隙锁组合而成的。

唯一索引字段等值查询：

- 当查询的记录是存在的，next-key lock 会退化成「记录锁」。
- 当查询的记录是不存在的，next-key lock 会退化成「间隙锁」。

非唯一索引字段等值查询：

- 当查询的记录存在时，除了会加 next-key lock 外，还额外加间隙锁，也就是会加两把锁。
- 当查询的记录不存在时，只会加 next-key lock，然后会退化为间隙锁，也就是只会加一把锁。

非唯一索引和主键索引的范围查询的加锁规则不同之处在于：

- 唯一索引在满足一些条件的时候，next-key lock 退化为间隙锁和记录锁。
- 非唯一索引范围查询，next-key lock 不会退化为间隙锁和记录锁。

##### update

InnoDB 存储引擎的默认事务隔离级别是「可重复读」， InnoDB 通过 next-key 锁（记录锁和间隙锁的组合）来锁住记录本身和记录之间的“间隙”，防止其他事务在这个记录之间插入新的记录，从而避免了幻读现象。

当执行 update 语句时，实际上是会对记录加独占锁（X 锁）的，如果其他事务对持有独占锁的记录进行修改时是会被阻塞的。另外这个锁并不是执行完 update 语句就会释放的，而是会等事务结束时才会释放。

在 update 语句的 where 条件使用了唯一索引，那么 next-key 锁会退化成记录锁，也就是只会给一行记录加锁。在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。

update 语句必须使用 where，并且 where 条件中必须有索引列；并且在测试机确认该语句是否走的是索引扫描，防止因为扫描全表，而对表中的所有记录加上锁。开启MySQL sql_safe_updates 参数，这样可以预防 update 操作时 where 条件没有带上索引列。

##### 死锁

1，可重复读隔离级别下，是存在幻读的问题。Innodb 引擎为了解决「可重复读」隔离级别下的幻读问题，就引出了 next-key 锁，它是记录锁和间隙锁的组合。

表中保存id<=100的数据，事务A尝试插入101，向使用select for update查询101数据是否已经存在，不存在再插入，事务B尝试插入102，流程与A相同。A查询时101不是唯一值索引，所以行锁的类型是间隙锁，于是间隙锁的范围是（100, +∞），由于间隙锁与间隙锁之间是兼容的，B在查询后使用间隙锁锁住（100，+∞）。当A插入数据时，会在插入间隙上再次获取插入意向锁，插入意向锁与间隙锁是冲突的，所以需要等待事务B释放间隙锁之后，才能获取到插入意向锁。同理当B插入数据时，需要等待事务A释放间隙锁之后，才能获取到插入意向锁。

2，设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。

##### 索引种类

https://developer.huawei.com/consumer/cn/forum/topic/0204405591412170236

* 按数据结构分类可分为：B+tree索引、Hash索引、Full-text索引。

  > 1，B+树，多叉树访问非叶节点少，减少磁盘访问。一个索引对应一棵 B+ 树，主键索引的叶子节点存的是整行数据，非主键索引的叶子节点内容是主键的值（找到后到ID索引树搜索一次），主键索引树占用存储与主键大小有关，二级索引树占用大小与索引列和主键列大小有关，自增主键。避免回表：查询字段为id和索引字段；复合字段索引，将经常访问的多个字段构建索引。
  >
  > 2，Hash 索引<索引列，行指针>，优点：快速、适合等值查询；缺点：范围查询、哈希冲突回表、不能利用部分索引键查询。
  >
  > 3，Full-text索引：大量的文本数据检索，键字的匹配来进行查询过滤，那么就需要基于相似度的查询，而不是原来的精确数值比较。全文索引在大量的数据面前，能比 like + % 快 N 倍。
  >
  > https://blog.csdn.net/belongtocode/article/details/102990112
  >
  > https://cloud.tencent.com/developer/article/1658694
  >
  > ```sql
  > create fulltext index idx_name on table_name(field0,field1);
  > select * from table_name where match(field0,field1) against('str');
  > ```
  >
  > 正排表是以文档的ID为关键字，表中记录文档中每个字的位置信息，查找时扫描表中每个文档中字的信息直到找出所有包含查询关键字的文档。建立比较方便且易于维护;查询的时候需对所有的文档进行扫描以确保没有遗漏，检索效率低下。
  >
  > 倒排表以字或词为关键字进行索引，表中关键字所对应的记录表项记录了出现这个字或词的所有文档，一个表项就是一个字表段，它记录该文档的ID和字符在该文档中出现的位置情况，full inverted index，其表现形式为{单词，（单词所在文档的ID， 再具体文档中的位置）}，相关度是基于匹配的关键词的个数，以及关键词在文档中出现的次数。在整个索引中出现次数越少的词语，匹配时的相关度就越高。倒排表的建立和维护都较为复杂，但是在查询的时候由于可以一次得到查询关键字所对应的所有文档，所以效率高于正排表。

* 按物理存储分类可分为：聚簇索引、二级索引（辅助索引）。

##### 最左匹配原则

* 最左匹配原则：如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到，同时遇到范围查询(>、<、between、like)就会停止匹配。这里可以看出 a 是有序的，而 b，c 都是无序的。但是当在 a 相同的时候，b 是有序的，a,b 相同的时候，c 又是有序的。所以查询a=0,b=1,c=2时，过滤完a=0的数据后b有序，过滤完b=1数据后c有序，可以利用到abc的索引。a=0,b>1,c=2经过a,b过滤后c无需，只能用到索引a,b。![700|500](%E9%9D%A2%E7%BB%8F.assets/1804577-20200521182659976-48843100.png)


##### 联合索引 

* 减少开销。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销。

* 覆盖索引。对联合索引(col1,col2,col3)，如果有如下的sql: select col1,col2,col3 from test where col1=1 and col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。

* 效率高。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w10% 10% *10%=1w，效率提升可想而知！

##### 索引优化

* 如果查询语句中的where、order by、group 涉及多个字段，一般需要创建多列索引。
* 更新十分频繁、数据区分度不高的列不宜建立索引，一般情况下，把选择性区分度高的字段放在前面，过滤后剩下更少数据（age/gender）。
* 避免使用范围查询很多情况下，范围查询都可能导致无法使用索引。
* 尽量避免查询不需要的数据（回表）。
* 最左前缀匹配原则，
* 索引列不能参与计算（隐式类型转换）
* 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

##### 级联查询

先确定所连接的表，再确定所要查询的字段，确定连接条件以及连接方式

* inner join返回两个表基于连接条件实际匹配的行，即两个表交集，先笛卡尔积再过滤。outer join返回两个表的并集结果，即匹配条件不满足的两个表的记录也将返回，mysql没有outer join 相关语句，但可以对left join和right join的结果用union连接来实现。

  ```sql
  select a.v1,b.v2 from A as a inner join B as b on a.ID = b.ID;
  ```
  
* left join表示左侧表所有记录都将返回，并且不满足匹配条件的右侧连接表记录将返回null。

  先笛卡尔积，再过滤，如果左分组存在满足条件的行该分组结束，如果不存在，返回只包含左式的行。

  ```sql
  select a.v1,b.v2 from A as a left join B as b on a.ID = b.ID;
  select a.v1,b.v2 from A as a left join B as b on a.ID = b.ID where b.ID=null;
  ```

* right join与left join恰恰相反，表示右侧表所有记录都将返回，并且不满足匹配条件的左侧连接表记录将返回null。

  ```sql
  select a.v1,b.v2 from A as a right join B as b on a.ID = b.ID;
  select a.v1,b.v2 from A as a right join B as b on a.ID = b.ID where a.ID=null;
  ```
  
* 外联，Mysql不支持外联，使用uinon替代

  ```sql
  select
      t1.value1, t2.value2
  from t1
  left join t2
    on t1.id1 = t2.id2
  union all      -- union 会去重，uinon all保留重复项
  select
      t1.value1, t2.value2
  from t2
  left outer join t1
    on t1.id1 = t2.id2
  where
      t1.value1 = NULL
      
  select
      t1.value1, t2.value2
  from t1
  left join t2
    on t1.id1 = t2.id2
  where
       t2.value2=null
  union all      -- union 会去重，uinon all保留重复项
  select
      t1.value1, t2.value2
  from t2
  left outer join t1
    on t1.id1 = t2.id2
  where
      t1.value1 = NULL
  ```





![700|425](%E9%9D%A2%E7%BB%8F.assets/20841286-f8e223bfa2c187f9.webp)

##### 查询缓慢

1，偶尔慢：

* 数据库会在内存中把对应字段的数据更新了，并把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到磁盘中去。如果更新很频繁，这个时候 redo log 很快就会被写满了，需要立即把数据同步到磁盘的，只能暂停其他操作，就会导致我们平时正常的SQL语句突然执行的很慢。

* 语句涉及到的表锁或者行锁，并且被别人占据，只能慢慢等待别人释放锁了。使用`show processlist`命令来查看当前的状态哦。

2，频繁慢

* 字段没有索引：刚好查询的字段上没有索引，只能走全表扫描了，导致这条查询语句很慢。建立字段索引字段；复合字段索引，将经常访问的多个字段构建索引。
* 字段有索引，但却没有用索引：在字段的左边做了运算或者使用函数（where x-1>1000，where f(x)>1000），在查询的时候就不会用上索引，从 MySQL 8.0 开始，索引特性增加了函数索引，即可以针对函数计算后的值建立一个索引，也就是说该索引的值是函数计算后的值，所以就可以通过扫描索引来查询数据；对索引隐式类型转换，比如索引字段是字符串类型，但是在条件查询中输入的参数是整型的话， MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较，也就是对索引使用了函数。
* 字段有索引，但却没有用索引：左或者左右模糊匹配（like ‘%x’，like ‘%x%’，因为索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较）；
* 字段有索引，但却没有用索引：在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。这是因为 OR 的含义就是两个只要满足一个即可，因此只有一个条件列是索引列是没有意义的，只要有条件列不是索引列，就会进行全表扫描。
* 字段有索引，但却没有用索引：非主键索引保存主键，需要到主键索引树中查询（回表），需要两次查询，如果所有行都匹配查询结果，就相当于全表扫描，并且每行数据走了两次索引，引擎会判断认为走两次所用还不如直接全表扫描开销小。系统是通过索引的区分度来判断的，一个索引上不同的值越多，意味着出现相同数值的索引越少，意味着索引的区分度越高，满足查询条件的数据越少，意味着走索引查询越有优势。通过采样的方式，来预测索引的区分度，由于统计的失误，导致区分度估计偏小，导致系统没有走索引，而是走了全表扫描。强制走索引：`select * from t force index(x) where x < 100 ;`，重新进行抽样：`analyze table t;`

##### B树、B+树

* B树是一颗多路平衡查找树：阶数m，每个节点最多有m-1个关键字，非根节点至少有m/2个关键字。每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。

* B+树：非根节点元素范围：m/2 <= k <= m-1；内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。当节点元素数量大于m-1的时候，按中间元素分裂成左右两部分，中间元素分裂到父节点当做索引存储，上移，高度增加。删除操作导致数量<m/2时，如果兄弟节点的元素大于m/2，可以直接通过兄弟节移动，然后更新父节点的索引，如果兄弟节点的元素不大于m/2，则将当前节点和兄弟节点合并，并且删除父节点中的key，上移，高度减少。

* B+树优势：非叶子结点只保存指针，所有关键字都在叶子结点，非叶子结点存储的元素更多，使得查询的IO次数更少。所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。所有的叶子节点形成了一个有序链表，更加便于查找（区间查询： 查询5-10，把到5这个标记，再找到10，然后串起来就行了），用 B 树来做范围查询的话，需要使用中序遍历。

  <img src="%E9%9D%A2%E7%BB%8F.assets/1460000020416603.webp" alt="10" style="zoom:50%;" />

##### B+树

why：要能高效地查询某一个记录，也要能高效地执行范围查找->按ID排序，二分查找->二叉查找树，通过分层来降低每一层的搜索量O(log(N))，因为查找树是一个跳跃结构，不必连续排列，插入的时候元素不需要向后排列-> 为防止每次插入的元素都是查找树中最大的元素，二叉查找树就会退化成了一条链表O(N)，平衡查找树O(log(N))->InnoDB 的数据是按「数据页」为单位来读写的，以页为单位将其整体读入内存。IO次数为树高，因此在构造索引的时候，我们更倾向于采用 “矮胖” 的 树数据结构->只有叶子节点（最底层的节点）才存放了数据，非叶子节点（其他上层节）仅用来存放目录项作为索引，所有节点按照索引键大小排序，构成一个双向链表，便于范围查询；

B+树相比B树优势：非叶子结点只保存指针，所有关键字都在叶子结点，非叶子结点存储的元素更多，因此 B+ 树可以比 B 树更「矮胖，使得查询的IO次数更少。所有的查询都要查找到叶子节点，查询性能是稳定的，而B树，每个节点都可以查找到数据，所以不稳定。所有的叶子节点形成了一个有序链表，更加便于查找（区间查询： 查询5-10，把到5这个标记，再找到10，然后串起来就行了），用 B 树来做范围查询的话，需要使用中序遍历。B 树没有冗余节点，删除节点的时候非常复杂，B+ 树有大量的冗余节点，这样使得删除一个节点的时候，可以直接从叶子节点中删除，甚至可以不动非叶子节点，这样删除非常快，

##### count

1，`count()` 是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 `NULL `的记录有多少个。

2，`count(*) `其实等于` count(0)`，MySQL 会将 `*` 参数转化为参数 0 来处理，不会去读取数据。

`count(1)`、` count(*)`、` count(主键字段)`在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描，因为相同数量的二级索引记录可以比聚簇索引记录占用更少的存储空间。`count(*)`和`count(1)`不会读取记录中的任何字段的值，因为0,1明显非null。`count(id)`：InnoDB 循环遍历聚簇索引，将读取到的记录返回给 server 层，然后读取记录中的 id 值，就会 id 值判断是否为 `NULL`，如果不为 `NULL`，就将 count 变量加 1。

` count(字段) `的效率是最差的，会采用全表扫描的方式来统计。

`count(*)=count(1)>count(id)>count(字段)`

3，优化：第一种，近似值，对于统计个数不需要很精确，`show table status `。第二种，额外表保存计数值， MyISAM 的数据表都有一个 meta 信息有存储了row_count值，手动维护这个计数表，在新增和删除操作时，进行+1，-1操作。

##### 数据页

1，页 是InnoDB存储引擎管理数据库的最小磁盘单位，一个页的大小一般是16KB。一次至少读取一页的数据到内存，或者刷新一页的数据到磁盘。

![700|375](%E9%9D%A2%E7%BB%8F.assets/image-20220911105518442.png)

InnoDB 是以页为单位存放数据的，InnoDB 表是索引组织的表，数据是按主键顺序存放的。数据可能会分散到多个不连续的页中存储，这时就会通过 FIL_PAGE_PREV 和 FIL_PAGE_NEXT 将上一页和下一页连起来，就形成了一个双向链表。这样就通过一个双向链表把许许多多的页就都串联起来了，而无需这些页在物理上真正连着。

![700|450](%E9%9D%A2%E7%BB%8F.assets/image-20220911110210428.png)

User Records、Free Space、Page Directory 这些部分为实际的行记录存储空间。next_record 指向的是记录头与数据之间的位置偏移量，单向链表串联页内每一行的记录数据。这个位置向左读取就是记录头信息，向右读取就是真实数据。

![700|475](%E9%9D%A2%E7%BB%8F.assets/image-20220911105905145.png)

页面与页面双向链表连接，页内记录与记录单向链表连接。

![700|550](%E9%9D%A2%E7%BB%8F.assets/image-20220911111738448.png)

查找时定位到页之后通过`next_record`沿着链表一直往后找，时间复杂度高。页中的数据其实是分为多个组的，槽就存放了每个组中最大的那条记录的相对位置，形成一个子目录，通过子目录就能缩小查询的范围，提高查询性能了。查找数据时，利用二叉查找从页目录中找到主键值比本记录的主键值大并且差值最小的槽，并找到该槽所在分组中主键值最小的那条记录，再通过最小记录的 next_record 遍历记录，就能快速定位到匹配的那条记录了。

![700|475](%E9%9D%A2%E7%BB%8F.assets/image-20220911112736684.png)

##### sql编写

https://www.cnblogs.com/jpfss/p/6613611.html

*  找到第K大：包含重复值`select salary from Employee order by salary desc limit 1 offset k-1;`，不包含重复值：` select distinct salary from Employee order by salary desc limit 1 offset k-1;`

##### 索引下推

https://www.cnblogs.com/three-fighter/p/15246577.html

##### explain

https://www.cnblogs.com/acm-bingzi/p/mysqlExplain.html

##### #{}、${}

https://www.cnblogs.com/liaowenhui/p/12217959.html


- `#{}` 是更安全的占位符语法，适用于大多数情况下，`MyBatis`在处理`#{}`时，会将SQL中的`#{}`替换为`?`号，使用`PreparedStatement`的`set`方法来赋值，可以保证参数值的类型安全和 SQL 注入防护。

  `SELECT * FROM users WHERE username = #{username} AND age = #{age}`

- `${}` 是一种更原始的占位符语法，适用于需要更灵活的动态 SQL 拼接，但需要开发者自行确保参数值的安全性。

  `SELECT * FROM ${tableName} WHERE ${columnName} = ${value}`

##### 权限管理

https://help.aliyun.com/document_detail/183354.html

https://www.cnblogs.com/richardzhu/p/3318595.html

##### Mybatis 扩展

https://blog.51cto.com/u_14969174/2547322

##### 数据库优化

https://juejin.cn/post/6844904038459244552

https://www.51cto.com/article/709910.html

https://www.zhihu.com/question/36431635

##### 分库分表

https://www.51cto.com/article/709614.html

分库主要解决的是并发量大的问题。因为并发量一旦上来了，那么数据库就可能会成为瓶颈，因为数据库的连接数是有限的，分表其实主要解决的是数据量大的问题。

拆分的时候有两种分法，分别是横向拆分(水平拆分)和纵向拆分(垂直拆分)。假如我们有一张表，如果把这张表中某一条记录的多个字段，拆分到多张表中，这种就是纵向拆分。那如果把一张表中的不同的记录分别放到不同的表中，这种就是横向拆分。

在分表的过程中，我们需要有一个字段用来进行分表，常建议大家按照买家Id进行分表。因为这样可以避免一个关键的问题那就是数据倾斜(热点数据)。一个大的卖家可能会产生很多订单，得有一些表的数据量非常的大，但是有些表的数据量又很小，这就是发生了数据倾斜，而不太容易出现一个买家能把数据买倾斜了。买家ID的一致性Hash确定所在表。

买家来查询的时候，是一定可以把买家ID带过来的，我们直接去对应的表里面查询就行了。卖家查询的话，同样可以带卖家id过来，那么，我们可以有一个基于binlog、flink等准实时的同步一张卖家维度的分表，这张表只用来查询，来解决卖家查询的问题。按照订单查询，在生成订单号的时候，我们一般会把分表解决编码到订单号中去。

全局ID的生成：多张单表中的自增主键就一定会发生冲突，可以每个表设置ID起始位置和终止位置。雪花算法也是比较常用的一种分布式ID的生成方式，它具有全局唯一、递增、高可用的特点。雪花算法生成的主键主要由 4 部分组成，1bit符号位、41bit时间戳位、10bit工作进程位以及 12bit 序列号位。

做了分库分表之后，所有的读和写操作，都需要带着分表字段，这样才能知道具体去哪个库、哪张表中去查询数据。如果不带的话，就得支持全表扫描。一旦我们要从多个数据库中查询或者写入数据，就有很多事情都不能做了，比如跨库事务就是不支持的。

##### 主从复制

https://www.cnblogs.com/rickiyang/p/13856388.html

0，架构：一主一从 / 一主多从； 多主一从（将多个库的数据备份到一个库中存储）；双主复制（两个MySQL服务器互做对方的从，任何一方有变更，都会复制对方的数据到自己的数据库）

1，过程

在从节点上执行 `sart slave` 命令开启主从复制开关，开始进行主从复制。从节点上的 I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容。

主节点接收到来自从节点的 I/O 请求后，通过负责复制的 I/O 进程（log Dump Thread）根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的 Binlog file 以及 Binlog position（Binlog 下一个数据读取位置）。

从节点的 I/O 进程接收到主节点发送过来的日志内容、日志文件及位置点后，将接收到的日志内容更新到本机的 relay log 文件（Mysql-relay-bin.xxx）的最末端，并将读取到的 Binlog文件名和位置保存到`master-info` 文件中，以便在下一次读取的时候能够清楚的告诉 Master ：“ 我需要从哪个 Binlog 的哪个位置开始往后的日志内容，请发给我”。

Slave 的 SQL 线程检测到relay log 中新增加了内容后，会将 relay log 的内容解析成在能够执行 SQL 语句，然后在本数据库中按照解析出来的顺序执行，并在 `relay log.info` 中记录当前应用中继日志的文件名和位置点。

![700|475](%E9%9D%A2%E7%BB%8F.assets/image-20221010161818482.png)

2，异步模式 ：主节点不会主动推送数据到从节点，主节点如果崩溃掉了，此时主节点上已经提交的事务可能并没有传到从节点上，如果此时，强行将从提升为主，可能导致新主节点上的数据不完整。

半同步模式(semi-sync)：主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到 relay log 中才返回成功信息给客户端，提高了数据的安全性，造成了一定程度的延迟。

全同步模式：指当主库执行完一个事务，然后所有的从库都复制了该事务并成功执行完才返回成功信息给客户端。因为需要等待所有从库执行完该事务才能返回成功信息，所以全同步复制的性能必然会收到严重的影响。

3，问题

Slave 同步延迟：Master 端写 Binlog 由于是顺序写效率很高， Master 端的写效率要高过 Slave 端的读效率，这时候就有同步延迟的问题。基于组提交的并行复，并发执行 relay log 中主库提交的事务，提高效率。

5，GTID复制：从库会告知主库已经执行的事务的 GTID 的值，然后主库会将所有未执行的事务的 GTID 的列表返回给从库，并且可以保证同一个事务只在指定的从库执行一次，通过全局的事务 ID 确定从库要执行的事务的方式代替了以前需要用 Binlog 和 位点确定从库要执行的事务的方式。

master 更新数据时，会在事务前产生 GTID，一同记录到 Binlog 日志中。slave 端的 I/O 线程将变更的 Binlog，写入到本地的 relay log 中,读取值是根据`gitd_next变量`，告诉我们 slave 下一个执行哪个 GTID。SQL 线程从 relay log 中获取 GTID，然后对比 slave 端的 Binlog 是否有记录。如果有记录，说明该 GTID 的事务已经执行，slave 会忽略。如果没有记录，slave 就会从 relay log 中执行该 GTID 的事务，并记录到 Binlog。在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有二级索引就用全部扫描。

6，canal：canal 伪装自己为 MySQL slave ，向 MySQL master 发送dump 请求，获得并解析binary log 备份。自行建立canal客户端，从canal中获取数据，通过消息队列并将数据更新至Redis.

##### 崩溃恢复

https://segmentfault.com/a/1190000039180234

* MySQL 的 bug：检查一下 MySQL 的 bug 库，找到了可能与你相关的 bug，确认它是否修复了。

* mysql 申请系统资源失败：系统内存不足（错误日志查找各部分内存占用）；磁盘空间满了。

* 两阶段提交保障数据一致性，假设Redo Log刷入成功了，但是还没来得及刷入Binlog MySQL就挂了。此时重启之后会发现Redo Log并没有Commit标识，此时根据记录的XA事务找到这个事务，进行回滚。如果Redo Log刷入成功，而且Binlog也刷入成功了，但是还没有来得及将Redo Log从Prepare改成Commit MySQL就挂了，此时重启会发现虽然Redo Log没有Commit标识，但是通过XID查询到的Binlog却已经成功刷入磁盘了，MySQL也要提交这个事务。

  重放Redo Log，将数据文件更新到尽可能最新的状态，提交没有提交成功的事务。同时一会把Undo Log初始化到崩溃前的状态，最后再将所有为未提交的事务用Undo Log回滚。

##### 慢SQL

https://www.cnblogs.com/kerrycode/p/5593204.html

https://cloud.tencent.com/developer/article/1545163

* explain查询统计
* https://www.cnblogs.com/xuanzhi201111/p/4175635.html

![700|1000](%E9%9D%A2%E7%BB%8F.assets/image-20221011224620955.png)

原因：未用到索引、回表、去重、排序、多表内联（拆分后union）、索引区分度低、字段比较多（垂直分表）、多表联合查询（中间表）、limit偏移量太大（将偏移量条件加到where查询）

##### 调优

1，合理加索引（太长的列建立前缀索引、索引更新不能频繁、索引列不能参与计算、索引区分度低）、联合索引、最左匹配覆盖索引、避免模糊查询

2，分库分表、读写分离、缓存、RAID、

3，慢日志记录、脏页buffer_pool_size刷盘频率、

##### 多租户

多租户简单来说是指一个单独的实例可以为多个组织服务，对它的数据和配置进行虚拟分区，保障客户的数据隔离。通过在多个租户之间的资源复用，运营管理维护资源，有效节省开发应用的成本。

* 即一个租户一个数据库，这种方案的用户数据隔离级别最高，安全性最好，但增大了数据库的安装数量，随之带来维护成本和购置成本的增加，适合高数据隔离级别的租户。
* 一个租户（Tenant）一个Schema。为安全性要求较高的租户提供了一定程度的逻辑数据隔离，并不是完全隔离；每个数据库可以支持更多的租户数量。如果出现故障，数据恢复比较困难，因为恢复数据库将牵扯到其他租户的数据；
* 表中通过TenantID区分租户的数据。这是共享程度最高、隔离级别最低的模式。维护和购置成本最低，允许每个数据库支持的租户数量最多。隔离级别最低，安全性最低，需要在设计开发时加大对安全的开发量；

### 容器

##### 原理

* 快速打包技术：标准化（运行时标准、镜像标准）；轻量级（无guest os、共享内核、无真正的容器存在、本质为宿主机上进程、进程调度、内存访问、文件IO都由宿主机完成、docker辅助角色、容器进程都是docker daemon子进程，无虚拟化、无完整OS、共享bootfs、无需引导与加载os、快，本质为进程无虚拟化损耗、namespace隔离无需os损耗、rootfs(发行版)存储空间小、）；易移植（标准化、rootfs+app+config+lib、完整依赖，沙河、集装箱（隔离、搬运）、易于拓展、功能单一、解耦易维护，paas，一次打包到处运行、多容器高性能，虚拟机可以占据全部性能）
* 架构：client(命令)、docke_host(daemon进程、images、container)、远程仓库
* Linux Container：内核虚拟化技术，轻量级的虚拟化，隔离进程和资源
* namespce：约束进程的动态表现来创建边境，PID Namespace（init pid=1、层级结构（同级、上层下层）、clone进程时添加clone_newPID参数、可见性、发送信号）、Mount Namespace （隔离看到的挂载点视图、视图在挂在后才改变、chroot、容器镜像、rootfs、发行版、执行环境文件系统（bin、lib、root、无内核）、一致性）、Network namespace 让进程只看到当前namespace中的网络设备、隔离路由表。不存在真实的容器、安全、多容器高性能。
* cgroups：容器进程与主机上其它进程平等竞争、可能占据主机全部资源、多子系统、一组进程cpu、memory资源限制、接口为文件系统、树结构（子系统、容器）、参数（docker run时指定）。V1(子系统协调困难)。

##### 运行

* 镜像：文件系统、层:发行版（只读、whileout）、共享、unionfs（分层、修改为一层、增量rootfs、每一层都挂载在宿主机相应的目录下、层次覆盖、继承）、rootfs+app+config+lib、完整依赖,

* 容器：init层（ro、wh、host信息（host属于只读镜像但用户常修改此值，并不希望提交，commit只提交可读可写层））+readwrite（数据修改发生在此，增、改变（copy on write）、删除（wo文件、遮挡只读层文件）、commit保存可读可写层而只读层不变,将读写层+镜像层打包为镜像，其中镜像层共享不占用空间），写时复制、限制资源及试图的进程。

* 优势：bootfs,rootfs,无guest os,

* Client-Server结构的系统，Docker的守护进程。通过Socket从客户端访问！Docker-Server接收到Docker-Client的指令，就会执行这个命令

  ![700|425](%E9%9D%A2%E7%BB%8F.assets/docker-stages.png)

* docker exec 开启一个新的终端，新的进程属于容器对应的namespace和cgroups但是其父进程是docker daemon而不是pin=1，一个进程的 Namespace 信息在宿主机上以一个文件的方式存在，可以选择一个进程并加入他说在的namespace，
* attach 进入正在执行的终端。
* pin=1进程收到结束信号，直接给其子进程发送kill信号后容器结束。

##### 命令行

```shell
docker system prune -f # 删除停止容器和网络和镜像
docker image prune -a # 删除未被使用镜像
docker volume prune -f # 删除空闲volune
docker container run --rm  -it image_name args # 创建的容器在使用结束后自动删除容器
```

`CMD `与`ENTRYPOINT`联合使用，`ENTRYPOINT` 设置执行的命令，`CMD`传递参数：

```shell
ENTRYPOINT ["echo"]
CMD []

docker container run -it -rm image_name hello # 输出hello
```

#####  信号处理

pin=1：one process per comntainer，只有pid=1可控，init进程、守护进程、祖先、第一个用户态进程、管理、生命周期、信号、docker stop和kill（默认）发送sigterm（正常终止信号缺省行为退出，自定义handler资源清理、等待、sigkill,传播给子进程、优雅），kill -9强制，忽略（sigstop，sigkill除外）+捕获（自定义、sigstop，sigkill除外）+缺省，处理孤儿和回收僵尸进程(dumb-init三方)。

Kill：sig_ignore(内部调用&默认handler&目标为pin=0)则忽略信号，kill -9 1再容器内部不工作。kill 1：如果pin=1实现了堆sigterm的自定义则响应否则不响应。

正常停止容器：pin=1收到sigtrem(缺省行为是释放资源后退出)，其他进程收到pin=1发出的sigkill强制结束。自定义pin=1的singterm的hander，向其他进程转发sigterm而非sigkill,资源清理，graceful shutdown。

shell格式：命令行格式、先启动shell再执行服务程序，pin=1线程为shell，sigterm,handler，未提供、等待，sigkill强制退出。exec格式：字符串集合、pin=0线程为目标程序，docker run命令行cmd使用exec格式。

僵尸进程：zombie->exit，结束、资源已释放，占据PID,等待父进程(直接父类)回收(父进程收到子进程结束信号、僵尸不想赢kill信号、wait()、waitpid)、父进程获取子进程退出信息（nginx）、资源泄露(PID)。父进程结束：孤儿进程、收养、init进程。

默认情形下，docker提供一个隐含的entrypoint：“/bin/sh -c”，如果不指定entrypoint，cmd内容就是entrypoint的参数：/bin/sh -c python app.py。Docker 容器的启动进程为 ENTRYPOINT，而不是 CMD。

##### 文件

* 文件复制时如果是复制到文件夹中需要指明`/src/`，如果只写`/src`会将`src`当作文件，将文件复制到镜像中并重命名为`src`。
* 可写层是和特定的容器绑定，Data Volume由Docker管理（挂载方便、共享、读写权限管理），Bind Mount用户指定存储位置，`dockerfile`中的``VOLUME ["app"]`设置项是将主机目录挂载到容器中的目录app上，本机会自动创建一个随机名字的volume，去存储我们在Dockerfile定义的volume，默认在`/var/lib/docker/volumes`下；命令行通过`-v`可以可以手动的指定本机目录，以及对应于容器内的路径，这个路径是可以任意的，不必需要在Dockerfile里通过VOLUME定义。
* Data Volume挂载原理：当容器进程被创建之后，尽管开启了 Mount Namespace，但是在它执行 chroot之前，容器进程一直可以看到宿主机上的整个文件系统。只需要在 rootfs 准备好之后，在执行 chroot 之前，把 Volume 指定的宿主机目录挂载到指定的容器目录在上，这个 Volume 的挂载工作就完成了。Mount Namespace 已经开启了。这个挂载事件只在这个容器里可见。在宿主机上是看不见容器内部的这个挂载点的，这就保证了容器的隔离性不会被 Volume 打破，同时commit也不会提交挂载目录。挂载的底层实现为Bind Mount将一个目录或者文件，而不是整个设备，挂载到一个指定的目录上（文件修改发生在宿主机的对应目，不会影响容器镜像的内容。

##### 构建

* dockerfile：基础镜像、环境(run安装软件、变量arg、环境变量env、多行合并）、交互（网络、端口、挂载）、加入目标程序文件（add,copy）、启动(cmd命令行覆盖，entrypoint、联合使用)。等同于 Docker 使用基础镜像启动了一个容器，然后在容器中依次执行 Dockerfile 中的原语。
* 缓存：当dockerfile中某一层发生改变，该层以及其之后的所有层都会重新构建，不使用缓存，即使之后层并未发生变化。可以将不经常的层放到前面，将经常变化的层放到后面，合理利用缓存，加快构建速度。
* 多阶段构建：适用于程序的编译操作复杂，需要大量辅助程序，而编译后的程序并不需要这些辅助程序，通过多阶段构建，将编译阶段从最终的结果中分离，将编译结构构建进最终的输出镜像，精简结果镜像。
* 用户：容器默认root权限，/root映射到容器，/etc/sudoers映射到容器；run创建用户组和用户，更改目标文件归属，切换用户。

![700|450](%E9%9D%A2%E7%BB%8F.assets/image-20220712170641886.png)

* 基础环境层。这一层定义操作系统运行的版本、运行时环境层。这一层定义了业务代码的运行时环境（JDk）、Web 容器层。这一层定义了业务代码运行的容器的配置（tomcat）、业务代码层

##### 网络

* 容器访问外网：veth-pair虚拟设备接口，成对出现的，一端连接一个namespace(veth_container放入容器network namespace,veth-host放入host network namespace，实现host通信)；容器数据在网桥处进行网络地址转换(bridge+NAT,将veth-host加入docker0,容器+docker0构成子网)，借助本地主机地址访问外网（容器-(veth-pair)->docker0-(nat)->eth0）。NAT用于解决IP地址不足的问题，给一系列设备分配私有IP，当他们想要访问外网时，利用NAT将私有发送地址转换为共有地址，同样当受到外界发送回来的数据是将目的IP转换为私有IP，相当于一些列设备公用一个IP地址。

* 容器默认连接到名称为bridge的bridge桥接网络(veth)，bridge网络还连接本地主机端（eth）。一个容器可以连接到多个bridge上，拥有多个私有IP地址。

  自定义的bridge可以实现DNS的功能（iptable），可以直接使用与该bridge连接的容器名直接通信，而默认bridge(docker0)未实现该功能。

  ```
  docker network connect bridge_name container_name #连接
  docker network dis connect bridge_name container_name #断开连接
  ```

* Network namespace隔离,IP地址，路由表。

* host网路使用和主机一样的网络，类似于容器、主机使用相同网络设备，免去转换，提升性能（注意多个容器监听相同端口导致冲突）。none网络下的容器无法实现使用网络（内部、外部网络都无法使用，常用于容器编排）。

##### 端口

* 利用IPtable实现主机端口到容器私有地址及其端口的映射(8080 to:172.17.0.2:80)。`EXPOSE`并不是真正的暴露的端口，只是为了告诉使用者该容器应该暴漏该端口，在启动容器时要使用`-p`暴漏端口。

##### compose

* docker -compose服务更新文件发生改变后使用`docker-compose up `重新启动服务，会自动更新发生修改的容器，未经过修改的容器不会被重启。如果某个容器对应的镜像发生改变需要手指指定`build`参数：`docker-compose up -d --build`重新构建镜像并重启容器。如果是删除镜像需要添加参数以删除多余的容器：`docker-compose up -d --remove orphans`。当需要重启时使用`docker-compose restart`重启所有服务。

* docker-compose默认会为文件中定义的所有服务定义一个bridge，所以容器将可以使用服务名ping通，但是不同docker-compose间无法ping通（可以ping通本地主机，bridge默认会将本地网络自动加入）。

* 水平扩展：`docker-compose up -d --scale flask=3`将名为`flask`的服务扩展为3份，当通过服务名（DNS）连接flask时会将连接请求均分到三个服务，实现简单的发在均衡。

* 隐藏关键信息：对于不希望出现在docker-compose中的敏感信息，可以使用`${arg_name}`替换，再在相同文件夹下创建`.env`文件，写入`arg_name=abc`，在启动compose时会自动替换，可以使用`docker-compose config`检查替换后的compose文件。

* 服务依赖： 添加配置项`depends_on`指定该服务依赖另一个服务，需要在依赖服务启动后再启动该服务。但是服务启动不代表能正常提供服务，可以设置健康检查，`HEALTHCHECK`配置项，更细化检查指标。

##### 安全

* capbilities:原始两类（root,非root）；capability权限细分（一个特权操作对应一个capability），主机上：（root用户进程默认包含全部cap，非root进程默认无任何cap），容器：（privileged容器可以进行全部特权操作，容器中root用户进程默认只开启部分cap、安全、按需设置cap）
* user namespace:容器中root用户进程默认只开启部分cap更改修改主机上关键文件，主机root用户与容器root用户uid相同，共享内核导致软件漏洞危害主机系统；指定普通uid（使用宿主机上该id对应的用户、主机上uid共享，多容器冲突、资源受限）；usernamsespce(隔离uid、gid，容器-主机映射、容器中uid=0(再容器内拥有一定特权)->宿主机上普通用户（即使逃逸权限有限），指定映射范围防止冲突)；以非root创建管理容器（docker以非root执行）

##### 容器编排

* 一组联合挂载在 /var/lib/docker/aufs/mnt 上的 rootfs（容器镜像、静态视图、开发者关注重点）+ 一个由 Namespace+Cgroups 构成的隔离环境，（容器运行时，动态视图）。

* Master（负责api服务、调度、编排；如何编排、管理、调度用户提交的作业）+Node结构；kubelet 通过CRI（Container Runtime Interface）的远程调用接口负责同容器运行时打交道，gri接口定义了容器运行时的各项核心操作(通用性，不局限于docker)，通过 OCI 这个容器运行时规范同底层的Linux 操作系统进行交互；gRPC 协议同一个叫作 Device Plugin 的插件进行交互，是 Kubernetes 项目用来管理 GPU 等宿主机物理设备的主要组件；通过CNI（Container Networking Interface）和CSI（Container Storage Interface）实现对网络和存储的管理。

  ![700|425](%E9%9D%A2%E7%BB%8F.assets/image-20220310221912531.png)



* 在大规模集群中的各种任务之间，实际上存在着各种各样的关系;虚拟机（粗粒度）->容器(细粒度);以统一的方式来定义任务之间的各种关系;将非常频繁的交互和访问的容器划为一个pod,Pod 里的容器共享同一个 Network Namespace、同一组数据卷，从而达到高效率交换信息的目的;Service服务(Web应用与数据库、故意不在同一机上部署、容灾)；实现多个pod间的交互给 Pod 绑定一个 Service 服务，而 Service 服务声明的 IP 地址等信息是“终生不变”的。Service 服务的主要作用，就是作为 Pod 的代理入口，从而代替 Pod 对外暴露一个固定的网络地址。外部应用只关心service,Service Kubernetes 负责后端真正代理的 Pod 的 IP 地址、端口等信息的自动更新、维护以及负载均衡；Kubernetes 项目定义容器间关系和形态的主要方法。
* 通过一个“编排对象”，比如 Pod、等，来描述你试图管理的应用；定义一些“服务对象”，比如 Service等负责具体的平台级功能。调度（运行起来）->编排（自动处理容器间的关系）

##### 限制资源

[理解Docker（4）：Docker 容器使用 cgroups 限制资源使用-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/377861)

1，cgroup 相关的所有操作都是基于内核中的 cgroup virtual filesystem，挂载这个文件系统就可以了。文件系统默认情况下都是挂载到 `/sys/fs/cgroup` 目录下。

- blkio — 这个子系统为块设备设定输入/输出限制，比如物理设备（磁盘，固态硬盘，USB 等等）。
- cpu — 这个子系统使用调度程序提供对 CPU 的 cgroup 任务访问。
- cpuacct — 这个子系统自动生成 cgroup 中任务所使用的 CPU 报告。
- cpuset — 这个子系统为 cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。
- devices — 这个子系统可允许或者拒绝 cgroup 中的任务访问设备。
- freezer — 这个子系统挂起或者恢复 cgroup 中的任务。
- memory — 这个子系统设定 cgroup 中任务使用的内存限制，并自动生成内存资源使用报告。
- net_cls — 这个子系统使用等级识别符（classid）标记网络数据包，可允许 Linux 流量控制程序（tc）识别从具体 cgroup 中生成的数据包。
- net_prio — 这个子系统用来设计网络流量的优先级
- hugetlb — 这个子系统主要针对于HugeTLB系统进行限制，这是一个大页文件系统。

2，在对应子模块下创建进程组，表示将在该模块下限制进程使用。如在cpu模块下创建进程组`mkdir /sys/fs/cgroup/cpu/hello`，加入该进程组得进程都会收到对应得限制。

3，进程组下存在多个配置文件，表示对不同指标进行限制，如使用` cpu.cfs_quota_us`限制cpu占用比例。更改配置文件`echo 20000 > cpu.cfs_quota_us`。

```
cgroup.clone_children  cgroup.procs       cpu.cfs_quota_us  cpu.stat           tasks
cgroup.event_control   cpu.cfs_period_us  cpu.shares        notify_on_release
```

4，将要限制得进程pid加入task文件`echo 2428 > tasks`。

### 算法与数据结构

##### 线性结构

* 数组：连续的内存（缓存友好、局部性原理）；随机访问O(1)；插入/删除(O(N)，移动)；适用于个数确定（扩容为原来的1.5倍）、读取多、写入少
* 链表：不是连续的内存空间；插入/删除(O(N)，查找)；占用更多的空间（指针）；跳表；适用于个数不确定、读取少、写入多
* 栈：LIFO；插入删除O（1）；览器的回退和前进、函数调用；数组链表实现；
* 队列：FIFO；插入删除：O（1）；数组链表实现；适用一定顺序来处理数据的场景；消息队列、线程池中的请求/任务队列；

##### 树

* 满二叉树：每一个层的结点数都达到最大值；完全二叉树：除最后一层外其余层都是满的（最后一程左->右）；数组存储:i->2i+1,2i+2(堆)；深度优先（栈）、广度优先（队列）；深度为O(logN)
* 二叉查找树：有序、插入（最底层）、删除（左子树最大值、右子树最小是、尽量保证子树结构、减少操作次数）；O(logN)；退化（插入有序数据，O(N))；中序遍历实现排序
* AVL树：平衡条件（|左-右|<=1）保证O(logN)；单旋转（不平衡点回溯：LL/RR，对中间点旋转），双旋转（不平衡点回溯：LR/RL，对末节点两次旋转）;插入删除后都要平衡操作。
* B+树：平衡多叉树叉树（除根节点外的每个节点子节点M/2~M，半满防止退化为2叉树），数据在树叶上，第i个关键字代表第i+1个子树中最小关键字、跳表、每个叶节点容量有限（存储数据有限）;$log_{M/2}(N)$；添加元素超过容量要分裂、父节点满继续向上分裂（高度增加的唯一方式）；删除元素导致节点数低于下限从附近节点领养元素，如果附近节点元素过少无法领养则合并，向上不断合并（高度减少的唯一方式）

##### 遍历

```java
package collection;

import java.util.*;

public class TreeTraversal {
    private class TreeNode {
        int val;
        TreeNode left;
        TreeNode right;

        TreeNode() {
        }

        TreeNode(int val) {
            this.val = val;
        }

        TreeNode(int val, TreeNode left, TreeNode right) {
            this.val = val;
            this.left = left;
            this.right = right;
        }
    }

    // 前序遍历的迭代实现
    public List<Integer> preorderTraversal(TreeNode root) {
        List<Integer> result = new ArrayList<>();
        if (root == null) {
            return result;
        }
        Deque<TreeNode> stack = new LinkedList<>();
        stack.push(root);
        while (!stack.isEmpty()) {
            TreeNode node = stack.pop();
            result.add(node.val);
            if (node.right != null) {
                stack.push(node.right);
            }
            if (node.left != null) {
                stack.push(node.left);
            }
        }
        return result;
    }

    // 中序遍历的迭代实现
    public List<Integer> inorderTraversal(TreeNode root) {
        List<Integer> result = new ArrayList<>();
        if (root == null) {
            return result;
        }
        Deque<TreeNode> stack = new LinkedList<>();
        TreeNode node = root;
        while (node != null || !stack.isEmpty()) {
            while (node != null) {
                stack.push(node);
                node = node.left;
            }
            node = stack.pop();
            result.add(node.val);
            node = node.right;
        }
        return result;
    }

    // 后序遍历的迭代实现
    public List<Integer> postorderTraversal(TreeNode root) {
        List<Integer> result = new ArrayList<>();
        if (root == null) {
            return result;
        }
        Deque<TreeNode> stack = new LinkedList<>();
        stack.push(root);
        while (!stack.isEmpty()) {
            TreeNode node = stack.pop();
            result.add(node.val);
            if (node.left != null) {
                stack.push(node.left);
            }
            if (node.right != null) {
                stack.push(node.right);
            }
        }
        Collections.reverse(result);
        return result;
    }
}
```



##### hash

* 分离链表法（hashcode+equals）、线性探查（形成区块、占据其他数据空间、填充因子<0.5，插入复杂度：1/(1-f)）、平方探测（移动1,4,9,,,）、双散列（i*hash(x)，i=1,2,3,,）;再散列（扩容）；string不变类缓存hashcode；

##### 堆

* 完全二叉树；数组存储；高度logN；结点的值总是不大于或不小于其父结点的值；最大堆、最小堆；插入：放入底层空位后上滤O(logN)平均O(1);删除最大值/最小值：删除根形成空洞，取空洞左子节点和右子节点中较小的值 替换空洞，空洞下移值最底层，将最末元素填入空洞。O(logN)，最末元素较大只能重新放到最底层;建堆：N次插入：最坏O(NlogN)平均O(N)。查找第k小元素构建完整最小堆再删除k次O(N+klogN)、构建k大小的最大堆，该堆表示最小的k个元素，后续元素与堆中最大值（根元素）比较，若小于根则删除根将当前元素插入下滤，若大于根则忽略O(k+1+(N-k)logk)=O(Nlogk)。

##### 排序

* 插入：构建有序区间，将待排序数插入有序区间；适用n较小原数组有序；稳定；原位；O(N^2);

  ```java
public class Sort {

    /**
     * 冒泡排序
     * 过程：重复遍历数组，每次比较相邻的元素并交换，将最大的元素逐步移至数组末尾。
     * 时间复杂度：O(n^2) 最坏情况下要遍历 n*(n-1)/2 次
     * 空间复杂度：O(1) 原地排序
     * 稳定性：稳定
     * 适合场景：适用于小规模或基本有序数组
     */
    public static void bubbleSort(int[] arr) {
        for (int i = 0; i < arr.length - 1; i++) {
            boolean swapped = false;
            for (int j = 0; j < arr.length - 1 - i; j++) {
                if (arr[j] > arr[j + 1]) {
                    int temp = arr[j];
                    arr[j] = arr[j + 1];
                    arr[j + 1] = temp;
                    swapped = true;
                }
            }
            if (!swapped) {
                break;
            }
        }
    }

    /**
     * 插入排序
     * 过程：从第二个元素开始，将每个元素插入到前面已经排序好的部分。
     * 时间复杂度：O(n^2)，在最坏情况下需要进行 n*(n-1)/2 次比较
     * 空间复杂度：O(1) 原地排序
     * 稳定性：稳定
     * 适合场景：适用于小规模或基本有序数组
     */
    public static void insertionSort(int[] arr) {
        for (int i = 1; i < arr.length; i++) {
            int current = arr[i];
            int j = i - 1;
            while (j >= 0 && arr[j] > current) {
                arr[j + 1] = arr[j];
                j--;
            }
            arr[j + 1] = current;
        }
    }

    /**
     * 选择排序
     * 过程：每次找到未排序部分的最小元素并交换到当前位置
     * 时间复杂度：O(n^2)，因为总是需要遍历每个元素
     * 空间复杂度：O(1) 原地排序
     * 稳定性：不稳定
     * 适合场景：适用于小规模数组
     */
    public static void selectionSort(int[] arr) {
        for (int i = 0; i < arr.length - 1; i++) {
            int minIndex = i;
            for (int j = i + 1; j < arr.length; j++) {
                if (arr[j] < arr[minIndex]) {
                    minIndex = j;
                }
            }
            int temp = arr[i];
            arr[i] = arr[minIndex];
            arr[minIndex] = temp;
        }
    }

    /**
     * 归并排序
     * 过程：递归地将数组分成两部分，对两部分分别排序，然后合并。
     * 时间复杂度：O(n log n) 分解和合并每次都花费O(n)，一共进行log(n)次
     * 空间复杂度：O(n) 需要额外空间存放合并结果，非原位
     * 稳定性：稳定
     * 适合场景：比较次数少，适合大规模、需要稳定排序的数组
     */
    public static void mergeSort(int[] arr) {
        if (arr.length <= 1) {
            return;
        }
        int[] temp = new int[arr.length];
        mergeSort(arr, 0, arr.length - 1, temp);
    }

    private static void mergeSort(int[] arr, int left, int right, int[] temp) {
        if (left >= right) {
            return;
        }
        int mid = left + (right - left) / 2;
        mergeSort(arr, left, mid, temp);
        mergeSort(arr, mid + 1, right, temp);
        merge(arr, left, mid, right, temp);
    }

    private static void merge(int[] arr, int left, int mid, int right, int[] temp) {
        int i = left, j = mid + 1, k = left;
        while (i <= mid && j <= right) {
            // 添加=是为了保持稳定，相同的值，原先位于左侧的排序后还是在左侧
            if (arr[i] <= arr[j]) {
                temp[k++] = arr[i++];
            } else {
                temp[k++] = arr[j++];
            }
        }
        while (i <= mid) {
            temp[k++] = arr[i++];
        }
        while (j <= right) {
            temp[k++] = arr[j++];
        }
        System.arraycopy(temp, left, arr, left, right - left + 1);
    }

    static Random random = new Random();

    /**
     * 快速排序（单路）
     * 过程：选择一个基准，分区，将小于基准的放左边，大于基准的放右边，递归排序两部分。
     * 时间复杂度：O(n log n)，最坏情况下为 O(n^2)。
     * 本质为构建二叉查找树，每层选取根节点划分区间复杂度为O(n)，每次选择区间中位数则共进行log(n)层划分，每次选择最大值或者最小值则进行n层划分。
     * 空间复杂度：O(log n) 递归栈的空间，构建二叉查找树的树高。
     * 稳定性：不稳定，原位
     * 适合场景：适合一般情况的大规模数据
     */
    public static void quickSortSingle(int[] arr, int left, int right) {
        if (left >= right) {
            return;
        }
        // arr[:idx-1] <value; arr[idx]=p; arr[idx+1:]>=value
        int pivot = partitionSingle(arr, left, right);
        quickSortSingle(arr, left, pivot - 1);
        quickSortSingle(arr, pivot + 1, right);
    }

    private static int partitionSingle(int[] arr, int left, int right) {
        int pivotIndex = left + random.nextInt(right - left + 1);
        swap(arr, left, pivotIndex);
        int pivot = arr[left];
        int j = left;
        for (int i = left + 1; i <= right; i++) {
            if (arr[i] <= pivot) {
                j++;
                swap(arr, i, j);
            }
        }
        swap(arr, left, j);
        return j;
    }

    /**
     * 快速排序（双路）
     * 过程：从两侧指针向中间移动，左侧遇到>=p的元素停下，右侧遇到<=p的元素停下，之后二者交换下标各向中间移动一位，直至二者相遇
     * 时间复杂度：O(n log n)，最坏情况下为 O(n^2)
     * 空间复杂度：O(log n) 递归栈的空间
     * 稳定性：不稳定，原位
     * 适合场景：适合一般情况的大规模数据，有大量重复数据
     */
    public static void quickSortDouble(int[] arr, int left, int right) {
        if (left >= right) {
            return;
        }
        // arr[:idx-1] <=value; arr[idx]=p; arr[idx+1:]>=value
        int pivot = partitionDouble(arr, left, right);
        quickSortDouble(arr, left, pivot - 1);
        quickSortDouble(arr, pivot + 1, right);
    }

    private static int partitionDouble(int[] arr, int left, int right) {
        int pivotIndex = left + random.nextInt(right - left + 1);
        swap(arr, left, pivotIndex);
        int pivot = arr[left];
        int i = left + 1, j = right;
        while (true) {
            while (i <= right && arr[i] < pivot) {
                i++;
            }
            while (j >= left + 1 && arr[j] > pivot) {
                j--;
            }
            if (i > j) {
                break;
            }
            swap(arr, i, j);
            i++;
            j--;
        }
        swap(arr, left, j);
        return j;
    }


    /**
     * 快速排序（三路）
     * 过程：分区时将数组分为小于、等于和大于基准三部分，递归排序小于和大于部分。
     * 时间复杂度：O(n log n)，在有大量重复元素时更接近 O(n)
     * 空间复杂度：O(log n) 递归栈的空间
     * 稳定性：不稳定，原位
     * 适合场景：适合含大量重复元素的大规模数据
     */

    public static void quickSortThreeWay(int[] arr, int left, int right) {
        if (left >= right) {
            return;
        }
        int pivotIndex = left + random.nextInt(right - left + 1);
        swap(arr, left, pivotIndex);
        int pivot = arr[left];
        int lt = left;
        int gt = right + 1;
        int i = left + 1;

        while (i < gt) {
            if (arr[i] < pivot) {
                lt++;
                swap(arr, i, lt);
                i++;
            } else if (arr[i] > pivot) {
                gt--;
                swap(arr, i, gt);
            } else {
                i++;
            }
        }
        // arr[:lt] <value; arr[lt+1:gt-1]=p; arr[gt:]>value
        swap(arr, left, lt);
        // arr[:lt-1] <value; arr[lt:gt-1]=p; arr[gt:]>value
        quickSortThreeWay(arr, left, lt - 1);
        quickSortThreeWay(arr, gt, right);
    }

    /**
     * 堆排序
     * 过程：将数组视为二叉堆构建最大堆，通过不断移除堆顶元素（最大值）并重建堆实现排序。
     * 时间复杂度：O(n log n)，每次堆化操作的时间复杂度为 O(log n)，初始构建堆进行 n/2 次操作，删除n次堆顶元素。
     * 空间复杂度：O(1)，原地排序
     * 稳定性：不稳定
     * 适合场景：适用于不需要稳定排序的大规模数据
     */
    public static void heapSort(int[] arr) {
        int n = arr.length;
        // 构建最大堆
        // 从最后一个非叶子节点开始，向上调整，确保每个节点都满足堆的性质
        // 因为i需要根据其l,r的值，决定当前以i为根节点子树的最大值，所以需要l,r分别为各自子树的最大值，所以需要逆向处理
        for (int i = n / 2 - 1; i >= 0; i--) {
            heapify(arr, n, i);
        }
        // 逐步将堆顶元素（最大值）移到数组末尾，并调整剩余部分为新的最大堆
        for (int i = n - 1; i >= 0; i--) {
            swap(arr, 0, i);
            // 最大值转移到末尾后，待排序区间缩减为[0:i-1]
            // 对更新后的arr[0]下滤
            heapify(arr, i, 0);
        }
    }

    // n: 树节点数，i：要调整的节点
    private static void heapify(int[] arr, int n, int i) {
        int largest = i;
        int left = 2 * i + 1;
        int right = 2 * i + 2;
        if (left < n && arr[left] > arr[largest]) {
            largest = left;
        }
        if (right < n && arr[right] > arr[largest]) {
            largest = right;
        }
        if (largest != i) {
            // arr[largest]上浮
            swap(arr, i, largest);
            // arr[largest]下滤
            heapify(arr, n, largest);
        }
    }

    /**
     * 希尔排序
     * 过程：将数组分为若干子序列分别进行插入排序，然后逐步减小子序列间隔直到整个数组有序。
     * 时间复杂度：最坏情况下为 O(n^2)，平均复杂度约为 O(n^(3/2)) - O(n^(5/4))，与间隔序列相关。
     * 空间复杂度：O(1)，原地排序
     * 稳定性：不稳定（同一轮排序中元素可能跨越较大间隔，改变相同元素的相对位置）
     * 适合场景：适合大规模、对稳定性要求不高的数组，速度快于插入排序
     */
    public static void shellSort(int[] arr) {
        int n = arr.length;

        // 使用希尔增量序列（n / 2, n / 4, ..., 1）
        for (int gap = n / 2; gap > 0; gap /= 2) {
            // 对每个间隔序列进行插入排序
            for (int i = gap; i < n; i++) {
                int temp = arr[i];
                int j = i;
                while (j >= gap && arr[j - gap] > temp) {
                    arr[j] = arr[j - gap];
                    j -= gap;
                }
                arr[j] = temp;
            }
        }
    }

    /**
     * 计数排序
     * 过程：统计数组中每个元素出现的次数，并根据统计结果将元素按顺序输出。
     * 时间复杂度：O(n + k)，n 为元素个数，插入复杂度O(n)，k 为元素的值范围，读取复杂度O(k)
     * 空间复杂度：O(k)，需要额外数组存储计数
     * 稳定性：稳定
     * 适合场景：适用于数据范围有限且为整数的数组，如成绩排序
     * 是否原位：否
     */
    public static void countingSort(int[] arr) {
        if (arr.length == 0) {
            return;
        }
        int max = Arrays.stream(arr).max().orElse(Integer.MIN_VALUE);
        int min = Arrays.stream(arr).min().orElse(Integer.MAX_VALUE);

        int range = max - min + 1;
        int[] count = new int[range];
        int[] output = new int[arr.length];

        // 统计每个元素的频次
        for (int num : arr) {
            count[num - min]++;
        }

        // 计算累加和，生成排序位置
        // count[i]: 小于等于i+min的值的个数
        for (int i = 1; i < count.length; i++) {
            count[i] += count[i - 1];
        }

        // 将元素放到输出数组中
        // 倒序填充结果数组是为保持排序的稳定性，count[arr[i] - min] - 1保存最后一个arr[i]的位置，之后逐次前移
        for (int i = arr.length - 1; i >= 0; i--) {
            output[count[arr[i] - min] - 1] = arr[i];
            count[arr[i] - min]--;
        }

        // 将结果复制回原数组
        System.arraycopy(output, 0, arr, 0, arr.length);
    }

    /**
     * 桶排序
     * 过程：将元素划分到不同的桶中，分别对每个桶进行排序后合并。
     * 时间复杂度：O(n + k)，在数据均匀分布时接近 O(n)
     * 空间复杂度：O(n + k)，需要存储桶
     * 稳定性：稳定（若使用稳定排序算法对桶内排序）
     * 适合场景：适合浮点数排序或数据均匀分布的整数数组
     * 是否原位：否
     */
    public static void bucketSort(float[] arr) {
        if (arr.length == 0) {
            return;
        }

        // 创建桶
        int n = arr.length;
        List<Float>[] buckets = new ArrayList[n];
        for (int i = 0; i < n; i++) {
            buckets[i] = new ArrayList<>();
        }

        // 将元素分配到对应的桶中，需要数据分布较为均匀
        for (float num : arr) {
            // 假设 arr 元素在 [0, 1) 范围内
            int bucketIndex = (int) (num * n);
            buckets[bucketIndex].add(num);
        }

        // 对每个桶进行排序并合并结果
        int index = 0;
        for (List<Float> bucket : buckets) {
            // 使用内置排序对每个桶排序
            Collections.sort(bucket);
            for (float num : bucket) {
                arr[index++] = num;
            }
        }
    }

    /**
     * 基数排序
     * 过程：从最低位到最高位依次进行排序，常使用计数排序对每一位进行排序。
     * 时间复杂度：O(d * (n + b))，d 为位数，b 为基数，n 为元素个数
     * 空间复杂度：O(n + b)，需要额外空间存储计数
     * 稳定性：稳定
     * 适合场景：适合固定长度的整数或字符串排序，如身份证号、电话号码等
     * 是否原位：否
     */
    public static void radixSort(int[] arr) {
        if (arr.length == 0) {
            return;
        }

        int max = Arrays.stream(arr).max().orElse(0);
        int maxDigit = Integer.toString(max).length();

        int exp = 1;
        int[] output = new int[arr.length];

        for (int i = 0; i < maxDigit; i++) {
            int[] count = new int[10];

            // 统计每个位上的数字
            for (int num : arr) {
                int digit = (num / exp) % 10;
                count[digit]++;
            }
            // count[i]: 对应位为小于等于i的值的个数
            for (int j = 1; j < 10; j++) {
                count[j] += count[j - 1];
            }
            // 倒序填充结果数组是为保持排序的稳定性，count[digit] - 1保存最后一个arr[j]的位置，之后逐次前移
            for (int j = arr.length - 1; j >= 0; j--) {
                int digit = (arr[j] / exp) % 10;
                output[count[digit] - 1] = arr[j];
                count[digit]--;
            }
            // 第i位排序结果已反映在arr的顺序中，获得第i+1位相同的数值集合时，该集合已按照后i位大小排序
            // 765，864，963 按个位数排序：963，864，765，获得十位为6的集合时得到：963，864，765。已按照个位数排序
            System.arraycopy(output, 0, arr, 0, arr.length);
            exp *= 10;
        }
    }

    /**
     * 拓扑排序（Kahn 算法）
     * 过程：计算每个节点的入度，将入度为 0 的节点加入队列，不断取出队首节点并将其邻接节点的入度减 1，如果邻接节点的入度变为 0，则将其加入队列，直到队列为空。
     * 时间复杂度：O(V + E)，其中 V 为节点数，E 为边数
     * 空间复杂度：O(V)
     * 稳定性：无稳定性可言（用于有向无环图）
     * 适合场景：适合有依赖关系的任务调度等
     * 是否原位：否
     */
    public static List<Integer> topologicalSortKahn(int numVertices, List<List<Integer>> adjList) {
        int[] inDegree = new int[numVertices];
        for (List<Integer> neighbors : adjList) {
            for (int neighbor : neighbors) {
                inDegree[neighbor]++;
            }
        }

        Queue<Integer> queue = new LinkedList<>();
        for (int i = 0; i < numVertices; i++) {
            if (inDegree[i] == 0) {
                queue.offer(i);
            }
        }

        List<Integer> topologicalOrder = new ArrayList<>();
        while (!queue.isEmpty()) {
            int node = queue.poll();
            topologicalOrder.add(node);

            for (int neighbor : adjList.get(node)) {
                inDegree[neighbor]--;
                if (inDegree[neighbor] == 0) {
                    queue.offer(neighbor);
                }
            }
        }

        if (topologicalOrder.size() != numVertices) {
            throw new IllegalArgumentException("Graph has a cycle, topological sorting is not possible.");
        }
        return topologicalOrder;
    }

    private static void swap(int[] arr, int i, int j) {
        int tmp = arr[i];
        arr[i] = arr[j];
        arr[j] = tmp;
    }
}
/*
JDK 实现：
一、基本数据类型数组(byte[], char[], short[], int[], long[], float[], double[])排序
1. 数组长度 <= 43：使用插入排序
   - 小范围数据下插入排序的性能优于快速排序和归并排序，因为其比较和移动元素的开销较小，且可以充分利用 CPU 缓存
   - 混合插入排序：每次选择两个未排序数据[a, b]，先插入a，在插入B时，将根据b与a的关系调整插入区间，减少比较次数
2. 数组长度 44 < n <= 286：使用快速排序
   - 使用双轴快排(Dual-Pivot Quicksort)：5个等间隔选举数值，选择第1个和第3个作为枢纽，随机数据上的性能通常优于单轴快速排序，增加比较次数，减少数据访问次数，匹配CPU运算快于内存访问
   - 适用于无序的基本数据类型数组排序，且在数据规模较大时比传统快排更快。
3. 数组长度 > 286：使用归并排序
   - 保证最坏情况下仍然是O(nlogn)
   - 针对部分有序的情况做了优化，统计有序区间个数，如果有序区间个数少则证明数据局部有序，直接将有序区间并归

二、对象数组(Object[])排序：
1. TimSort算法（改进的归并排序）
   - 将数组划分为多个已排序的小片段（称为 runs），并使用插入排序对较小的片段排序，再将这些已排序的片段用归并排序进行合并。
   - 对几乎有序的数据特别有效，性能可以接近 O(n)
 */

  ```


  获得第k小元素：选取枢纽元划分为两个空间s1,s2,如果|s1|>=k则目标元素再s1中，func(s1,k),如果k=|s1|+1则枢纽元为目标元素，如果k>|s1|则目标在s中，且为s2中第k-|s1|-1小元素，func(s2,k-|s1|-1)，划分为两个区间后只选一个区间递归T(N)=T(N/2)+N => O(N)



* 外部排序：适合输入量很大；IO耗时；

  双路合并：一个输入N,内存容量为M,每次读取M个输入构成N/M个有序字串 NlogM->并归排序,每一层并归复杂度O(N)，共log(N/M)层并归，O(N*log(N/M))->总复杂度O(NlogM+Nlog(N/M))。
  
  多路合并：一个输入N,内存容量为M,每次读取M个输入构成N/M个有序字串 NlogM->k路合并，败者树，类似最小堆，k个字串的第一个值构成树叶节点->兄弟几点比较，较小者胜出上浮->输出树顶值，该输出对应字串的下一个输入读入，比较上浮->k个顺串处理完毕得到长度为kM得顺串->顺串不断增长至N。
  
  比特图：N个不重复且<=$10^7$的正整数:(1)构建长$10^7$的batmap，每一位初始化为0,bitmap[a[i]]=1，结束后扫描输出，如果无法容纳$10^7/8$字节，可以将数据划分为两部分，先排序<=$10^7/2$的值后排序 $>10^7/2$的的值，内存消耗为$10^7/16$字节。

##### 图论

* 概念：邻接矩阵（有权，无权，适合稠密图）；邻接表（数组+链表，数组表示点，链表表示和该点相连的点，适合稀疏图）。

* Floyd最短路径算法：一条i->j的最短路必须要经过点k，那么i->k的最短路加上k->j的最短路一定是i->j 经过k的最短路。

  ```java
   for (int k = 0; k < n; k++) {
       for (int i = 0; i < n; i++) {
           for (int j = 0; j < n; j++) {
               a[i][j] = Math.min(a[i][j], a[i][k] + a[k][j]);
           }
       }
   }
  ```

  多源最短路，会求出任意出发点到任意终点的路径，空间复杂度$O(n^2)$，时间复杂度达到了$O(n^3)$，只有在数据规模很小的时候，才适合使用这个算法。

* dijkstra最短路径算法：基于贪心的单源最短路算法。

  寻找点i，满足min(d[i])  i∈B，满足这个条件的点i，必定是无法被继续松弛的点，如果说要松弛点i，那么必定通过A中或者B中的点进行更新，若通过B中的点j进行更新那么松弛之后的路径为d[j] + a[j][i] 由于d[i]已经是最小了，因此d[j]+a[j][i]>d[i]  因此不可能是通过B中的点进行松弛，若通过A中的点m进行松弛，由于m是点集A中的点，因此点m一定松弛过点i，重复的松弛没有意义的。

  维护两个点集A,B，A点集代表已经求出源点到该点的最短路的点的集合，B代表未求出源点到该点的最短路径的点的集合。维护一个向量d,d[i]代表源点到点i的最短路径长度。不断进行以下操作：找出点集B中d[i] i∈B 最小的点，这个点为进入点集A的候选节点，然后通过该点更新B中与其连同的点以该点为中介到源点的距离，更新向量d，($d_w=min(dw,dv+c_{v,w})$，$d_v$表示v到源点距离)，然后将该候选点放入点集A，直到点集B为空。

* prim最小生成树：“加点法”，每次从未知集合中迭代选择与已知集合连接代价最小的边对应的点，加入到最小生成树中，更新未知集合中与该点相连的点到已知集合的距离($d_w=min(d_w,c_{v,w})$，$d_v$表示v到已知集合的距离)。算法从某一个顶点s开始，逐渐长大覆盖整个连通网的所有顶点。最小生成树中任意两点距离不是最小的，只保证联通所有点的距离最小。

* Kruskal最小生成树算法：“加边法”，初始最小生成树边数为0，每一个点都是一个独立的数，每迭代一次就选择一条满足条件的最小代价边，在他所连接的两个不同的树时，加入到最小生成树的边集合里。

  把图中的所有边按代价从小到大排序；->把图中的n个顶点看成独立的n棵树组成的森林；->按权值从小到大选择边，所选的边连接的两个顶点ui,vi，ui,vi,应属于两颗不同的树，则成为最小生成树的一条边，并将这两颗树合并作为一颗树。->重复(3),直到所有顶点都在一颗树内或者有n-1条边为止。

```java
package collection;

import java.util.*;

/**
 * Prim算法
 * 加点法，适合稠密图，即边数较多的图。
 * 原理：从一个顶点开始，使用优先队列保存未处理点，逐步扩展与已知点集合具有最小权重的边，直到包含图中所有顶点。
 * 时间复杂度：`O(E log V)`，其中 `E` 为边数，`V` 为顶点数。
 * 每个节点的相邻节点会被加入优先队列，每次加入和弹出操作的时间复杂度为 `O(log V)`，对于 `E` 条边，堆操作的复杂度为` O(E log V)`。
 */
class PrimMST {
    public static class Edge {
        int to, weight;

        public Edge(int to, int weight) {
            this.to = to;
            this.weight = weight;
        }
    }

    public int prim(int n, List<List<Edge>> graph) {
        boolean[] visited = new boolean[n];
        // 按照与已知点集合的距离升序
        PriorityQueue<Edge> minHeap = new PriorityQueue<>(Comparator.comparingInt(e -> e.weight));
        minHeap.offer(new Edge(0, 0));
        int totalWeight = 0;
        while (!minHeap.isEmpty()) {
            // 获得离已知点集合最近的未知点
            Edge currentEdge = minHeap.poll();
            int to = currentEdge.to;
            // 节点可能因为多次通过点中转点，被多次添加到pq，只需要保留距离最小的记录
            if (visited[to]) {
                continue;
            }
            visited[to] = true;
            totalWeight += currentEdge.weight;
            for (Edge edge : graph.get(to)) {
                if (!visited[edge.to]) {
                    minHeap.offer(edge);
                }
            }
        }
        for (boolean v : visited) {
            if (!v) {
                return -1;
            }
        }
        return totalWeight;
    }
}

/**
 * Kruskal算法
 * 加边法，适合稀疏图，即边数较少的图。
 * 原理：通过对所有边按权重排序，逐步加入不构成环的边来形成最小生成树。Kruskal算法依赖并查集来判断是否形成环。
 * 时间复杂度：`O(E log E + E α(V))`，其中` α(V) `是并查集的常数级复杂度。
 * O(E log E) 对所有边排序复杂度，O(E α(V))对每条边需要查找根节点和union
 */
class KruskalMST {
    public static class Edge implements Comparable<Edge> {
        int from, to, weight;

        public Edge(int from, int to, int weight) {
            this.from = from;
            this.to = to;
            this.weight = weight;
        }

        @Override
        public int compareTo(Edge other) {
            return Integer.compare(this.weight, other.weight);
        }
    }

    private int find(int[] parent, int x) {
        if (parent[x] != x) {
            parent[x] = find(parent, parent[x]);
        }
        return parent[x];
    }

    private void union(int[] parent, int[] rank, int x, int y) {
        int rootX = find(parent, x);
        int rootY = find(parent, y);
        if (rootX != rootY) {
            if (rank[rootX] > rank[rootY]) {
                parent[rootY] = rootX;
            } else if (rank[rootX] < rank[rootY]) {
                parent[rootX] = rootY;
            } else {
                parent[rootY] = rootX;
                rank[rootX]++;
            }
        }
    }

    public int kruskal(int n, List<Edge> edges) {
        // 按照边权重降序
        Collections.sort(edges);
        int[] parent = new int[n];
        int[] rank = new int[n];
        for (int i = 0; i < n; i++) {
            parent[i] = i;
            rank[i] = 0;
        }
        int totalWeight = 0, count = 0;
        // 遍历未处理边中权重最小的边
        for (Edge edge : edges) {
            int root1 = find(parent, edge.from);
            int root2 = find(parent, edge.to);
            if (root1 != root2) {
                totalWeight += edge.weight;
                union(parent, rank, root1, root2);
                count++;
                if (count == n - 1) {
                    break;
                }
            }
        }
        return count == n - 1 ? totalWeight : -1;
    }
}

/**
 * Dijkstra算法
 * 用于单源最短路径问题，适合边权非负的有向或无向图，效率较高。
 * 原理：维护一个优先队列记录未处理点，每次从队列中取出离起点最近的点，更新其邻接点的与起点最短距离。
 * 复杂度：`O((V + E) log V)`
 * 每个节点在最坏情况下都会被加入和提取一次，复杂度为O(V log V)；每条边在最坏情况下都需要通过中转缩短与起点距离，之后加入堆替换原有距离，松弛操作的总复杂度为O(E log V)
 */
class DijkstraShortestPath {
    public int[] dijkstra(int n, List<List<int[]>> graph, int start) {
        int[] dist = new int[n];
        // 表示从 start 到其他所有节点的最短距离
        Arrays.fill(dist, Integer.MAX_VALUE);
        dist[start] = 0;
        // 按照与起点距离升序
        PriorityQueue<int[]> pq = new PriorityQueue<>(Comparator.comparingInt(a -> a[1]));
        pq.offer(new int[]{start, 0});
        while (!pq.isEmpty()) {
            // 获得未处理点中离起点最近的点
            int[] node = pq.poll();
            int u = node[0], d = node[1];
            // 节点u可能因为多次通过点中转点，而缩短与起点距离，被多次添加到pq，只需要保留距离最小的记录
            if (d > dist[u]) {
                continue;
            }
            // 如果u邻接点因为u的中转而缩短距离，将其加入pq
            for (int[] edge : graph.get(u)) {
                int v = edge[0], weight = edge[1];
                if (dist[u] + weight < dist[v]) {
                    dist[v] = dist[u] + weight;
                    pq.offer(new int[]{v, dist[v]});
                }
            }
        }
        return dist;
    }
}

/**
 * Bellman-Ford算法
 * 迭代边，适用于边权可负的单源最短路径问题。能处理负权边，但效率较低。
 * 原理：通过迭代多次迭代所有边[u,v]，尝试通过u使得ds_u+du_v < ds_v，更新所有节点到起点的最短距离，最终得到起点到所有节点的最短路径。
 * 复杂度：`O(V * E)`。
 */
class BellmanFordShortestPath {
    public int[] bellmanFord(int n, List<int[]> edges, int start) {
        // 从 start 到其他所有节点的最短距离
        int[] dist = new int[n];
        Arrays.fill(dist, Integer.MAX_VALUE);
        dist[start] = 0;
        for (int i = 0; i < n - 1; i++) {
            boolean updated = false;
            // 通过迭代所有边[u,v]，尝试通过u使得ds_u+du_v < ds_v，更新所有节点到起点的最短距离
            for (int[] edge : edges) {
                int u = edge[0], v = edge[1], weight = edge[2];
                if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) {
                    dist[v] = dist[u] + weight;
                    updated = true;
                }
            }
            // 没有更新表示提前结束
            if (!updated) {
                break;
            }
        }

        // 检查负权环
        for (int[] edge : edges) {
            int u = edge[0], v = edge[1], weight = edge[2];
            if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) {
                System.out.println(" Graph contains a negative weight cycle");
            }
        }
        return dist;
    }
}

/**
 * Floyd-Warshall算法
 * 迭代点，用于多源最短路径问题，适合稠密图。能计算图中任意两个节点之间的最短路径，并可以处理负权边，但不适用于负权环。
 * 原理： 通过迭代查找节点k能否作为i->j中间节点，使得di_k+d_k_j < di_j, 更新所有节点对之间的最短路径，最终得到任意两个节点之间的最短路径。
 * 复杂度：`O(V^3)`
 */
class FloydWarshallShortestPath {
    public int[][] floydWarshall(int n, int[][] graph) {
        int[][] dist = new int[n][n];
        for (int i = 0; i < n; i++) {
            System.arraycopy(graph[i], 0, dist[i], 0, n);
        }
        // 通过迭代查找节点k能否作为i->j中间节点，使得di_k+d_k_j < di_j, 更新所有节点对之间的最短路径
        for (int k = 0; k < n; k++) {
            for (int i = 0; i < n; i++) {
                for (int j = 0; j < n; j++) {
                    if (dist[i][k] != Integer.MAX_VALUE && dist[k][j] != Integer.MAX_VALUE) {
                        dist[i][j] = Math.min(dist[i][j], dist[i][k] + dist[k][j]);
                    }
                }
            }
        }
        // 检查负权环
        for (int i = 0; i < n; i++) {
            if (dist[i][i] < 0) {
                System.out.println("Graph contains a negative weight cycle");
            }
        }
        return dist;
    }
}

/**
 * Shortest Path Faster Algorithm
 * Bellman-Ford 的优化版，用队列来加速更新，通常在稀疏图且负权边较多时比 Bellman-Ford 快。
 * 原理：队列中保存由于使用中转节点k，使得到起点距离ds_k+dk_i < ds_i的节点i，再以i为起点尝试松弛其邻接节点，直至无可松弛节点
 * 复杂度：最坏情况下` O(V * E)`
 */
class SPFAShortestPath {
    public int[] spfa(int n, List<int[]>[] graph, int start) {
        // 从 start 到其他所有节点的最短距离
        int[] dist = new int[n];
        Arrays.fill(dist, Integer.MAX_VALUE);
        dist[start] = 0;
        Queue<Integer> queue = new LinkedList<>();
        boolean[] inQueue = new boolean[n];
        queue.offer(start);
        inQueue[start] = true;
        // 队列中保存由于使用中转节点k，使得到起点距离ds_k+dk_i < ds_i的节点i
        while (!queue.isEmpty()) {
            int u = queue.poll();
            inQueue[u] = false;
            // 由于i的距离缩短，尝试松弛其邻接节点
            for (int[] edge : graph[u]) {
                int v = edge[0], weight = edge[1];
                if (dist[u] != Integer.MAX_VALUE && dist[u] + weight < dist[v]) {
                    dist[v] = dist[u] + weight;
                    if (!inQueue[v]) {
                        queue.offer(v);
                        inQueue[v] = true;
                    }
                }
            }
        }
        return dist;
    }
}

/**
 * A（A-star）算法
 * 用于有障碍物的最短路径规划场景，设计一个启发函数`f(n) = g(n) + h(n)`来引导搜索。
 * 其中`g(n)`：从起点到节点 `n` 的实际代价（如路径长度）；`h(n)`：从节点 `n `到目标节点的启发式估计（如欧式距离或曼哈顿距离）。
 * A* 算法会选择队列中`f(n) `最小的节点进行扩展，如果该节点p的邻接节点n能通过该节点中转，获得更好的`g_p+1 < g_n`，更新节点n的`g_n=g_p+1`和`h`并加入队列，完成松弛，不断重复上述过程，以此找到一条最短路径。
 * <p>
 * 初始化：将起点加入优先队列，并初始化 g(n) 和 f(n)。
 * 扩展节点：从优先队列中取出 f(n) 最小的节点。
 * 检查终点：若当前节点是终点，路径完成。
 * 更新邻居节点：对当前节点的每个邻居节点，计算其 g(n) 和 f(n) 值，并更新优先队列。
 * 循环：重复步骤2-4，直到找到最优路径或无解。
 */
class AStarAlgorithm {
    static class Node implements Comparable<Node> {
        // toX, toY, fromDist, toDist
        int x, y, g, h;

        Node(int x, int y, int g, int h) {
            this.x = x;
            this.y = y;
            this.g = g;
            this.h = h;
        }

        int f() {
            return g + h;
        }

        @Override
        public int compareTo(Node other) {
            return Integer.compare(this.f(), other.f());
        }
    }

    private static final int[][] DIRS = {{0, 1}, {1, 0}, {0, -1}, {-1, 0}};

    public int aStar(int[][] grid, int[] start, int[] end) {
        int rows = grid.length, cols = grid[0].length;
        // 用于选择当前估值 f(n) 最小的节点进行扩展。
        PriorityQueue<Node> openSet = new PriorityQueue<>();
        // 记录已处理的节点
        boolean[][] closedSet = new boolean[rows][cols];
        // 记录每个节点从起点到此节点的最小代价g
        int[][] gScore = new int[rows][cols];

        for (int i = 0; i < rows; i++) {
            Arrays.fill(gScore[i], Integer.MAX_VALUE);
        }
        int startX = start[0], startY = start[1];
        int endX = end[0], endY = end[1];
        gScore[startX][startY] = 0;
        openSet.offer(new Node(startX, startY, 0, heuristic(startX, startY, endX, endY)));
        while (!openSet.isEmpty()) {
            Node current = openSet.poll();
            int x = current.x, y = current.y;
            if (x == endX && y == endY) {
                return current.g;
            }
            // 节点可能因为多次通过点中转点，而减小g，被多次添加到openSet，只需要保留距离最小的记录
            if (closedSet[x][y]) {
                continue;
            }
            closedSet[x][y] = true;
            for (int[] dir : DIRS) {
                int nx = x + dir[0], ny = y + dir[1];
                if (nx >= 0 && ny >= 0 && nx < rows && ny < cols && grid[nx][ny] == 0) {
                    // 节点p的邻接节点n能通过该节点中转，获得更好的`g_p+1 < g_n`，更新节点n的`g_n=g_p+1`和`h`并加入队列，完成松弛
                    int tentativeG = current.g + 1;
                    if (tentativeG < gScore[nx][ny]) {
                        gScore[nx][ny] = tentativeG;
                        int h = heuristic(nx, ny, endX, endY);
                        openSet.offer(new Node(nx, ny, tentativeG, h));
                    }
                }
            }
        }
        return -1;
    }

    // heuristic启发函数
    private int heuristic(int x, int y, int endX, int endY) {
        return Math.abs(x - endX) + Math.abs(y - endY);
    }
}
```

##### 技巧

* 贪婪：每个阶段都选择局部最优，期望多个局部最优构成全局最优。
* 分治：分（递归解决小问题），治（从子问题的解构建原问题的解）。
* 动态规划：数学递推公式->递归算法-> 非递归算法（子问题答案记录到一个表格内）
* 回溯：穷举、在当前选择一种状态后将计数器减1后传入到子问题递归求解，子问题递归求解，子问题返回后撤销当前的选择，使用另一选择继续传递给子问题递归求解。在求解问题想要进行解空间判断，如果后续所不存在解则返回(裁剪)，如果计数器达到要求则将解保存后返回。

##### 数据结构

* 跳表：解决链表随机访问问题，建立多级索引，以每k个节点向上构建一个索引为列，共log_k(N)层层次结构，查找复杂度log_k(N)+k，修复成本。
* 红黑树：avl复杂、添加颜色规则近似达到平衡，红黑树与AVL树高度相近，发生旋转更少，插入复杂度更低，插入、删除、查找复杂度：O(logN)；红/黑；根为黑，叶(null)为黑；一个节点到以他为根节点的子树的所有null(叶子，黑色)节点路径中黑节点数相同；红色不能连续，红父必黑子；插入节点必在根节点并为红色，如果其父为黑则插入完成，否则要不断向上进行进行颜色改变与旋转（单、双）；删除节点向上变色与旋转。
* **AVL树**：保持严格的平衡，要求任意节点的左右子树高度差最多为1。这种严格平衡保证了树的高度较低，从而在最坏情况下具有对数时间复杂度的操作（查找、插入、删除）。但由于高度差要求较严格，每次插入或删除后可能需要多次旋转来恢复平衡，导致其操作成本较高。适合读多，写/改/删少的场景。
* **红黑树**：红黑树则在平衡上要求较宽松。它通过特定的颜色标记和规则来保证树的平衡性，允许每个节点的左右子树高度差最多为2倍。因此，红黑树的平衡性略差于AVL树，但它的旋转次数通常较少，操作更加高效。适合写/改/删多读少

##### BFS、DFS

BFS：必须要保存搜索过程中的状态，来搜索最短径路的解是比较合适的。

DFS：不必保存搜索过程中的状态，适合搜索全部的解。

### JVM

##### 参数

* Xss：虚拟机栈、本地方法栈；无限递归（SOF）;递归方法本地变量过多（SOF）;无限加线程(OOM)；P61,单线程下调用方法太深导致sof，多线程下每个线程栈占据固定空间，创建线程太多导致oom，使用64vm或者减少堆大小或者减少每个线程栈大消除以增大可用线程数，每个线程内调用方法太深导致sof。
* Xms、Xmx：堆，不断创建对象(OOM:内存泄漏(GCROOT)、内存溢出(生命周期、堆参数))；字符串常量池；P63
* XX:DirectMemery：直接；内存区

##### 线程数限制

JVM中可以生成的最大数量由JVM的堆内存大小、Thread的Stack内存大小、系统最大可创建的线程数量（Java线程的实现是基于底层系统的线程机制来实现的，系统可以生成的最大线程数：/proc/sys/kernel/threads-max默认 14553，系统可创建的最大pid数：/proc/sys/kernel/pid_max，默认值是 `32768`）三个方面影响。

增大堆内存（-Xms，-Xmx）会减少可创建的线程数量（栈区=可用内存-堆-直接内存），增大线程栈内存（-Xss，32位系统中此参数值最小为60K）也会减少可创建的线程数量（每个现象独立栈，栈区空间一定下，单个线程栈占据内存越小，可创建线程越多）。

##### cpu占用过高
- 运行 `top` 或 `htop` 命令可以查看系统中所有进程的CPU占用情况。你可以根据进程ID（PID）找到你的Java进程。看到 `java` 进程的 PID 和 CPU 占用率。
- `jps -mlv`：得到PID+main方法参数+主类包名+JVM参数。
* 使用 `VisualVM` 或 `JConsole` 这类图形化工具来连接JVM进程，查看内存使用情况、线程状态、CPU使用、GC统计等指标。判断是否存在无限循环或高频繁调用的函数、不当的并发控制（如死锁或线程竞争）、不合理的资源管理（如频繁的数据库查询、文件I/O等）。
* 业务代码问题：获取线程栈：`jstack pid >filename.log`，线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，得到线程状态（TIMED_WATING、WATING、BLOCKED、RUNNABLE）、调用关系，CPU执行时间，锁的持有状态（locked），等待锁的状态(waiting to lock)，等待事件(Wait on condition )。通过分析高cpu线程的栈快照，以定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。 
* GC问题：`jstat -gc <PID> 1000`，输出GC的状态信息，查看是否存在频繁的GC。`VisualVM`分析堆快照，获得各类型对象数量与占据空间，与GC root间引用关系。

##### 服务缓慢
1. 硬件资源瓶颈
CPU: 通过监控工具查看 CPU 使用率。如果 CPU 使用率持续高，可能存在计算密集型的操作，或者线程数过多。
内存: 内存不足可能导致频繁的垃圾回收（GC），导致响应慢。查看内存使用情况和GC日志。
磁盘 I/O: 磁盘 I/O 性能差可能影响应用的读写性能。查看磁盘的读写速度和负载。
2. 垃圾回收（GC）
GC频繁: 如果垃圾回收频繁且停顿时间长，可能导致性能下降。可以通过JVM的GC日志查看停顿时间和GC次数，必要时调整堆内存大小和GC策略。
JVM参数: 调整 JVM 参数（如 -Xms、-Xmx、-XX:MaxMetaspaceSize）来优化内存分配，避免频繁的 GC。
3. 数据库瓶颈
查询性能差: 检查数据库的查询是否优化，是否存在慢查询或未使用索引的情况。可以使用数据库的慢查询日志分析。
数据库连接池: 数据库连接池配置不当（如连接池大小过小）可能导致数据库连接等待，影响性能。
网络延迟: 数据库的网络延迟可能会影响访问速度，确保数据库与应用服务在同一局域网或有快速的网络连接。
4. 线程阻塞
线程池配置不当: 如果线程池大小过小，或者处理任务的队列过长，可能会导致请求排队等待。检查应用中的线程池配置（如 ExecutorService 或线程池的大小）。
死锁: 如果存在死锁，线程无法正常执行，导致服务变慢。使用线程分析工具（如 jstack）来查看是否存在死锁。
5. 网络瓶颈
网络延迟和带宽限制: 服务之间的通信（如微服务之间的调用）可能由于网络延迟或带宽限制而变慢。可以通过网络监控工具检查网络性能。
DNS解析问题: 如果服务的 DNS 解析存在问题，也可能导致延迟。可以通过查看 DNS 查询日志进行排查。
6. 应用代码
N+1查询: 检查代码中是否存在数据库查询时未进行批量查询，导致大量的 N+1 查询。
不合理的算法: 代码中的复杂算法或循环可能导致性能问题。可以使用性能分析工具（如 JProfiler、YourKit）定位瓶颈。
缓存缺失: 如果某些数据不使用缓存，而每次请求都重新计算或查询，可能会导致响应慢。检查缓存配置（如 Redis、Ehcache）是否合理。
7. 外部依赖
第三方 API: 如果服务依赖外部 API 或服务（如支付、短信等），第三方服务的性能不佳或网络延迟可能导致响应缓慢。
消息队列: 如果使用了消息队列（如 Kafka、RabbitMQ），队列的堆积、消费者处理不及时也可能导致性能问题。
8. 负载均衡
负载均衡不均衡: 如果负载均衡器分配不均，可能导致某些实例负载过高，影响整体性能。检查负载均衡的策略和健康检查。
9. 日志过多
日志输出过多: 如果应用大量输出日志，特别是同步日志，会导致性能下降。可以调整日志级别或异步记录日志。
##### 频繁GC

https://tech.meituan.com/2017/12/29/jvm-optimize.html

* `jstat -gc pid interval count` 查看 GC 情况。eden、survior0/1、老年代、元空间容量及使用情况，young/full GC 次数和耗时。
* 堆内存配置过小 ：总大小3-4 倍活跃数据的大小; 新生代1-1.5 活跃数据的大小;老年代2-3 倍活跃数据的大小，确保 `-Xms` 和 `-Xmx` 配置适当。

* full gc 触发条件一般是 老年代空间不足，大量对象频繁进入老年代 + 老年代空间释放不掉。
  1，系统并发高、或者数据量过大，导致 young gc频繁，且gc后存活对象太多，动态年龄判断：每次gc存货对象年龄加一，当survior区中某个年龄对象占据内存大小占survior区容量的一半，将自动更新晋升老年代的阈值，降低进入老年代门槛，下次GC时将年龄超过阈值的对象被晋升到老年代，
  2，内存担保：survivor 区存放不下存活对象，直接放入老年代，老年代迅速堆满。调整内存分配比例 eden，survior0，survior1默认8:1：       1，增大survior区占比。
  3，程序一次性加载过多对象到内存 （大对象：内存担保），导致频繁有大对象进入老年代 造成full gc。
  4，gc频率持续上涨，而且full gc后回收效果不好，可能存在内存溢出的情况，老年代驻留了大量释放不掉的对象， 只要有一点点对象进入老年代就触发 full gc。 dump 排查具体原因。
  5，年轻代和老年代的内存都比较低，可能是元数据区加载了太多类，或者大量使用cglib工具生成大量代理类，触发full gc。
  6，老年代内存不高，频繁发生full gc，手动System.gc()。

* young GC、minor GC ： 使用 `jmap` 或 `jstat` 监控堆的使用情况。 **S0/S1**: 年轻代的两个 Survivor 区的使用情况，频繁变化可能表示频繁的垃圾回收。通常情况下，由于新生代空间较小，Eden区很快被填满，就会导致频繁Minor GC，因此可以通过增大新生代空间来降低Minor GC的频率。避免经常发生内存担保和动态晋升年龄计算，对象在新生代得到充分回收，只有生命周期长的对象才进入老年代,这样老年代增速变慢，full GC频率自然也会降低，同时因为单次 Young GC 时间更多取决于存活对象的数量，而非 Eden 区的大小，增大新生空间不会明显增大young GC 耗时。如果应用存在大量的短期对象，应该选择较大的年轻代；如果存在相对较多的持久对象，老年代应该适当增大。

* MaxTenuringThreshold 要尽量合理，不能设置太大，否则有些长寿对象在每次 GC 时都会在两个 Survivor 区之间来回复制，无疑是增加了复制阶段的耗时，新生代不断增长直到Survivor区溢出，一旦溢出发生，Eden+Svuvivor中对象将不再依据年龄全部提升到老年代，这样对象老化的机制就失效了。设置过小使对象过早晋升，即对象不能在新生代充分被回收，大量短期对象被晋升到老年代，老年代空间迅速增长，引起频繁的full GC。

* 大量使用直接内存（例如，通过 NIO的`ByteBuffer`）。

* **`-XX:MaxGCPauseMillis`**: 这个参数用于设置 G1 垃圾回收器的最大停顿时间目标。如果设置过低，G1 会尝试尽可能减少垃圾回收的停顿时间，可能导致频繁的小规模垃圾回收，进而增加整体的 GC 频率。
* **`-XX:G1HeapRegionSize`**:G1 会将堆划分为多个区域。`G1HeapRegionSize` 影响每个区域的大小，如果设置得过小，可能导致频繁的标记和回收，因为每个区域的垃圾回收都可能需要处理更多的对象。
* **`-XX:G1ReservePercent`**: G1 会保留一定比例的堆空间来应对临时的内存需求。如果设置的值过高，可能导致 G1 无法有效回收空间，从而增加 GC 频率。

##### OOM

https://www.anvilliu.com/2021/04/01/JVM%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%EF%BC%88OOM%EF%BC%89%E7%9A%849%E7%A7%8D%E7%B1%BB%E5%9E%8B/

https://blog.51cto.com/u_15257216/2861461

* OOM heap space：java堆内存溢出，一般由于内存泄露或者堆的大小设置不当导致内存溢出引起。内存泄露就是某些对象不再被应用程序使用，而GC无法回收的情况，这些对象会无限期保留在Java堆空间中，最终堆积触发（使用了 File 等资源没有回收，ThreadLocal用完未remove），需要通过内存监控软件查找程序中的泄露代码；；堆大小可以通过虚拟机参数-Xms,-Xmx等修改。

  `jmap -dump:format=b,file=file_name pid_java `实时导出堆信息，对Dump出来的堆转储快照进行分析，哪里发生了内存泄露，哪些对象占据了堆的大部分，这些对象在代码中的位置。确认内存中的对象是否是必要的，也先分是内存泄漏还是内存溢出。如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链，这样就能够找到泄漏的对象是通过怎么样的路径与GC Roots相关联的导致垃圾回收机制无法将其回收，掌握了泄漏对象的类信息和GC Roots引用链的信息，就可以比较准确地定位泄漏代码的位置。

  如果不存在泄漏，那么就是内存溢出，内存中的对象确实必须存活着，申请的内存超出了JVM能提供的内存大小。那么此时就需要通过虚拟机的堆参数（ -Xmx和-Xms）来适当调大参数；从代码上检查是否存在某些对象存活时间过长、持有时间过长的情况，尝试减少运行时内存的消耗。

* OOM MetaSpace :元空间溢出，存放了被虚拟机加载的类信息，一般出现于大量Class，或者采用cglib等反射机制的情况，因为上述情况会产生大量的Class信息存储于方法区。检查代码中是否存在大量的反射生成的代理类操作。根据dump出的堆找到已加载的类中查找最昂贵的类加载器，从此类加载器中可以提取已加载类，并且按实例对此类进行排序，以使可疑对象排在首位，以此排除造成该OOM问题的程序代码。应用长时间运行，类型数据回收条件苛刻，重启强制回收。通过更改方法区的大小来解决，使用MetaspaceSize、MaxMetaspaceSize来修改。

* OOM stack：每个线程拥有独立栈，栈区空间大小一定下，可创建线程总数存在上限，不断创建线程将导致OOM，尝试减少每个线程栈大小-Xsm，单个线程栈占据内存越小，可创建线程越多。一台服务器可以创建的线程数依赖于物理配置和平台，如最大pid值、可创建线程总数限制。

* SOF：JVM 虚拟机栈是有深度的，在执行方法的时候会伴随着入栈和出栈。程序中存在深度递归调用、方法内声明了海量的局部变量导致栈帧大小增大、执行了大量方法，导致线程栈空间耗尽，栈大小设置太小也会出现此种溢出。修复引发无限递归调用的异常代码；排查是否存在类之间的循环依赖（当两个对象相互引用，在调用toString方法时也会产生这个异常）；需要执行大量方法或包含大量局部变量，这时可以通过虚拟机参数-Xss来适当地提高线程栈空间限制。

* OOM GC overhead limit：当Java进程绝大部分时间都在进行GC，但是只恢复了很少可用堆空间，连续多次GC都是如此那么就会抛出异常。这个错误是为了避免GC最终消耗了100%的CPU，而实际应用程序无法正常进行任何实际工作。分析是哪个地方在大量消耗内存，并且无法正常回收，通过jmap -heap pid查看堆内存占用，看是否本身分配过小，加大内存。

* Out of swap space：swap溢出，当JVM请求的总内存大于可用物理内存时，操作系统会开始把数据从内存中换到硬盘中。当数据将交换空间填满，并且物理空间也被填满之后会报出这个错误。操作系统配置的交换空间不足，有别的进程消耗了所有内存资源。可以增加交换空间的大小，但是对于Java的垃圾回收而言，交换是不希望发生的，因为交换过后的内存分配可能让GC暂停时间增加几个数量级。尽量避免别的进程和主要服务端程序竞争内存资源。也可以进行内存升级以从根本上增加内存大小。

* OOM native method：本机方法（native method）分配失败，使用操作系统本地工具进行诊断，难度较大。

* OOM Direct buffer memory：NIO使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样在一些场景就避免了 Java 堆和 Native 中来回复制数据，所以性能会有所提高。由于是分配 OS 本地内存，不属于 GC 管辖范围，如果不断分配本地内存，堆内存很少使用，那么 JVM 就不需要执行 GC，DirectByteBuffer 对象就不会被回收，这时虽然堆内存充足，但本地内存可能已经不够用了，就会出现 OOM，本地直接内存溢出。

  通过启动参数 MaxDirectMemorySize 调整 Direct ByteBuffer 的上限值；通过反射调用 sun.misc.Cleaner的 clean() 方法来主动释放被 Direct ByteBuffer 持有的内存空间。

* OOM array size：大数组，物理空间连续，无法找到一块足够大的内存容纳当前对象。JVM 限制了数组的最大长度，JVM 在为数组分配内存前，会检查要分配的数据结构在系统中是否可寻址，通常为 Integer.MAX_VALUE-2。尽量不要用一个特别大的数组去储存，可以分成较小的多个数组批量加载需要的数据）

* OOM Kill process：当内核检测到系统内存不足时，OOM killer 被激活，然后选择一个进程杀掉。Linux 内核允许进程请求比系统中可用内存更多的内存，但当大多数应用程序都消耗完自己的内存时，这些应用程序的内存需求加起来超出了物理内存（包括swap）的容量，内核（OOM killer）必须杀掉一些进程才能腾出空间保障系统正常运行。升级内存。

##### 堆、栈

栈（Stack）：栈是后进先出的顺序，最后被申请的块最先被释放。当函数被调用时，栈（Stack）队列上有一块区域会被分配出来用作存储局部变量和数据。当函数返回时，这块区域会被释放。Java中保存方法栈帧，生命收起和线程相同，线程结束自动回收释放。

堆（heap）的分配是在程序运行时完成的，分配速度较为缓慢，但是堆的可用空间非常的大。堆中的元素相互之间没有关联，各自都可以被任何时候随机访问。Java中保存对象、字符串常量，需要GC回收废弃对象。

![700](%E9%9D%A2%E7%BB%8F.assets/2002319-20210104192334091-1129829693.png)

##### 逃逸分析

https://www.cnblogs.com/hollischuang/p/12501950.html

### JDK源码

##### 集合

Java 集合， 一个是 Collection接口，主要用于存放单一元素；另一个是 Map 接口，主要用于存放键值对。对于Collection 接口，下面又有三个主要的子接口：List、Set 和 Queue。

* List: 存储的元素是有序的、可重复的。Arraylist：object[] 数组、LinkedList：双向链表。
* Set: 存储的元素是无序的、不可重复的。HashSet：（hashmap value=new Object()）,hashcode、equals保证唯一性,增删改查O(1);TreeSet：红黑树.compare接口实现唯一性,增删改查块O(logn)。
* Queue: 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。PriorityQueue: Object[] 数组来实现二叉堆。ArrayQueue: Object[] 数组 + 双指针。
* Map: 使用键值对（key-value）存储，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。LinkedHashMap： 底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。

##### ArrayList

1，初始化：未指定容量则数组大小为0，第一次插入时数组扩容到10，指定容量就是用该容量。

2，扩容：初始情况下，数组长度扩容为10（默认的）；正常情况下，新数组的长度是原数组的1.5倍，如果1.5倍不满足条件，则使用最小需求容量为新容量，如果1.5倍新容量满足小于最大长度条件下返回，否则数组长度最大为Integer.MAX_VALUE左右。将旧数组内容通过Array.copyOf全部复制到新数组。

3，插入：插入到数组末尾，首先判断是否需要扩容，然后给尾插赋值，时间复杂度为`O(1)`。插入到指定位置，判断是否需要扩容，然后通过`System.arraycopy`将`[index, size - 1]`的元素移动到`[index + 1, size]`，然后插入。

4，删除：删除指定位置的元素，先将通过`System.arraycopy`把指定位置后面的所有元素向前移动一位，再将最后一个位置元素置为`null`。

5，定位：`contains,indexOf`需要存储元素实现`equals`方法。

6,序列化：`elementData`属性前有`transient`关键字，这表示`elementData`不会被序列化。`ArrayList`自定义了`writeObject`和`readObject`方法，实现了`elementData`序列化和反序列化的逻辑，只保存非`null`数据。

7，迭代器：通过`foreach`访问元素的时候，不要对`ArrayList`进行修改，如果修改了`modCount`的值，那么会抛出`ConcurrentModificationException`异常。遍历时删除元素：逆向遍历List删除，避免未遍历元素位置的移动；使用迭代器中的remove方法。

8，线程安全：`Collections.synchronized(list)`，在ArrayList外面包装一层同步机制。CopyOnWriteArrayList：volatile transient声明的数组 array保证可见性；写时复制，主要是一种读写分离的思想。就是增删改时，先使用`synchronized`加锁，然后把ArrayList复制一个出来完成修改，再把ArrayList的引用指向扩容后的，最后释放锁，时间复杂度是O(n)。读的时候不需要加锁，如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据。CopyOnWrite并发容器用于读多写少的并发场景。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。

```java
public boolean add(E e) {
    synchronized (lock) {
        Object[] es = getArray();
        int len = es.length;
        es = Arrays.copyOf(es, len + 1);
        es[len] = e
        setArray(es);
        return true;
    }
}
public E get(int index) {
    return elementAt(getArray(), index);
}
```



##### LinkedList

1，双向链表，保存头尾节点。增删改查时根据目标下标是在前半部分还是后半部分，分别从头和尾开始遍历。

2，定位：`contains,indexOf`需要存储元素实现`equals`方法。

3，序列化：自定义了`writeObject`和`readObject`方法，只保存非`null`数据。

4，线程安全：`Collections.synchronized(list)`，在ArrayList外面包装一层同步机制；使用ConcurrentLinkedQueue。

##### HashMap

* 实现

[https://wafer.li/blog-corners/rollroll/interview/hashmap-%E7%9A%84-loadfactor-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF-0-75/](https://wafer.li/blog-corners/rollroll/interview/hashmap-的-loadfactor-为什么是-0-75/)

https://segmentfault.com/a/1190000023308658

https://xie.infoq.cn/article/66315679baf14c42725bafb08

填装因子:loadFactor是HashMap负载程度的一个度量，即HashMap持有的元素数量和HashMap大小的比值，loadFactor是为了让HashMap尽可能不满而存在的，理论上一次成功/不成功的查找耗时均为O(1+a)，a为装载因子，加载因子越大,填满的元素越多,空间利用率越高，但冲突的机会加大了，查找时间复杂度上升。反之加载因子越小，填满的元素越少，冲突的机会减小，查找时间复杂度下降，但空间浪费多了。当HashMap中的元素数量大于capacity*loadFactor时，HashMap就要扩容，并进行重新计算元素存储位置。

各种情形下设置也不尽相同，比如ThreadLocalMap的装载因子为2/3。转载因子变大查询复杂度升高，但是占用的空间降低了，对于内存消耗频繁/GC频繁的应用来说，如果能接受hashmap的查询耗时损耗，将转载因子变大可能是非常值得的。

* 链表转红黑树阈值

虽然红黑树有更好的查找效率O(log(N))，但是TreeNode的大小约为链表节点的两倍，在红黑树进行插入、删除等操作时为了平衡红黑树还要进行额外的操作，维护成本明显高于链表。所以只有在一个拉链已经拉了足够节点（默认为8）并且HashMap容量大于等于64的时候才会转为tree，否则进行扩容（容量较小发生大量冲突直接扩容，此时的空间复杂度可以忍受）。在理想情况下，使用随机的hashcode值，loadfactor为0.75情况，桶中的Node的分布频率服从参数为0.5的泊松分布：桶中出现8个数据的概率已经小于一千万分之一，该情形达到的概率的较小，并且当这个hash桶的节点因为移除或者扩容后resize数量变小（默认为6）的时候，我们会将树再转为拉链，可见引入红黑树冲突解决是作为极端情况下的兜底方案（比如哈希DoS攻击：RESTful兴起，数据传输使用Json，在收到Json字符串后进行jsonDecode操作，攻击者借由发送一条充满数千个变量的POST报文，所有变量的hashcode相同，在将数据存入HashMap时，某个哈希桶中有大量数据，导致哈希函数就会超载，仅是处理此单一请求也需要大量时间,n个数据插入复杂度O(N^2)），所以将阈值设为8，此时不会经常出现链表转红黑树的情况，而达到阈值的哈希桶也可以红黑树实现更快的查找，实现兜底。

* 哈希计算

`hashCode=31*hashCode+element.hashCode()`，选择值31是因为它是一个奇素数。如果它是偶数并且乘法的结果溢出，高位信息就会丢失，因为乘以2相当于左移。31一个很好的特性是乘法可以通过移位，并获得更好的性能减法来代替：``31*i==(i<<5)-i`，现代虚拟机会自动进行这种优化。实验表明从超过50,000个英语单词计算哈希值时，使用常量31、33、37、39和41将在每种情况下产生少于7次的冲突，这可能是许多Java实现选择此类常量的原因。

`hash=(h=key.hashCode())^(h>>>16)`，key的hash值高16位不变，低16位与高16位异或作为key的最终hash值，最后元素下标为：`index=（n-1）&hash`，(本质为除n取余，当且仅当n=2^k时成立)，其中n=table.length。

![2884823463jdfdjfgjdf](%E9%9D%A2%E7%BB%8F.assets/2884823463jdfdjfgjdf.png)

因为table的长度都是2的幂，因此如果对hashCode直接取余，index仅与hashCode的低n位有关，hashCode的高位都被与操作置为0了，这样做很容易产生碰撞。设计者权衡了speed,utility,andquality，通过将高16位与低16位异或来获得hsah值，使下标值同时用到高位与低位的信息，hashCode只要有一位发生改变，整个hash返回值就会改变，保证了hash值的随机性。设计者考虑到现在的hashCode分布的已经很不错了，而且当发生较大碰撞时也用树形存储降低了冲突。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。

* 插入

->延迟初始化；桶为空直接插入。
->如果是链表则一次比较`hash`以及`== or key.equals()`相等则替换（如果设置了onlyIfAbsent标志，则不会替换），否则比较下一个元素，都不成立则尾插到末尾，再判断是否需要生成红黑树。
->如果是红黑树则调用红黑树的插值方法插入新节点。红黑树中大小比较顺序：hash->equals->比较器，hash若相等则比较`equals or ==`，相等则替换，不等则尝试使用key的比较器决定左下移还是右下移，如果key未实现比较器或者实现了比较器且比较器返回相等，则到左子树和右子树查找，如果比较器返回不等，则到左子树或者右子树查找。
->最后判断是否要扩容。
```java
static class Node<K,V> implements Map.Entry<K,V> {
	final int hash;
	final K key;
	V value;
	Node<K,V> next;
}

final V putVal(int hash, K key, V value, boolean onlyIfAbsent,  
               boolean evict) {  
    Node<K,V>[] tab; Node<K,V> p; int n, i;  
    // 延迟初始化
    if ((tab = table) == null || (n = tab.length) == 0)  
        n = (tab = resize()).length;  
    // 桶为空直接写入
    if ((p = tab[i = (n - 1) & hash]) == null)  
        tab[i] = newNode(hash, key, value, null);  
    else {  
        Node<K,V> e; K k;  
        // hash相等 and ( == or equals )直接替换
        if (p.hash == hash &&  
            ((k = p.key) == key || (key != null && key.equals(k))))  
            e = p;  
        else if (p instanceof TreeNode)  
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);  
        else {  
            for (int binCount = 0; ; ++binCount) {  
                if ((e = p.next) == null) {  
		            // 插入队尾，在判断是否要转换红黑树
                    p.next = newNode(hash, key, value, null);  
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st  
                        treeifyBin(tab, hash);  
                    break;  
                }  
                if (e.hash == hash &&  
                    ((k = e.key) == key || (key != null && key.equals(k))))  
                    break;  
                p = e;  
            }  
        }  
        if (e != null) { // existing mapping for key  
            V oldValue = e.value;  
            if (!onlyIfAbsent || oldValue == null)  
                e.value = value;  
            afterNodeAccess(e);  
            return oldValue;  
        }  
    }  
    // 元素增加后是否要扩容
    ++modCount;  
    if (++size > threshold)  
        resize();  
    afterNodeInsertion(evict);  
    return null;  
}
final TreeNode<K,V> putTreeVal(HashMap<K,V> map, Node<K,V>[] tab,  
                               int h, K k, V v) {  
    Class<?> kc = null;  
    boolean searched = false;  
    TreeNode<K,V> root = (parent != null) ? root() : this;  
    for (TreeNode<K,V> p = root;;) {  
        int dir, ph; K pk;  
        // 比较hash决定查找左右树
        if ((ph = p.hash) > h)  
            dir = -1;  
        else if (ph < h)  
            dir = 1;  
        // hash相等 and (== or equals) 
        else if ((pk = p.key) == k || (k != null && k.equals(pk)))  
            return p;  
        // 如果实现了compare接口，并且接口返回相等则到左子树和右子树查找
        // 如果没有实现接口，则到左子树和右子树查找
        else if ((kc == null &&  
                  (kc = comparableClassFor(k)) == null) ||  
                 (dir = compareComparables(kc, k, pk)) == 0) {  
            // 如果compare接口返回相等，或者未实现接口，则到左右子树查找
            if (!searched) {  
                TreeNode<K,V> q, ch;  
                searched = true;  
                if (((ch = p.left) != null &&  
                     (q = ch.find(h, k, kc)) != null) ||  
                    ((ch = p.right) != null &&  
                     (q = ch.find(h, k, kc)) != null))  
                    return q;  
            }  
            dir = tieBreakOrder(k, pk);  
        }  
		// 实现了接口且返回不等，则到左子树右或者子树查找
        TreeNode<K,V> xp = p;  
        if ((p = (dir <= 0) ? p.left : p.right) == null) {  
            Node<K,V> xpn = xp.next;  
            TreeNode<K,V> x = map.newTreeNode(h, k, v, xpn);  
            if (dir <= 0)  
                xp.left = x;  
            else  
                xp.right = x;  
            xp.next = x;  
            x.parent = x.prev = xp;  
            if (xpn != null)  
                ((TreeNode<K,V>)xpn).prev = x;  
            moveRootToFront(tab, balanceInsertion(root, x));  
            return null;  
        }  
    }  
}
```
* 扩容

容量变为以前的两倍`newCap=oldCap<1`。
无论是红黑树还是链表都是挨个计算`(e.hash&oldCap)==0?`(其中`oldCap=2^k`)是否成立，如果成立表明hash的第`k+1`个二进制为0，此时`newIndex=(newCap-1)&hash`的最高位也就是第k个二进制位为0，也是时`newIndex=oldIndex`，`newIndex`仍旧在原先的旧位置，如果hash的第k个二进制为1，则newIndex相较于oldIndex多出来第k位，也就是`newIndex=2^k+oldIndex=oldCap+oldIndex`。
通过遍历桶中元素，将元素分为低位(oldIndex)、高位(oldCap+oldIndex)两个链表。如果桶里面原先装的是红黑树还要判断各自是否满足树化条件，如果满足还要转换为红黑树，，之后将两个集合放入新bucket数组完成扩容。
扩容的时间复杂度为O(N)，一次扩容后还能再插入N个数据，所以扩容的成本可以均摊到后续N个元素中，每个元素的扩容成本为O(1)，最终元素的插入时间复杂度仍为O(1）。

* 初始化参数

初始化容量：initialCapacity的默认值是16，即使内存足够，也不能将initialCapacity设得过大，虽然大初始化容量可避免扩容导致的效率的下降，get和put方法都是常数复杂度的，也不是因此而增加时间复杂度。但是实际的程序可能不仅仅使用get和put方法，也有可能使用迭代器，如使用EntrySet迭代时，底层实现时挨个遍历哈希桶，再在桶里挨个遍历节点，如果initialCapacity容量较大，导致大量空哈希桶，那么会使迭代器效率降低。所以理想的情况还是在使用HashMap前估计一下数据量，太小反复扩容导致得数组复制、重新计算下标、重新构建红黑树的开销，太大空间利用率低，迭代器遍历成本上升。

* key选择

key最好选择Immutable对象（Immutable：创建之后就不能发生改变，任何对它的改变都应该产生一个新的对象；对象应该是final的，以此来限制子类继承父类，以避免子类改变了父类的immutable特性；如果类中包含mutable类对象，那么返回给客户端的时候，返回该对象的一个拷贝，而不是该对象本身，防止用户修改）。
如果不是不可变对象，需要参与计算hashCode、equals、compare得字段不变即可。
覆写hashCode()以及equals()方法。
如果在HashMap中使用可变对象作为Key带来的问题：如果HashMapKey发生变化，导致hashCode()/equal()的结果改变，那么该key在HashMap中的存取时可能再也查找不到这个Entry了。
常见的Key比如String、Integer这些类已经很规范的覆写了hashCode()以及equals()方法，并且作为不可变类天生是线程安全的，可以不用被synchronize就在并发环境中共享，可以很好的优化比如因为不可变所以可以缓存hash值，避免重复计算等。

```java
@Override
public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof Main main)) return false;
    return x == main.x && y.equals(main.y);
}

@Override
public int hashCode() {
//    int result = 1;
//    for (Object element : fields)
//        result = 31 * result + element.hashCode();
    return Objects.hash(x, y);
}
```

* 成环

  https://juejin.cn/post/6844903554264596487（多线程使用头插法直接搬移元素 a->b->c ==>   c ->b -> a ）

  JDK8通过尾插和拆分两个链表后再赋值解决。

##### 比较

[HashMap?ConcurrentHashMap?相信看完这篇没人能难住你！|crossoverJie'sBlog](https://crossoverjie.top/2018/07/23/java-senior/ConcurrentHashMap/)

[阿里面试官经常问的HashMap和ConcurrentHashMap，相信看完这篇没有面试官能再难住你-SegmentFault思否](https://segmentfault.com/a/1190000023843490)

[面试必备：HashMap、Hashtable、ConcurrentHashMap的原理与区别-猿人谷-博客园(cnblogs.com)](https://www.cnblogs.com/heyonggang/p/9112731.html)

[深入解析ConcurrentHashMap实现内幕，吊打面试官，没问题-SegmentFault思否](https://segmentfault.com/a/1190000021237438?utm_source=sf-similar-article)

[探究HashMap线性不安全（二）——链表成环的详细过程-比脚更长的路-博客园(cnblogs.com)](https://www.cnblogs.com/lonelyjay/p/9726187.html)

[面试：为了进阿里，死磕了ConcurrentHashMap源码和面试题(一)-SegmentFault思否](https://segmentfault.com/a/1190000024432650?utm_source=sf-similar-article)

[面试：为了进阿里，死磕了ConcurrentHashMap源码和面试题(二)-SegmentFault思否](https://segmentfault.com/a/1190000024439085)

[HashMap源码分析-简书(jianshu.com)](https://www.jianshu.com/p/b40fd341711e)

* HashMap VS HashTable VS ConcurrentHashMap

Hashtable、ConcurrentHashMap是线程安全，HashMap是非线程安全。多线程环境下HashTable的对数据进行修改的方法都使用了synchronized描述符，来满足线程安全的特性，使用了对象级别的同步锁，读和写操作都需要获取锁，本质上仍然只允许一个线程访问，其他线程被排斥在外，当每次对Map做修改操作的时候都会锁住这个Map对象。HashMap在多线程环境下也可以使用Collections.synchronizedMap()方法来获取一个线程安全的集合。Collections.synchronizedMap()实现原理是Collections定义了一个SynchronizedMap的内部类，这个类实现了Map接口，在调用方法时使用synchronized来保证线程同步，虽然synchronized不再放在方法上，而是放在方法内部，使用this作为互斥量作为同步块出现，但仍然是对象级别的同步锁，和hashTable没有太大区别。HashTable已经被淘汰了，如果不需要线程安全，那么使用HashMap，如果需要线程安全，那么使用ConcurrentHashMap。

ConcurrentHashMap底层使用Node(value 、next都用了volatile修饰，保证了可见性)数组+链表+红黑树的数据结构来实现，并发控制使用synchronized和CAS来操作
定位出的节点如果为空表示当前位置可以写入数据，利用CAS尝试写入，写入数据时调用Unsafe的本地方法写入数据，此时使用CAS乐观锁写入数据，性能可以得到很大提升；
如果获得的元素非空或者cas失败，利用synchronized锁住桶中的第一个节点，这里是对数组元素加锁（Node），无论是相较于Collections.synchronizedXXX返回的包装类还是HashTable，加锁粒度更细，多个桶可以并发读写。然后查找key，找到则替换找不到则插入尾部，最后进行红黑树转换与扩容
```java
    transient volatile Node<K,V>[] table;
    
	static class Node<K,V> implements Map.Entry<K,V> {
		final int hash;
		final K key;
		volatile V val;
		volatile Node<K,V> next;
	}
	
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh; K fk; V fv;
            // 延迟初始化
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            // bucket空，cas尝试修改一次
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null, new Node<K,V>(hash, key, value)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else if (onlyIfAbsent // check first node without acquiring lock
                     && fh == hash
                     && ((fk = f.key) == key || (fk != null && key.equals(fk)))
                     && (fv = f.val) != null)
                return fv;
            // bucket非空或者为空但是cas失败，锁住bucket第一个元素
            else {
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            // 查找目标key，找到则替换，找不到则插入尾部
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key, value);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                        else if (f instanceof ReservationNode)
                            throw new IllegalStateException("Recursive update");
                    }
                }
                // 红黑树化
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        // 扩容 
        addCount(1L, binCount);
        return null;
    }
	private final void addCount(long x, int check) {  
	    CounterCell[] cs; long b, s;  
	    // 借用Longadder的设计思路来统计map的当前容量，减少锁竞争
	    // 维护一个Long的数组，多个线程并发修改时，选取数组中没有被占用的Long进行加减，最后计算结果时将数组内的数字求和
	    if ((cs = counterCells) != null ||  
	        !U.compareAndSetLong(this, BASECOUNT, b = baseCount, s = b + x)) {  
	        CounterCell c; long v; int m;  
	        boolean uncontended = true;  
	        if (cs == null || (m = cs.length - 1) < 0 ||  
		        // 随机选取下标cas尝试修改
	            (c = cs[ThreadLocalRandom.getProbe() & m]) == null ||  
	            !(uncontended =  
	              U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x))) {  
	            fullAddCount(x, uncontended);  
	            return;  
	        }  
	        if (check <= 1)  
	            return;  
	        // 对long数组求和得到map数据个数
	        s = sumCount();  
	    }  
	    if (check >= 0) {  
	        Node<K,V>[] tab, nt; int n, sc;  
	        // sizeCtl是扩容阈值，当当前容量大于扩容阈值时，触发扩容
	        // 在进入扩容逻辑后，sizeCtl会变成负数，高16位是扩容的邮戳，低16位是同时进行扩容时的线程数
	        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&  
	               (n = tab.length) < MAXIMUM_CAPACITY) {  
	            int rs = resizeStamp(n) << RESIZE_STAMP_SHIFT;  
	            // 标识已经在扩容中
	            if (sc < 0) {  
		            // 小于等于0，则表示已经迁移完
	                if (sc == rs + MAX_RESIZERS || sc == rs + 1 ||  
	                    (nt = nextTable) == null || transferIndex <= 0)  
	                    break;  
	                // 将sizeCtl值+1表示扩容线程数+1
	                if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1))  
	                    transfer(tab, nt);  
	            }  
	            else if (U.compareAndSetInt(this, SIZECTL, sc, rs + 2))  
	                transfer(tab, null);  
	            s = sumCount();  
	        }  
	    }  
	}
```

`transfer`方法中从右到左开始移动数据，使用`transferIndex`标识当前未处理区间右边界。每个扩容线程CAS修改`transferIndex`，为自己分配长度为16的区间，防止多个线程工作区间重叠。每个桶扩容计算方法和HashMap一致，但是会锁住原本桶防止写入和扩容并发执行。
![[file-20241203013858339.png|550]]
* 如果在扩容桶时并发写入数据，put的线程失败或者扩容的线程失败，再重新触发对应的put或者扩容逻辑，避免并发问题。
* get方法无锁，使用读写分离的思路解决扩容时也能正确获取值：在转移桶内数据时，不移动桶内数据并且不修改桶内数据的next指针，而是new一个新的node对象放到新表中，不影响读取；在桶内数据迁移完后，在原table的桶内放一个`ForwardingNode`节点，通过这个节点的`find(k)`方法能获取到对应的数据；在整个库容完成后，将新表引用赋值给`volatile`的变量table，这样更新引用的动作对其他线程可见，将到新集合读取数据；


HashMap并发不安全：两个put的key发生了碰撞(桶下标值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖。此外如果多个线程同时检测到元素个数超过数组大小 * loadFactor，会发生多个线程同时对hash数组进行扩容，可能会引起链表成环而导致死循环的错误。ConcurrentHashMap是并发安全的，插入数据时通过原子操作判断哈希桶下有没有其它线程对数据进行了修改，保证了同时只有一个线程修改链表，防止出现链表成环，然后开始写入数据；读取时按照链表或者红黑树正常读取即可（Node字段value、next都用了volatile修饰，保证了可见性）。

HashTable底层实现是数组+单链表;HashMap是数组+单链表/红黑树；ConcurrentHashMap是数组+单链表/红黑树。HashMap的初始容量为16，Hashtable初始容量为11，两者的填充因子默认都是0.75。HashMap扩容时是capacity*2，Hashtable扩容时是capacity*2+1。HashTable会尽量使用素数、奇数。而HashMap则总是使用2的幂作为哈希表的大小。当哈希表的大小为素数时，简单的取模哈希的结果会更加均匀，而HashMap使用对hashCode二次运算增强hash值得随机性，来弥补容量不是素数的缺点，同时将哈希表的大小固定为了2的幂可以用位运算来替代取余速度更快。

HashMap支持null键和null值，而HashTable、ConcurrentHashMap在遇到key或者value为null时，会抛出NullPointerException异常。这仅仅是因为HashMap在实现时对null做了特殊处理，将null的hashCode值定为了0，从而将其存放在哈希表的第0个bucket中，因此在HashMap中不能由get()方法来判断HashMap中是否存在某个key，应该用containsKey()方法（containsKey，根据key获得节点，通过判断节点是否为null来判断key是否存在，即使key和value都为null的节点，节点本身也不为null）来判断。而concurrenthashmap它们是用于多线程的，并发的，如果map.get(key)得到了null，不能判断到底是映射的value是null,还是因为没有找到对应的key而为空，相较于单线程状态的hashmap却可以用containKey（key）去判断到底是否包含了这个null；支持并发的ConcurrentHashMap在调用containskey和m.get(key)时ConcurrentHashMap可能已经不同了。

HashMap的迭代器是fail-fast（旨在停止正常运行，而不是尝试继续可能存在缺陷的过程）迭代器，而ConcurrentHashMap、HashTable的迭代器不是fail-fast的，因为要支持并发。所以当在使用迭代器遍历HashMap时数据结构上被修改（增加或者移除元素不包括更新节点值），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛ConcurrentModificationException异常。

并发问题的三个来源：原子性、可见性、有序性。ConcurrentHashMap只能保证提供的原子性读写操作是线程安全的，也就是put()、get()操作是线程安全的。可见性问题： CPU 在计算时优先从离自己最近、速度最快的 CPU 缓存中获取数据去计算，其次再从内存中获取数据，导致数据不一致。原子性问题：比如注册用户，使用先判断是否存在，再写入数据，如果两个线程同时发现用户不存在，之后都进行写数据，将导致出现重复添加问题，可以两个操作放在一起执行完，这与数据库事务的原子性理解差不多。有序性：编译器为了提高性能有时候会改变代码执行的顺序，对于单线程代码指令重排序对于执行没有什么影响，但是会对多线程并发代码执行产生不可预知的结果。原理可以参考上节的原子性问题。

提供的`putIfAbsent`接口，其含义是如果 key 已经存在则返回存储的对象，否则返回`null`，这个方法实现加了synchronized锁，为线程安全。在这个场景中如果不使用putIfAbsent就要对register(User user)方法加锁，对于性能的影响更大。


##### ThreadLocal

[Java并发-ThreadLocal详解|Java全栈知识体系(pdai.tech)](https://www.pdai.tech/md/java/thread/java-thread-x-threadlocal.html#threadlocal造成内存泄露的问题)

[Java基础进阶之ThreadLocal详解-SegmentFault思否](https://segmentfault.com/a/1190000018399795)

[ThreadLocal详解-知乎(zhihu.com)](https://zhuanlan.zhihu.com/p/34406557)

[Java之ThreadLocal详解-掘金(juejin.cn)](https://juejin.cn/post/6844903487193481224#heading-15)

ThreadLocal提供了线程局部(thread-local)变量。在多线程中为每一个线程创建单独的变量副本的类，在使用ThreadLocal类型变量进行相关操作时，都会通过当前线程获取到ThreadLocalMap来完成操作，每个线程的ThreadLocalMap是属于线程自己的，ThreadLocalMap中维护的值也是属于线程自己的，这就保证了ThreadLocal类型的变量在每个线程中是独立的，在多线程环境下不会相互影响。

一个Thread派生一个ThreadLocalMap，该线程下的多个ThreadLocal可以向Map中存值，key为ThreadLocal本身。

使用场景：某个线程下的多个方法都需要使用数据库连接，如果在每次需要连接的地方都新建一个连接，使用完再关闭，是在高并发下导致服务器压力非常大，并且严重影响程序执行性能。使用ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。

根据当前线程获得类型为ThreadLocalMap的成员属性threadLocals，threadLocals类似于HashMap（未实现Map接口），给当前线程缓存了数据，要使用的时候就从本线程的threadLocals对象中获取就可以了,key就是当前Threadlocla对象，ThreadLocal使用两个静态变量保存前一个ThreadLocal的哈希值与哈希值的递增值，hashCode从0开始，每新建一个ThreadLocal，对应的hashcode就递增一个常量。ThreadLocalMap提供了基于ThreadLocal哈希值的get、set、remove等方法。查找时如果当前线程的threadLocals未初始化，则重新创建一个ThreadLocalMap对象,并且调用当前ThreadLocal的initialValue方法（默认返回null,可被重写）生成初始值并添加到ThreadLocalMap对象中并返回。如果threadLocals中不存在以当前ThreadLocal对象为Key的的对象,那么调用当前ThreadLocal的initialValue方法生成初始值，并且添加到当前线程的threadLocals中,并返回，如果存在就返回。

ThreadLocalMap用于维护线程本地变量值，是一个Map却没有实现Map接口，用一个Entry(弱引用)数组来存储Entry。数组中的Entry并不是链表形式,而是每个bucket里面仅仅放一个Entry，使用线性探测法解决冲突，因为ThreadLocalMap中存储元素并不多，转载因子（2/3）小，发生哈希冲突也不严重，直接使用线性探查法解决即可，没必要使用拉链法额外增加复杂度,此外数据全存储在数组中可以利用CPU缓存加快查询速度。如果插入数据时发生冲突则不断后移(到尾部后移到头图)至找到空位则插入或者指向对象key为null则运行过期元素清理，因为Entry的key使用的是弱引用的方式，如果ThreadLocal外部的不存在强应用，ThreadLocal将被回收，这时就无法再访问到key对应的value，需要把这样的无效Entry清除掉来腾出空间，并将元素插入。这里能通过线性探查法能解决冲突的前提数组有空位以供插入，这是通过在插入新元素导致数组中元素个数增加时，会进行过期元素清理与容量检查，空位不足则扩容，保证插入后数组中元素永远小于长度的2/3，永远有空位。查找时如果根据哈希值计算出的下标的Entry的key对不上，则后移遍历数组寻找key相等的元素返回，找不到返回null。

##### 内存泄漏

* ThreadLocalMap使用ThreadLocal的弱引用作为Entry的key，如果一个ThreadLocal没有外部强引用来引用它，下一次系统GC时，这个ThreadLocal必然会被回收，ThreadLocalMap中就会出现key为null的Entry。而get、set、remove等方法中，都会对key为null的Entry进行清除，等下一次垃圾回收时，这些Entry将会被彻底回收。但是如果当前线程一直在运行，并且一直不执行get、set、remove方法，这些key为null的Entry的value就会一直存在一条强引用链：ThreadRef->Thread->ThreadLocalMap->Entry->value，导致这些key为null的Entry的value永远无法回收，造成内存泄漏。为了避免这种情况，我们可以在使用完ThreadLocal后，手动调用remove方法，以避免出现内存泄漏。
* 如果用线程池来操作ThreadLocal对象也会造成内存泄露,通常在一个线程结束之后，线程本地实例的所有ThreadLoacalMap都会被垃圾收集，但是对于线程池里面不会销毁的线程(核心线程),每个线程里面的ThreadLocalMap都不会被回收（未设置allowCoreThreadTimeOut=true）；此外根据工程实践如果希望通过某个类将状态(例如用户ID、事务ID)与线程关联起来，那么通常在这个类中定义private static类型的ThreadLocal实例，那么核心线程下final static修饰的ThreadLocal并不会释放,而核心线程下ThreadLocalMap对于ThreadLocal虽然是弱引用,但是ThreadLocal的static强引用不释放,弱引用当然也会一直有值,同时创建的LocalVariable对象也不会释放,就造成了内存泄露;泄露的内存=核心线程数*LocalVariable对象的大小；为了避免出现内存泄露的情况,ThreadLocal提供了一个清除线程中对象的方法,即remove,其实内部实现就是调用ThreadLocalMap的remove方法。

* 子线程获取到父线程的ThreadLocal：InheritableThreadLocal让子线程获取到父线程中的值。原理是创建子线程时，复制父线程的InheritableThreadLocal的成员变量。

  ```java
  public class BaseTest {
  
      public static  final InheritableThreadLocal<String> inheritableThreadLocal = new InheritableThreadLocal<>();
      public static final ThreadLocal<String> threadLocal = new ThreadLocal<>();
  
      public static void main(String[] args) {
          inheritableThreadLocal.set("hello");
          threadLocal.set("hello");
          new Thread(()->{
              System.out.println(String.format("子线程可继承值：%s",inheritableThreadLocal.get()));// null
              System.out.println(String.format("子线程值：%s",threadLocal.get()));//hello
          }).start();
  
  
      }
  ```
* 线程池中的线程可能会复用，因此每次执行任务时，线程池中的线程并不会像新的线程那样有自己的独立上下文。`TransmittableThreadLocal` 允许你在任务执行之前把父线程的 `ThreadLocal` 值传递给子线程，确保每个线程都能获得相同的上下文。
  ```java
  import com.alibaba.ttl.TransmittableThreadLocal;

	public class TransmittableThreadLocalExample {
	
	    // 使用 TransmittableThreadLocal
	    private static final TransmittableThreadLocal<String> ttl = new TransmittableThreadLocal<>();
	
	    public static void main(String[] args) {
	        ttl.set("父线程的值");
	
	        // 创建一个线程池并提交任务
	        ExecutorService executorService = Executors.newFixedThreadPool(1);
	        executorService.submit(() -> {
	            // 子线程能够获取到父线程的 ThreadLocal 值
	            System.out.println("子线程读取 TransmittableThreadLocal 的值: " + ttl.get());
	        });
	        executorService.shutdown();
	    }
	}

```

#####  AQS

抽象的队列式的同步器，AQS定义了一套多线程访问共享资源的同步器框架

https://www.cnblogs.com/waterystone/p/4920797.html

https://www.cnblogs.com/wang-meng/p/12816829.html

https://developer.aliyun.com/article/779674#slide-16

https://pdai.tech/md/java/thread/java-thread-x-lock-AbstractQueuedSynchronizer.html

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220402163429679.png)

维护了一个volatile int state（代表共享资源，使用volatile修饰，保证多线程间的可见性。采用乐观锁思想的CAS算法，保证原子性操作。）和一个FIFO线程同步队列（多线程争用资源被阻塞此线程以及等待的状态等信息封装成Node加入到队列中，同时阻塞该线程，等待后续的被唤醒）。

Node结点是对每一个等待获取资源的线程的封装，其包含了需要同步的线程本身、前后节点、以及Node结点的等待状态（CANCELLED：表示当前结点已取消调度、SIGNAL：表示后继结点在等待当前结点唤醒、CONDITION：表示结点等待在Condition上，当其他线程调用了Condition的signal()方法后，CONDITION状态的结点将从等待队列转移到同步队列中，等待获取同步锁）

```java
public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable {
    //头结点
    private transient volatile Node head;
    //尾节点
    private transient volatile Node tail;
    //共享状态
    private volatile int state;

	//从父类继承来的字段：Thread exclusiveOwnerThread;表示占有锁的线程

    //内部类，构建链表的Node节点
    static final class Node {
        volatile Node prev;
        volatile Node next;
        volatile Thread thread;
        // 结点状态
        // CANCELLED，值为1，表示当前的线程被取消
        // SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark
        // CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中
        // PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行
        // 值为0，表示当前节点在sync队列中，等待着获取锁
        static final int CANCELLED =  1;
        static final int SIGNAL    = -1;
        static final int CONDITION = -2;
    	static final int PROPAGATE = -3;      
        volatile int status;  
    }
}
```

* 独占、共享：独占只有一个线程能执行，如ReentrantLock，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1，此后其他线程再tryAcquire()时就会失败，被`park()`操作挂起，直到A线程unlock()到state=0为止，其它线程才有机会获取该锁；共享，多个线程可同时执行，如CountDownLatch，在初始阶段将state变量设为n，每个线程执行完毕调用done()就将state减一，state变为0会unpark()主调用线程。
* 重入、不可重入：获取锁时如果当前线程就是持有锁的线程，则累加state值，释放锁的时候也要依次递减state值，获取多少次就要释放多么次，这样才能保证state是能回到零态的，当state=0时它会唤醒同步队列里的下一个线程。
* 公平、非公平： 非公平锁在使用tryAcquire()不再判断是否需要排队，直接尝试获取锁，如果更新成功则直接返回，否则把使用addWaiter()把当前线程包装成Node进入同步队列队尾，释放锁时被唤醒的线程可能与新到来线程形成竞争关系。公平锁使用tryAcquire()尝试获取锁，会判断是否需要排队，如果不需要排队，则直接cas操作更新同步状态为1，如果需要排队再入队排队。
  区别：1，非公平锁性能高于公平锁性能。非公平锁可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。2，非公平锁性能虽然优于公平锁，但是会存在导致线程饥饿的情况。在最坏的情况下，可能存在某个线程一直获取不到锁。不过相比性能而言，饥饿问题可以暂时忽略，这可能就是ReentrantLock默认创建非公平锁的原因之一了。

* acquire：

  ```java
  public final void acquire(int arg) {
      if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
          selfInterrupt();
  }
  ```

  ![2a3c22e2ac6d0a8990f04e4920760b57](%E9%9D%A2%E7%BB%8F.assets/2a3c22e2ac6d0a8990f04e4920760b57.png)

##### 自己实现锁

http://chickenman.cn/archives/651(待改进：如果当前只有一个等待线程时，重新获取一下锁，防止永远不被唤醒；Unpark后继续锁竞争，参考https://zhuanlan.zhihu.com/p/32883297())

##### 锁

1，互斥锁、自旋锁：

互斥锁加锁失败后，线程会释放 CPU ，给其他线程，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行；互斥锁加锁失败和唤醒时，会从用户态陷入到内核态，让内核帮我们切换线程，两次线程上下文切换的成本。

自旋锁加锁失败后，线程会忙等待（可以用 `while` 循环等待实现，不会放弃 CPU），直到它拿到锁；在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换；CAS 函数就把状态查看和加锁这两个步骤合并成一条硬件级指令，形成原子指令。

2，读写锁的工作原理是：

当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。

读写锁在读多写少的场景，能发挥出优势。读写锁可以分为「读优先锁」和「写优先锁」，都会产生饿死。

3，悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁，互斥锁、自旋锁（自旋锁基于 CAS 加了while 或者睡眠 CPU 的操作而产生自旋的效果，加锁失败会忙等待直到拿到锁）、读写锁，都是属于悲观锁。

乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作，CAS 是乐观锁。

#####  Condition

相比使用Object的wait()、notify()，使用Condition中的await()、signal()这种方式实现线程间协作更加安全和高效，每个lock可以对应多个condition，每个 Condition 对象都包含着一个 FIFO 队列，实现更精细控制，比如生产者消费者模型下生产满了就fullCondition.await()等待产品被消费后唤醒，往仓库添加元素后emptyCondition.signal()唤醒等待产品的线程。消费者消费产品后fullCondition.signal()唤醒等待空位的生产者，当产品空时emptyCondition.await()等待有产品后被唤醒。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220402194810792.png)

* `await()`：方法中首先调用`addConditionWaiter()`，用当前线程创建一个Node节点，waitStatus为CONDITION，并将节点加入到该队列的尾部。接着会调用fullyRelease()释放该节点的锁，然后使用isOnSyncQueue()不断检测该节点代表的线程是否在出现在同步队列中（收到signal信号之后就会在AQS队列中检测到），如果不存在则一直挂起，否则参与竞争同步状态，来阻塞线程，直到被唤醒或被中断。当被唤醒后使用acquireQueued()来尝试获取锁。

  ```java
  public final void await() throws InterruptedException { 
      if (Thread.interrupted())   // 如果当前线程被中断过，则抛出中断异常
          throw new InterruptedException();
      Node node = addConditionWaiter();   // 添加一个waitStatus为CONDITION的节点到条件队列尾部
      int savedState = fullyRelease(node);    // 释放操作。我们知道只有在拥有锁（acquire成功）的时候才能调用await()方法，因此，调用await()方法的线程的节点必然是同步队列的头节点。所以，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的条件队列中。
      int interruptMode = 0;  
      while (!isOnSyncQueue(node)) {  // isOnSyncQueue：判断node是否在同步队列（注意和条件队列区分。调用signal方法会将节点从条件队列移动到同步队列，因此这边就可以跳出while循环）
          LockSupport.park(this); // node如果不在同步队列则进行park（阻塞当前线程）
          if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)    
              break;
      }
      if (acquireQueued(node, savedState) && interruptMode != THROW_IE)   // acquireQueued返回true代表被中断过，如果中断模式不是THROW_IE，则必然为REINTERRUPT（见上面的checkInterruptWhileWaiting方法）
          interruptMode = REINTERRUPT;
      if (node.nextWaiter != null) // clean up if cancelled
          unlinkCancelledWaiters();   // 移除waitStatus为CANCELLED的节点
      if (interruptMode != 0) // 如果跳出while循环是因为被中断
          reportInterruptAfterWait(interruptMode);    // 则根据interruptMode，选择抛出InterruptedException 或 重新中断当前线程
  }
  ```

  

* `signal()`：调用`doSignal()`方法来唤醒在等待队列中等待最长时间的节点（条件队列里的首节点）,执行`enq()`方法加入到AQS同步队列中，接着开始通过CAS修改当前节点的前置节点waitStatus为SIGNAL，并且唤醒当前线程，被唤醒后尝试重新获取锁，如果获取锁失败继续会被挂起，直到另外线程释放锁才被唤醒。

Condition可以精准的对多个不同条件进行控制，Lock只能唤醒一个或者全部的等待队列。Condition需要使用Lock进行控制，使用的时候要注意lock()后及时的unlock()。

```java
public class ConditionTest{    
    private LinkedList<String> buffer; //容器    
    private int maxSize ;    
    private Lock lock;    
    private Condition emptyCondition;    
    private Condition fullCondition;
    
	public ConditionTest(int maxSize){
        this.maxSize = maxSize;
        buffer = new LinkedList<String>();
        lock = new ReentrantLock();
        emptyCondition = lock.newCondition();
        fullCondition = lock.newCondition();
    }

    public void set(String string) throws InterruptedException {
        lock.lock();    //获取锁
        try {
            while (maxSize == buffer.size()){
                fullCondition.await();       //满了，添加的线程进入等待状态
            }

            buffer.add(string);
            emptyCondition.signal();
        } finally {
            lock.unlock();      //记得释放锁
        }
    }

    public String get() throws InterruptedException {
        String string;
        lock.lock();
        try {
            while (buffer.size() == 0){
                emptyCondition.await();
            }
            string = buffer.poll();
            fullCondition.signal();
        } finally {
            lock.unlock();
        }
        return string;
    }
}
```

##### Synchronize、ReentrantLock

* Synchronized是java语言的关键字，是原生语法层面的互斥，需要jvm实现。ReentrantLock它是JDK 提供的API层面的互斥锁，需要lock()和unlock()方法来完成。

* synchronized既可以修饰方法，也可以修饰代码块。ReentrantLock用永远加锁、释放锁之间单位区间。Lock必须手动获取与释放锁，而synchronized不需要手动释放和开启锁。

* 使用synchronized，如果线程得不到想要的锁，将一直等待，不能被中断。使用ReentrantLock，如果等待了很长时间以后，可以中断等待。

* synchronized的锁是非公平锁，ReentrantLock默认情况下也是非公平锁，但可以通过带布尔值的构造函数要求使用公平锁。

* 绑定条件：ReentrantLock可以同时绑定多个Condition对象，实现精细控制（生产者、消费者），只需多次调用newCondition方法即可。synchronized中，锁对象的wait()和notify()或notifyAll()方法可以实现一个隐含的条件，但如果要和多于一个的条件关联的时候，就不得不额外添加一个锁。

  ##### 线程打印
  
  ```java
  import java.util.concurrent.locks.Condition;
  import java.util.concurrent.locks.Lock;
  import java.util.concurrent.locks.ReentrantLock;
  public class MulitiThread {
      int num = 0;
      final Lock lock = new ReentrantLock();
      Condition condition0 = lock.newCondition();
      Condition condition1 = lock.newCondition();
      Condition condition2 = lock.newCondition();
      // 精准控制线程被唤醒顺序，不存在错误线程被唤醒的情形，减少对同步锁的无意义竞争
      public void printNum0(int target, Condition curr, Condition next) {
          for (int i = 0; i < 10; ++i) {
              // 获得互斥锁
              lock.lock();
              try {
                  // 针对多余两个线程情形
                  while (num % 3 != target) {
                      try {
                          // 放弃锁加入等待队列，等待被前一个线程唤醒
                          curr.await();
                      } catch (InterruptedException e) {
                          throw new RuntimeException(e);
                      }
                  }
                  System.out.println("" + target + "-" + num);
                  // 将下一个线程从他的等待队列移到同步队列，参与锁竞争
                  num++;
                  next.signal();
              } finally {
                  // 释放锁，开始进入下一轮竞争
                  lock.unlock();
              }
          }
      }
      // 可能存在错误线程被欢迎的情形
      public void printNum1(int target) {
          for (int i = 0; i < 10; ++i) {
              // 获得互斥锁
              synchronized (lock) {
                  // 针对多余两个线程情形
                  while (num % 3 != target) {
                      try {
                          // 释放锁资源
                          lock.wait();
                      } catch (InterruptedException e) {
                          throw new RuntimeException(e);
                      }
                  }
                  System.out.println("" + target + "-" + num);
                  // 唤醒其余线程，让他们准备竞争锁
                  num++;
                  lock.notifyAll();
              }
          }
  
      }
  
      public static void main(String[] args) {
          MulitiThread mulitiThread = new MulitiThread();
          new Thread(() -> mulitiThread.printNum0(0, mulitiThread.condition0, mulitiThread.condition1)).start();
          new Thread(() -> mulitiThread.printNum0(1, mulitiThread.condition1, mulitiThread.condition2)).start();
          new Thread(() -> mulitiThread.printNum0(2, mulitiThread.condition2, mulitiThread.condition0)).start();
  //        new Thread(() -> mulitiThread.printNum1(0)).start();
  //        new Thread(() -> mulitiThread.printNum1(1)).start();
  //        new Thread(() -> mulitiThread.printNum1(2)).start();
  
      }
  }
  ```
  

##### 互斥、自旋、读写锁、乐观、悲观

https://cloud.tencent.com/developer/news/695304

https://pdai.tech/md/java/thread/java-thread-x-lock-all.html

##### 创建线程

* 继承 Thread 类，并重写它的 run 方法，对对象调用start()开始执行。编写简单，线程类已经继承了Thread类，所以不能再继承其他父类。
* 一个类实现 Runnable 接口，并实现 run 方法。然后创建 Runnable 实现类对象，并把它作为 target 传入 Thread 的构造函数中，最后调用 start 方法启动线程。
* 首先定义一个实现 Callable 接口的实现类，并实现 call 方法。call 方法是带返回值的。然后通过 FutureTask 的构造方法，把这个 Callable 实现类传进去。把 FutureTask 作为 Thread 类的 target ，创建 Thread 线程对象。通过 FutureTask 的 get 方法获取线程的执行结果。
* 线程类只是实现了Runnable接口或Callable接口，还可以继承其他类，实现其它接口。同时在这种方式下，多个线程可以共享同一个target对象，所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开，形成清晰的模型，较好地体现了面向对象的思想。
*  Executors 来创建线程池对象。定一个 Runnable 的实现类，重写 run 方法。然后创建一个拥有固定线程数的线程池。最后通过 ExecutorService 对象的 execute 方法传入线程对象。
* Executors 来创建线程池对象。定一个 Callable 的实现类，重写 call方法。然后创建一个拥有固定线程数的线程池。最后通过 ExecutorService 对象的 submit方法传入线程对象,并拿到一个Future对象。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。

##### Callable 、Runble

*  Runnable不返回任务执行结果，Callable可返回任务执行结果。
*  Callable在任务无法计算结果时抛出异常，而Runnable不能。
*  运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。
*  Runnable可以通过Runnable和ExecutorService 来执行，而Callable则只能通过ExecutorService 或者包装为FutureTask来执行。

##### 静态类、非静态内部类

* 静态特点：全局唯一；只加载一次，优先于非静态；使用方式上不依赖于实例对象；生命周期属于类级别，从JVM 加载开始到JVM卸载结束。
* 非静态内部类不能脱离外部类实体被创建，一个非静态内部类可以访问外部类的数据和方法，因为他就在外部类里面。静态内部类可以脱离外部类对象独立创建。
* 非静态内部类能够访问外部类的静态和非静态成员。静态类不能访问外部类的非静态成员，只能访问外部类的静态成员。

##### String、StringBuffer、StringBuilder

String是字符串常量，而StringBuffer和StringBuilder是字符串变量。由String创建的字符内容是不可改变的，而由StringBuffer和StringBuidler创建的字符内容是可以改变的。StringBuffer是线程安全的（很多方法使用lSynchronized修饰），而StringBuilder是非线程安全的。

虽然String、StringBuffer和StringBuilder都是final类，它们生成的对象都是不可变的，而且它们内部也都是靠byte[](ASCII、UTF16)实现的，但是不同之处在于，String类中定义的byte数组是final的，而StringBuffer和StringBuilder都是继承自AbstractStringBuilder类，它们的内部实现都是靠这个父类完成的，而这个父类中定义的byte[组只是一个普通是私有变量，可以用append追加。

String要设计成不可变:字符串常量池的需要,当创建一个String对象时,假如此字符串值已经存在于常量池中,则不会创建一个新的对象,而是引用已经存在的对象，假若字符串对象允许改变,那么将会导致各种逻辑错误,比如改变一个对象会影响到另一个独立对象。允许String对象缓存HashCode：Java中String对象的哈希码被频繁地使用, 比如在hashMap 等容器中，字符串不变性保证了hash码的唯一性,因此可以放心地进行缓存。安全性：String被许多的Java类(库)用来当做参数, 假若String不是固定不变的,将会引起各种安全隐患。



##### 线程池

https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html

[面试官：来！聊聊线程池的实现原理以及使用时的问题 - 掘金 (juejin.cn)](https://juejin.cn/post/6844904000056197127#heading-1)

在线程池中，使用了一个原子类AtomicInteger的变量来表示线程池状态和线程数量，该变量在内存中会占用4个字节，也就是32bit，其中高3位用来表示线程池的状态（running,stop,shutdown TIFYING,TERMINATED），低29位用来表示线程的数量。通过它判断当前线程池线程数用于后续流程判断。

```java
private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
private static final int COUNT_BITS = Integer.SIZE - 3;
private static final int COUNT_MASK = (1 << COUNT_BITS) - 1;

// runState is stored in the high-order bits
private static final int RUNNING    = -1 << COUNT_BITS;
private static final int SHUTDOWN   =  0 << COUNT_BITS;
private static final int STOP       =  1 << COUNT_BITS;
private static final int TIDYING    =  2 << COUNT_BITS;
private static final int TERMINATED =  3 << COUNT_BITS;
// worker集合锁
private final ReentrantLock mainLock = new ReentrantLock();
private final HashSet<Worker> workers = new HashSet<>();
private final BlockingQueue<Runnable> workQueue;
```



```java
private final class Worker extends AbstractQueuedSynchronizer implements Runnable{
    final Thread thread;//Worker持有的线程
    Runnable firstTask;//初始化的任务，可以为null
}
```

Worker这个工作线程，实现了Runnable接口，并持有一个线程thread，一个初始化的任务firstTask。thread是在调用构造方法时通过ThreadFactory来创建的线程，可以用来执行任务；firstTask用它来保存传入的第一个任务，这个任务可以有也可以为null。如果这个值是非空的，那么线程就会在启动初期立即执行这个任务，也就对应核心线程创建时的情况；如果这个值是null，那么就需要创建一个线程去执行任务列表（workQueue）中的任务，也就是非核心线程的创建。

Worker是通过继承AQS，使用AQS来实现独占锁这个功能。lock方法一旦获取了独占锁，表示当前线程正在执行任务中。 如果正在执行任务，则不应该中断线程。 如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 

线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。

线程池本意只是让核心数量的线程工作着，不论是 core 的取名，还是 keepalive 的设定，所以你可以直接把 core 的数量设为你想要线程池工作的线程数。而任务队列起到一个缓冲的作用。最大线程数这个参数更像是无奈之举，在最坏的情况下做最后的努力，去新建线程去帮助消化任务。所以我个人觉得没有为什么，就是这样设计的，并且这样的设定挺合理。当然如果你想要扯一扯 CPU 密集和 I/O 密集，那可以扯一扯。原生版线程池的实现可以认为是偏向 CPU 密集的，也就是当任务过多的时候不是先去创建更多的线程，而是先缓存任务，让核心线程去消化，我们知道，当处理 CPU 密集型任务的时，线程太多反而会由于线程频繁切换的开销而得不偿失，所以优先堆积任务而不是创建新的线程。而像 Tomcat 这种业务场景，大部分情况下是需要大量 I/O 处理的情况就做了一些定制，修改了原生线程池的实现，使得在队列没满的时候，可以创建线程至最大线程数。



##### 接口，抽象类

面向对象的三个特征：封装（隐藏信息，保护数据，降耦合度，复用）、继承（复用，多态，拓展）、多态（依赖于抽象，屏蔽底层）。

接口的设计目的，是对类的行为进行约束（更准确的说是一种“有”约束，因为接口不能规定类不可以有什么行为），也就是提供一种机制，可以强制要求不同的类具有相同的行为。它只约束了行为的有无，但不对如何实现行为进行限制。对“接口为何是约束”的理解，我觉得配合泛型食用效果更佳。

而抽象类的设计目的，是代码复用。当不同的类具有某些相同的行为(记为行为集合A)，且其中一部分行为的实现方式一致时（A的非真子集，记为B），可以让这些类都派生于一个抽象类。在这个抽象类中实现了B，避免让所有的子类来实现B，这就达到了代码复用的目的。而A减B的部分，留给各个子类自己实现。

继承是一个 "是不是"的关系，包含基本功能，而 接口 实现则是 "有没有"的关系，用于实现额外的功能。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系。

单继承，菱形问题；多接口，只是定义了行为特性的规约，没有实现，因此不会有二义性，自己实现。

##### 反射

反射可以在不知道会运行哪一个类的情况下，获取到类的信息，创建对象以及操作对象。这其实很方便于拓展，所以反射会是框架设计的灵魂，因为框架在设计的时候，为了降低耦合度，肯定是需要考虑拓展等功能的，不能将类型写死，硬编码。降低耦合度，变得很灵活，在运行时去确定类型，绑定对象，体现了多态功能。

反射可以修改权限，比如上面访问到`private`这些方法和属性，这是会破坏封装性的，有安全隐患，有时候，还会破坏单例的设计。

- Class.forName("com.Student)
- student.getClass()
- Student.class

使用`getFields()`可以获取到public的属性，包括static属性，使用`getDeclaredFields()`可以获取所有声明的属性，不管是`public`，`protected`,`private`不同修饰的属性。

##### 异常

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220823203147563.png)

* `Error`表示严重的错误，程序对此一般无能为力，出现此类异常程序可以终止运行；`Exception`则是运行时的错误，它可以被捕获并处理。`Exception`又分为两大类：`RuntimeException`以及它的子类；非`RuntimeException`（包括`IOException`、`ReflectiveOperationException`等等）

- 必须捕获的异常，包括`Exception`及其子类，但不包括`RuntimeException`及其子类，这种类型的异常称为Checked Exception。只要是方法声明的Checked Exception，要么捕获，要么上抛在更高的调用层捕获。
- 不强制要求捕获（可以捕获也可以不捕获）的异常，包括`Error`及其子类，`RuntimeException`及其子类。

##### 执行顺序

1，静态代码块，在类加载的时候执行，并且仅执行一次，如果一个类中有多个静态代码块，将按照书写顺序执行。用于执行某些需要在项目启动的时候就执行代码（如加载的配置文件）。

```java
static{
        System.out.println("静态代码块);
}
```

2，构造代码块,在类的每次实例化时在父类构造方法之后，当前构造方法之前执行。只要创建一个对象，构造代码块都会执行一次。做诸如统计创建对象的次数等功能。

```java
{
	System.out.println("构造代码块);
}
```

3，构造方法在类的每次实例化时执行。默认调用父类误差方法。

```java
{
    System.out.println("A inner);
}
public A() {
    System.out.println("A cons);
}
// 等价于
public A() {
    super()
    System.out.println("A inner);
    System.out.println("A cons);
}
```

```java
class A {
    static {
        System.out.println("A static);
    }
    {
        System.out.println("A inner);
    }
    public A() {
        System.out.println("A cons);
    }
}
class B extends A {
    static {
        System.out.println("B static);
    }
    {
        System.out.println("B inner);
    }
    public B() {
        System.out.println("B cons);
    }
}
public class Test {
    public static void main(String[] args) {
        new B();
        System.out.println("==========);
        new B();
    }
}

A static
B static 
A inner 
A cons 
B inner
B cons
==========
A inner
A cons
B inner
B cons


```


```java
public class ClassInit {  
    public static void main(String[] args) {  
        /*  
        变量指向父类，方法指向子类，父类方法变量指向父类，子类方法变量指向子类  
        类加载(clinit执行静态代码块与静态变量赋值)->对象分配内存，字段赋零值->实例化(init执行非静态代码快，变量赋值与与构造方法)  
        father static        
        son static        
        father none static        
        son=0        
        son none static        
        son=4        
        gay=2         
        */        
        Father gay = new Son();  
        System.out.println("gay="+gay.x);  
    }  
}  
  
  
class Father {  
    int x = 1;  
    static {  
        System.out.println("father static ");  
    }    
    {  
        System.out.println("father none static ");  
    }  
    public Father() {  
        x = 2;  
        print();  
    }  
    public void print() {  
        System.out.println("father=" + x);  
    }  
}  
  
class Son extends Father {  
    int x = 3;  
    static {  
        System.out.println("son static ");  
    }  
    {  
        System.out.println("son none static ");  
    }  
    public Son() {  
        x = 4;  
        print();  
    }  
    @Override  
    public void print() {  
        System.out.println("son=" + x);  
    }  
}
```


##### 继承关系

1，子类中如果不存在同名变量，子类访问的是父类变量，如果存在重名（重名即可，和类型无关），将访问子类独有变量。

```java
class A {
    int x = 1;
    public A() {
        System.out.println("A cons" + x);
    }
}
class B extends A {
    public B() {
        System.out.println("B cons" + x);
    }
}
public class Test {
    public static void main(String[] args) {
        new B(); // A cons1 B cons1
    }
}
/////////////////////////////////////////////////////////////
class A {
    int x = 1;
    public A() {
        System.out.println("A cons" + x);
    }
}
class B extends A {
	String x="2";
    public B() {
        System.out.println("B cons" + x);
    }
}
public class Test {
    public static void main(String[] args) {
        new B(); // A cons1 B cons2
    }
}
```

2，父类引用指向子类对象时，存在方法覆盖即执行的是之内方法；变量不存在覆盖问题，访问的是父类变量。如果需要访问子类变量需要手动类型转换。

```java
class A {
    int x = 1;
    public A() {
        System.out.println("A cons" + x);
    }
}
class B extends A {
    int x = 2;
    public B() {
        System.out.println("B cons" + x);
    }
}
public class Test {
    public static void main(String[] args) {
        A a = new B();// A cons1,B cons2
        System.out.println(a.x); // 1
        System.out.println(((B) a).x);//2
    }
}
```

##### 接口、抽象类

* 同：都不能被实例化 ；接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。
* 异：
  * 接口只有定义，不能有方法的实现（java 1.8中可以定义default方法体，和静态方法），而抽象类可以有抽象方法和实例方法。
  * 一个类可以实现多个接口，但一个类只能继承一个抽象类（菱形继承问题）。
  * 接口强调特定功能的实现（有没有），对类局部（行为）进行抽象，而抽象类强调所属关系（是不是），是对整个类整体进行抽象，包括属性、行为。
  * 接口成员变量默认为public static final，必须赋初值，不能被修改，抽象类中成员变量可以是各种类型的。
  * 设计层面不同，抽象类作为很多子类的父类，它是一种模板式设计，而接口是一种行为规范，它是一种辐射式设计。

##### 反射

1，反射是为了解决在运行期，对某个实例一无所知的情况下，如何调用其方法。

2，JVM在第一次读取到一种`class`类型时，将其加载进内存，创建一个`Class`类型的实例放入方法区，一个`Class`实例包含了该`class`的所有完整信息，包括类名、包名、父类、实现的接口、所有方法、字段等，通过`Class`实例获取`class`信息的方法称为反射（Reflection）。

3，用`instanceof`不但匹配指定类型，还匹配指定类型的子类。

4，字段

```java
Field getField(name)//根据字段名获取某个public的field（包括父类）
Field getDeclaredField(name)//根据字段名获取当前类的某个field（不包括父类）
field.setAccessible(true); // 修改访问权限，来访问非`public`字段，该字段一律允许访问。通过反射读写字段是一种非常规方法，它会破坏对象的封装
field.get(obj); //获得obj实例的field值
field.set(obj0,obj1) //把obj0中field的值改为obj1
```

字段不遵循多态原则，访问的是获取字段类的字段。

```java
Field f = Person.class.getField("x);
f.get(new Student());//获取的是父类变量
// 等价于
Person p = new Student(); 
p.x;
```

5，方法

```java
Method getMethod(name, Class...)//获取某个public的Method（包括父类），name为方法名称，Class为方法参数的Class 实例可变参。
Method getDeclaredMethod(name, Class...)//获取当前类的某个Method（不包括父类）
m.setAccessible(true); //调用非public方法，修改权限 
m.invoke(obj,args) //obj为要执行m方法的对象，args为方法参数可变参，invoke 默认返回Object返回值，要转型
m.invoke(null,args) //调用静态方法时，方法属于类而非对象，无需指定实例对象，第一个参数永远为null
```

仍然遵循多态原则：即总是调用作为参数的实际类型的覆写方法（如果不存在覆写，仍然调用父类方法）。

```java
Method m = Person.class.getMethod("hello);
m.invoke(new Student());
// 等价于
Person p = new Student(); 
p.hello();
```

6，构造方法

```java
Constructor getConstructors()//获取所有public的Constructor；
Constructor getDeclaredConstructors()//获取所有（任意权限修饰符）的Constructor。
constructor.setAccessible(true) //更改权限
constructor.newInstance(Object... parameters) // 通过构造方法创建实例
```

##### 泛型

1，java的泛型是由编译器在编译时实行的，编译器内部永远把所有类型`T`视为`Object`处理，但是，在需要转型的时候，编译器会根据`T`的类型自动为我们实行安全地强制转型。

2，缺陷

* `<T>`不能是基本类型，`Object`类型无法持有基本类型。

* 无法取得带泛型的`Class`，无论`T`的类型是什么，`getClass()`返回同一个`Class`实例。

* 不能实例化`T`类型：在泛型类内部不能`new T();`必须借助额外的`Class<T>`参数。

  ```java
  public class Pair<T> {
      private T first;
      private T last;
      // 通过反射来实例化T类型，使用的时候，也必须传入Class<T>
      public Pair(Class<T> clazz) {
          first = clazz.newInstance();
          last = clazz.newInstance();
      }
  }
  Pair<String> pair = new Pair<>(String.class);
  ```

* 不恰当的覆写方法，泛型参数类型被擦拭为`object`后可能与其它方法签名冲突。

3，读写限制

* `<? extends T>`允许调用读方法`T get()`获取`T`的引用：无论存储的是T还是T的子类，都可以用T接收，但不允许调用写方法`set(T)`传入`T`的引用：存储的是T还是T的子类，传入参数也是T或者T的子类，赋值时可能才能在向下类型转换；

* `<? super T>`允许调用写方法`set(T)`传入`T`的引用，但不允许调用读方法`T get()`获取`T`的引用（获取`Object`除外）：存储的是T或者T的父类，用T接收可能存在向下类型转换。

##### 排序

1，归并排序比较适用于处理较大规模的数据，当序列长度大于287时使用并归排序。优化并归排序，如果序列的有序字段较长，跳过对他们的划分，直接合并多个有序字段。

2，元素个数小于47时使用插入排序（快速排序的递归操作影响性能）。成对插入排序：在无序部分拿两个元素a1，a2，并调整使a1>a2； a1往左比较，找到合适位置后插入； a2只需在a1的左边进行比较（a1>a2）,找到合适的位置插入即可，减少了比较次数。

3，元素个数在[47,287]之间，使用快排。单枢纽元快排：使用一个枢纽元将数据划分3个区间（三路快排）。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220824195756587.png)



双枢纽元快排：使用两个枢纽元将数据划分3个区间。排序过程的瓶颈在于内存而不在于CPU，双枢纽元快排扫描元素个数更少，更快。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220824200106807.png)

堆数据5次抽样并排序，若随机挑选的这五个元素里面有重复的元素，则认为序列里有许多重复的元素，则直接用a[e3]作为轴进行单轴排序；否则，以a[e2]和a[e4]为轴进行双轴排序。

##### Java内存模型

1，当一个CPU需要读取主存时，它会将主存的部分读到CPU缓存中。当CPU需要将结果写回到主存中去时，它会将内部寄存器的值刷新到缓存中。

![700|525](%E9%9D%A2%E7%BB%8F.assets/image-20220911174752093.png)

2，一致性：当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致的情况。指令重排序：为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-Of-Order Execution）优化，如果存在一个计算任务依赖另一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。

3，解决可见性：volatile关键字保证新值能立即同步到主内存，以及每个线程在每次使用volatile变量前都立即从主内存刷新；synchronized关键字执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行初始化变量的值、对一个变量执行unlock操作之前，必须先把此变量同步回主内存中。

4，解决有序性：volatile关键字本身就包含了禁止指令重排序的语义（使用内存屏障来满足happens before原则）；synchronized则是由“一个变量在同一个时刻只允许一条线程对其进行lock操作”这条规则获得的，这个规则决定了持有同一个锁的两个同步块只能串行地进入。

5，解决原子性：synchronized关键字，需要使用同步块技术，保证原子性。



##### 多线程生产者消费者

```java
public class ProductThread extends Thread {
    private int taskNum;
    private ArrayBlockingQueue queue;
    public ProductThread(int taskNum,ArrayBlockingQueue queue) {
        this.taskNum = taskNum;
        this.queue = queue;
    }
    public void run() {
        try {
            //模拟生产
            Thread.currentThread().sleep(5000);
            System.out.println("开始生产);
            queue.add(taskNum);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }
}
```

```java
public class ConsumerThread extends Thread {
    private ArrayBlockingQueue queue;
    public ConsumerThread(ArrayBlockingQueue queue) {
        this.queue = queue;
    }

    public void run() {
        System.out.println("准备消费);
            int taskNum;
            try {
                taskNum = (int) queue.take();
                System.out.println("消费了"+taskNum);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }   
    }
}
```

```java
public class ProductAndConsumer {

    public static void main(String[] args) {
        ArrayBlockingQueue<Integer> queue = new ArrayBlockingQueue<Integer>(20);
        //为多生产者和多消费者分别开创的线程池
        ThreadPoolExecutor productPool = 
                new ThreadPoolExecutor(10,20,60,TimeUnit.MILLISECONDS,new ArrayBlockingQueue(5),new ThreadPoolExecutor.CallerRunsPolicy());
        ThreadPoolExecutor consumerPool = 
                new ThreadPoolExecutor(10,20,60,TimeUnit.MILLISECONDS,new ArrayBlockingQueue(5),new ThreadPoolExecutor.CallerRunsPolicy());

        System.out.println("start);
        for(int i = 0;i<100;i++) {

            productPool.execute(new ProductThread(i,queue));
            consumerPool.execute(new ConsumerThread(queue));
        }
        productPool.shutdown();
        consumerPool.shutdown();
    }
}
```

弹幕发送

```java
@Component
public class SomeBean {
    @Bean
    public ArrayBlockingQueue<String> arrayBlockingQueue() {
        return new ArrayBlockingQueue<>(20);
    }
    @Bean
    public ThreadPoolExecutor threadPoolExecutor(@Autowired ArrayBlockingQueue<String> arrayBlockingQueue) {
        ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 20, 60, TimeUnit.MILLISECONDS, new ArrayBlockingQueue(5), new ThreadPoolExecutor.CallerRunsPolicy());
        for (int i = 0; i < 5; ++i) {
            threadPoolExecutor.submit( new DanmuSender(arrayBlockingQueue));
        }
        return threadPoolExecutor;
    }
}
///////////////////////////////////////////////////
@Component
public class DanduGen {
    @Autowired
    ArrayBlockingQueue<String> arrayBlockingQueue;

    public  void func() {
        for (int i = 0; i < 12; ++i) {
            arrayBlockingQueue.add(""+i);
        }
    }
}
///////////////////////////////////////////////////
public class DanmuSender implements Runnable {

    ArrayBlockingQueue<String> queue;

    public DanmuSender(ArrayBlockingQueue<String> queue) {
        this.queue = queue;
    }

    @Override
    public void run() {
        while (true) {
            String map = null;
            try {
                map = queue.take();
            } catch (InterruptedException e) {
                throw new RuntimeException(e);
            }
            // 将消息并发送给指定用户
            System.out.println(map);
        }
    }
}

///////////////////////////////////////////////////
@SpringBootApplication
@AutoConfiguration
public class DemoApplication {

    public static void main(String[] args) {
        ApplicationContext app=SpringApplication.run(DemoApplication.class, args);
        ((DanduGen)app.getBean("danduGen)).func();

    }
}
```

##### ArrayBlickQueue

1，一个锁，两个condition（notEmpty，notFull）

2，插入时

```java
final ReentrantLock lock = this.lock;
try {
    while (count == items.length)
        notFull.await();
    enqueue(e);
    count++;
    notEmpty.signal();
} finally {
    lock.unlock();
}
```

3，获取时

```java
final ReentrantLock lock = this.lock;
try {
    while (count == 0)
        notEmpty.await();
    e=dequeue();
    count--;
    notFull.signal();
} finally {
    lock.unlock();
}
```



##### 中断

https://www.cnblogs.com/noteless/p/10372826.html

[详细分析Java中断机制_Java_丁一_InfoQ精选文章](https://www.infoq.cn/article/java-interrupt-mechanism)
* 类库中的有些类的方法也可能会调用中断，如 FutureTask 中的 cancel 方法，如果传入的参数为 true，它将会在正在运行异步任务的线程上调用 interrupt 方法，如果正在执行的异步任务中的代码没有对中断做出响应，那么 cancel 方法中的参数将不会起到什么效果；又如 ThreadPoolExecutor 中的 shutdownNow 方法会遍历线程池中的工作线程并调用线程的 interrupt 方法来中断线程，所以如果工作线程中正在执行的任务没有对中断做出响应，任务将一直执行直到正常结束。
* 不会强求被中断线程一定要在某个点进行处理。实际上，被中断线程只需在合适的时候处理即可，如果没有合适的时间点，甚至可以不处理，这时候在任务处理层面，就跟没有调用中断方法一样。“合适的时候”与线程正在处理的业务逻辑紧密相关，例如，每次迭代的时候，进入一个可能阻塞且无法中断的方法之前等，但多半不会出现在某个临界区更新另一个对象状态的时候，因为这可能会导致对象处于不一致状态。
* 如果遇到的是可中断的阻塞方法抛出 InterruptedException，可以继续向方法调用栈的上层抛出该异常，如果是检测到中断，则可清除中断状态并抛出 InterruptedException，使当前方法也成为一个可中断的方法。
- 若有时候不太方便在方法上抛出 InterruptedException，比如要实现的某个接口中的方法签名上没有 throws InterruptedException，这时就可以捕获可中断方法的 InterruptedException 并通过 Thread.currentThread.interrupt() 来重新设置中断状态。如果是检测并清除了中断状态，亦是如此。
##### 常量池

https://cloud.tencent.com/developer/article/1450501
* 符号引用
* 文本字符串
```java
/*
 `String s = "123";` 中会首先检查并存储到常量池，如果不存在则存入，然后指向该常量池对象；
 `new String("123")` `"123"`首先检查并存储到常量池，如果不存在则存入，但 `new String("123")` 会创建一个新的 `String` 对象，并指向堆中的对象，无论"123"在常量池是否存在。
*/
String s1 = "Hello";  
String s2 = "Hello";  
String s3 = "Hel" + "lo";  // 编译优化
String s4 = "Hel" + new String("lo");  // 非常量运行时计算
String s5 = new String("Hello");  
String s7 = "H";  
String s8 = "ello";  
String s9 = s7 + s8;  // 非常量运行时计算
final String s10 = "H";  
final String s11 = "ello";  
String s12 = s10 + s11;  、、// 常量编译时计算
// s1,s2,s3,s12直接指向同一个常量池对象；s4,s5,s9指向堆中新建对象
System.out.println(s1 == s2);  // true  
System.out.println(s1 == s3);  // true  
System.out.println(s1 == s4);  // false  
System.out.println(s1 == s5);  // false  
System.out.println(s1 == s9);  // false  
System.out.println(s1 == s12);  // true  
System.out.println(s5 == s5.intern());//false  s5==s1
System.out.println(s1 == s5.intern());//true   s1==s1
```
##### jdk版本特性

https://blog.oxings.com/article/31.html
* Java8
	lambada表达式
	函数式接口
	默认方法
	Stream API 对元素流进行函数式操作
	Optional 解决NullPointerException
	使用元空间Metaspace代替持久代（PermGen space）
* Java9
	提供了List.of()、Set.of()、Map.of()和Map.ofEntries()等工厂方法；模块化
* Java10
	并行全垃圾回收器 G1；局部变量类型推断
* Java14
	Record类型，类似于Lombok 的@Data注解
##### 注解

1，第一类是由编译器使用的注解，@Override；这类注解不会被编译进入.class文件，它们在编译后就被编译器扔掉了。

2，第二类是由工具处理.class文件使用的注解，比如有些工具会在加载class的时候，对class做动态修改，实现一些特殊的功能。这类注解会被编译进入.class文件，但加载结束后并不会存在于内存中。

3，第三类是在程序运行期能够读取的注解，它们在加载后一直存在于JVM中，这也是最常用的注解。@PostConstruct。

##### static

https://juejin.cn/post/6844903988098236429

变量（类加载）、方法、代码块（类加载）、内部类（只能访问外部类静态成员）

##### Lambda

https://www.zhihu.com/question/20125256

代码块赋值，传递代码块（匿名实现）；函数式接口，方法接口（传递成员方法），optional（避免冗长if else 空值判断）；流处理；代码简洁；

##### stream

https://juejin.cn/post/6844903830254010381

元素是特定类型的对象，形成一个队列。Java中的Stream并不会存储元素，而是按需计算，lambda函数式编程模式。

数据源 流的来源：集合，数组，IntStream， 产生器generator 等。

生成：parallelStream；中间操作：filter, map, reduce,Sorted； 终端操作：foreach、collect。

 延迟性处理，当且仅当存在终端操作时，中间操作操作才会被执行。前一个元素走完全部流程才开始处理下一个元素，结果是随着链条垂直移动的。

##### optional

https://zhuanlan.zhihu.com/p/125758212

Optional是一个包装器类，其中包含对其他对象的引用。Optional提供一种类型级解决方案来表示可选值而不是空引用。通过增加构建更具表现力的API的可能性来减少Java系统中空指针异常的情况。

Optional.of(value)；

isPresent：如果有值返回true，如果为null返回false；

ifPresent：接收函数接口，如果存在值，则使用该值调用指定的使用者；否则什么都不做；

get：如果Optional存在一个值，则返回，不存在则抛出NoSuchElementException。

orElse：接收默认值，如果返回值存在则返回，否则返回other。

orElseGet：接收生产者接口，如果有值则返回，没有则调用Supplier函数，并返回。

##### 重载重写

1，重写方法的规则：

参数列表必须完全与被重写的方法相同，否则不能称其为重写而是重载。

返回的类型必须一直与被重写的方法的返回类型相同，否则不能称其为重写而是重载。

访问修饰符的限制一定要大于被重写方法的访问修饰符（public>protected>default>private）

重写方法一定不能抛出新的检查异常或者比被重写方法申明更加宽泛的检查型异常。

2，重载的规则：

必须具有不同的参数列表；

返回类型可以相同也可以不同，只要参数列表不同就可以了；

可以有不同的访问修饰符；

可以抛出不同的异常；

3，重写与重载的区别在于：

重写多态性起作用，对调用被重载过的方法可以大大减少代码的输入量，同一个方法名只要往里面传递不同的参数就可以拥有不同的功能或返回值。用好重写和重载可以设计一个结构清晰而简洁的类，可以说重写和重载在编写代码过程中的作用非同一般.

##### HashMap 1.8

https://www.cnblogs.com/liang1101/p/12728936.html

* JDK1.7用的是头插法，而 JDK1.8及之后使用的都是尾插法
* 扩容位置判断：hash&oldLength==0
* 数组+链表+红黑树
* 扰动处理：1次位运算 + 1次异 或运算

##### 红黑树

1，

性质1：每个节点要么是黑色，要么是红色。

性质2：根节点是黑色。

性质3：每个叶子节点（NIL）是黑色。

性质4：每个红色结点的两个子结点一定都是黑色。

性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。

2，自平衡：左旋、右旋和变色。

3，从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。

##### 包装类型

Integer实际是对象的引用，当new一个Integer时，实际上是生成一个指针指向此对象；而int则是直接存储数据值。Integer的默认值是null，int的默认值是0。

面向对象需求，泛型。

优化：valueOf()和直接装箱赋值在小范围数据下使用缓存对象。

##### JUC

1，原子类：基本类型、引用类型、数组。

2，锁：AQS、condition、ReentrantLook、读写锁、

3，集合：ConcurrentHashMap、ConcurrentLinkedQueue、CopyOnWriteArrayList、ArrayBlockingQueue

4，线程：Callable、CountDownLatch、ThreadPoolExecutor

##### wait sleep

https://cloud.tencent.com/developer/article/1493834

1、sleep方法是Thread类的静态方法；wait方法是Object类的成员方法

2、sleep方法使当前线程暂停执行指定的时间，让出cpu给其他线程，但是它的监控状态依然保持着，当指定的时间到了又会自动恢复运行状态。在调用sleep方法后，线程不会释放对象锁；而当调用wait方法时，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用notify()方法后本线程才进入对象锁定池处于准备状态。

3、sleep方法有可能会抛出异常，所以需要进行异常处理；wait方法不需要处理

4、sleep方法可以在任何地方使用；wait方法只能在同步方法和同步代码块中使用

5，sleep用于在主线程中等待其他线程完成任务，wait用于多个任务线程间的通信协调。

##### 赋值和深/浅拷贝的区别

- 当我们把一个对象赋值给一个新的变量时，赋的其实是该对象的在栈中的地址，而不是堆中的数据。也就是两个对象指向的是同一个存储空间，无论哪个对象发生改变，其实都是改变的存储空间的内容，因此，两个对象是联动的。
- 浅拷贝：重新在堆中创建内存，拷贝前后对象的基本数据类型互不影响，但拷贝前后对象的引用类型因共享同一块内存，会相互影响。
- 深拷贝：从堆内存中开辟一个新的区域存放新对象，对对象中的子对象进行递归拷贝,拷贝前后的两个对象互不影响。

### Web

https://bytedance.feishu.cn/file/boxcnPjF5oJxpZh4ZQYDwVCSxib

#####  微服务概述

* 架构风格是一种将单个应用程序作为一组小型服务开发的方法，每个服务都在自己的进程中运行，赋予系统灵活的代码组织方式和发布节奏，使得快速交付和应对变化成为可能。每个服务是针对一个单一职责的业务能力的封装，专注做好一件事情，实现松耦合。并使用轻量级机制（通常是基于HTTP的API）进行通信。 这些服务是围绕业务功能构建的，可以通过全自动部署机制独立部署。 这些服务不需要集中式管理，可以用不同的编程语言编写，并使用不同的数据存储技术，合适的业务问题选择合适的技术可以独立演化，服务与服务之间采取与语言无关的API进行集成，只要保持API不变，对微服务架构中的每个组件服务进行开发、部署、运营和扩展，而不影响其他服务的功能。在整体式架构中，如果一个组件出现故障，可能导致整个应用程序无法运行。通过微服务，应用程序可以通过降低功能而不导致整个应用程序崩溃来处理总体服务故障。

* 单体服务可能只需部署至一小片应用服务区集群，而微服务架构可能变成需要构建/测试/部署/运行数十个独立的服务，并可能需要支持多种语言和环境。隐式接口及接口匹配问题：把系统分为多个协作组件后会产生新的接口，需协调一起发布。分布式系统的复杂性：作为一种分布式系统，微服务引入了复杂性和其他若干问题，例如网络延迟、容错性、不可靠的网络，CAP。

* 微服务区别于单体架构的地方就在于“分而治之”，即通过切分服务以明确模块或者功能边界。然而，仅有“分”是不行的，软件系统是一个整体，很多功能来自若干服务模块的配合，因此必然要有“合”的手段，最终在线上，它们应当成为一个整体。Docker将所有应用都标准化为可管理、可测试、易迁移的镜像/容器，因此为不同技术栈提供了整合管理的途径。对各系统进行Docker化，就很容易通过统一的docker build，建立一致性的构建服务，再结合compose等基础设施处理服务依赖，这些工作最终就可以产生一个平台，（自动化的）将被微服务打散的整个系统再构建出来。

##### 最终一致性

1，系统中的所有分散在不同节点的数据，经过一定时间后，最终能够达到符合业务定义的一致的状态。同步操作不同操作耗时增加；部分操作成功、部分操作失败。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220828124557929.png)

2， 措施

* 多数据库事务：针对多数据库事务可以根据二阶段提交协议。

  > 第一阶段：协调者向所有的参与者发起执行事务询问；各参与者节点执行事务操作，如果本地事务成功，将Undo和Redo信息记入事务日志中，但不提交；根据是否成功反馈给协调者 Yes或者No。
  >
  > 第二阶段 (commit/rollback)：协调者根据准备阶段的投票结果执行事务提交、中断事务。提交：参与者收到commit请求后，执行事务提交，并在完成提交之后，释放整个占用的事务资源，向协调者发送Ack信息。中断事务：参与者接收到Rollback请求后，利用Undo信息，来执行事务回滚操作。在完成回滚之后，释放占用的资源，向协调者发送Ack信息。协调者接收到所有参与者反馈的Ack信息后，完成事务提交/中断。

  耗时长：涉及到多个节点的网络通信,通信时间如果过长,事务的相对时间也就会过长,那么锁定资源的时间也就长了；单点故障：一旦协调者发生故障，参与者会一直阻塞下去。数据不一致：部分参与者接受到了commit请求，部分未收到。

* 事务型消息队列：在处理业务逻辑的地方发送消息，之后消息队消费者来进行处理，如果成功，则结束，如果没有成功，则重试，直到成功。

* 消息队列+定时补偿机制：在处理业务逻辑的地方发送消息，之后消息队消费者来进行处理，如果成功，则结束，如果没有成功，不再是消息中间件自身的重试逻辑了，而是单独的补偿任务机制，使用死信队列，定时任务在操作可以成功时再重试。

* double check机制：A在同步调用B，B返回成功了。A为了确保，在过一段时间，再调用B一次，查询一下之前的那次调用是否成功。



##### 架构定义

 ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220701214030946.png)

无集中管理：各自选择合适技术栈。有界上下文：每个微服务有自己独立数据，独立演化。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220701214431827.png)

独立边界：由逐组件独立上升到服务模块化，允许其它服务调用。

最终一致性：各个服务保存部分独立数据，需要保证数据一致。

##### 康威法则

应用架构反应组织业务架构。初创企业业务简单，使用单块应用—>后续发展模块强耦合，沟通成本高—>单块架构拆分服务。

##### 单块优先

项目第一阶段的主要目标是快速开发和验证想法，证明产品思路是否可行。初始阶段使用单块应用，快速高效，随着业务的复杂再升级到微服务。初始阶段业务模型不成熟，无法清晰准确的拆分业务，并且业务启动开发慢。先使用单块应用，随着业务的开展，业务边界越清晰，容易划分。架构是设计出来的VS架构是演化出来的。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220701215558592.png)

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220701222401695.png)

职能划分团队：产品、开发、测试、运维团队。产品上线、反馈成本大。微服务：多职能成员聚合，围绕服务开发，囊括架构、设计、开发、评审、测试、运维，端到端所有权，降低跨团队沟通成本，一个微服务团队大约12人。按照每个开发人员负责不超过 3 个大的服务为标准，毕竟每个人的精力是有限的，所以在拆分微服务时，可以按照开发人员的总人数来决定。

##### 中台

大中台，小前台。强大中台为前台提供见识支撑，加快业务迭代。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220701222941082.png)

##### 服务分层

基础服务：订单服务、购物车服务。聚合服务：适配不同接入端口，聚合基础服务同时呈现给用户。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220701223712433.png)



##### 技术架构

机构复杂，初创团队建议单块应用。

网关层：反向路由，限流熔断，安全，跨横切面功能。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220704172754951.png)

##### 服务描述

常用的服务描述方式包括 RESTful API、XML 配置以及 IDL 文件三种。

* RESTful API 方式通常用于 HTTP 协议的服务描述，并且常用 Wiki 或者Swagger来进行管理，接口声明->接口实现->暴露接口，比较适合用作跨业务平台之间的服务协议。
* XML 配置方式多用作 RPC 协议的服务描述，通过 .xml 配置文件来定义接口名、参数以及返回值类型等，在服务提供者和服务消费者之间维持一份对等的 XML 配置文件，服务端通过加载 server.xml 配置文件将接口暴露出去。客户端通过加载 client.xml 配置文件来引入要调用的接口（ClassPathXmlApplicationContext）。对业务代码侵入性比较高，适合公司内部联系比较紧密的业务之间采用。
* IDL 文件方式通常用作 Thrift 和 gRPC 这类跨语言服务调用框架中，通过一种中立的方式来描述接口，使得在不同的平台上运行的对象和不同语言编写的程序可以相互通信交流，比如 gRPC 就是通过Protobuf 文件来定义服务的接口名、参数以及返回值的数据结构，然后利用 protoc 插件即可自动生成 Server /Client端的对应语言的代码，从而具备跨语言服务调用能力。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220712110449533.png)

##### 注册中心



服务之间的调用都通过接口描述来约定，约定内容包括接口名、接口参数以及接口返回值。

直接指定 ip+port：没有任何动态能力,难以处理多个实例下游实例

使用 DNS：dns的维护管理比较麻烦，甚至需要手工配置；本地 DNS 存在缓存，导致延迟；DNS 没有负载均衡；不支持服务探活检查；DNS 不能指定端口，不能实现端口级别的服务发现，只能做到ip级别

服务注册发现：新增一个统一的服务注册中心，用于存储服务名到服务实例之间的映射关系，上线服务向注册中心注册服务，声明自己能够提供哪些服务以及服务的地址是什么，完成服务发布，消费者请求注册中心，查询所需要调用服务的地址，然后以约定的通信协议向服务提供者发起请求，得到请求结果后再按照约定的协议解析结果；旧服务实例下线前，从服务注册中心删除该实例，下线流量；新服务实例上线后，在服务注册中心注册。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706113514663.png)



* 服务提供者在启动时，根据服务发布文件中配置的发布信息向注册中心注册自己的服务,并向 Registry 定期发送心跳汇报存活状态（如果超过 TIMEOUT 后服务端都没有收到客户端的心跳消息，则服务端认为这个服务节点已经不可用，将会从注册中心中删除其信息）。
* 服务消费者在启动时，根据消费者配置文件中配置的服务信息向注册中心订阅自己所需要的服务，把 Registry 返回的服务节点列表缓存在本地内存中
* 注册中心返回服务提供者地址列表给服务消费者。对调用情况进行监控，以了解服务是否正常，一旦注册中心探测到有服务提供者节点新加入或者被剔除，就必须立刻通知所有订阅该服务的服务消费者，刷新本地缓存的服务节点信息。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220711223918144.png)

注册中心一般都是采用集群部署来保证高可用性，并通过分布式一致性协议来确保集群中不同节点之间的数据保持一致(raft算法)。



##### 服务发现

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220704173005843.png)



* 1，LB服务发现、负载均衡。服务上线->申请域名->运维将服务注册到LB，通过域名指向服务。用户访问->dns解析->访问LB->负载均衡到后台服务。配置复杂，需要运维介入，需要单点LB，稳定性差；用户访问需要通过LB中转，有性能损失。
* 2，LB移到应用进程内部。服务自动注册到注册器中，并定时发送心跳保活，用户进程内置LB实现负载均衡，与注册器定时同步服务信息。无中节性能损失，无集中LB，多语言下客户端实现复杂。
* 3，每台主机上配置一个LB。服务自动注册到注册器中，并定时发送心跳保活，LB与注册器定时同步服务信息。用户进程调用本机LB实现负载均衡。每台主机上存在一个LB运维复杂。

##### 网关

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220704175310395.png)

将请求导向正确的服务提供方，将请求转为内部调用，屏蔽内部实现细节。

在网关上添加均衡器：使得网关无状态，上线线不对服务产生影响。

日志：请求都要通过网关，在网关处统计请求信息。

##### zulu

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705105555462.png)



zuul runner管理三层过滤器:pre routing 前置路由过滤器（日志功能，定制功能 ）+rounting 路由过滤器（找到目标服务并调用）+post rounting后置路由过滤器（日志、审计、异常处理）。基于脚本的过滤器，支持动态插拔。

过滤器加载机制：编译过滤器->持久化->拉取过滤器，上传到过滤器目录->扫描目录发现新增过滤器->加载过滤器。

req context：在三级过滤器间共享信息。

##### 路由发现

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705114331583.png)

##### 配置中心

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705115349700.png)

apollo配置中心使用内存缓存保存配置，并定期写入本地文件缓存，健壮性好，高可用。

配置中心主动推送更新+客户端定时爬取更行，保证及时性。

##### 通信

常用的服务描述方式包括 RESTful API（HTTP 协议的服务描述，并且常用 Wiki 或者Swagger来进行
管理）、XML（ RPC 协议的服务描述，通过 *.xml 配置文件来定义接口名、参数以及返回值类型等。） 配置以及 IDL（Thrift 和 gRPC 这类跨语言服务调用框架中，比如 gRPC 就是通过Protobuf 文件来定义服务的接口名、参数以及返回值的数据结构） 文件三种。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705115939789.png)

rpc强耦合：客户端服务端使用自定义格式通信。

rpc强类型客户端：使用接口定义语言生成强类型客户端。

##### protobuf JSON

* 编解码大多指明占据大小，采用位移运算，比 JSON/XML 的字符匹配效率高。
* 通过定义数据格式，去除变量名称和json中无意义的括号等符号，占据空间小。
* pb定义了Varint 类型，使用变长编码压缩数值类型。 简单来说，值越小的数字，使用越少的字节数表示 。




##### 治理

- 服务治理：服务注册；服务发现；注册中心主动摘除机制（心跳）；负载均衡（ 随机算法、轮询算法、最少活跃调用算法、一致性 Hash 算法）；扩缩容； 流量治理；稳定性治理
- 可观测性：日志采集；日志分析；监控打点； 监控大盘；异常报警；链路追踪
- 安全：身份验证；认证授权；访问令牌； 审计； 传输加密； 黑产攻击

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705121157334.png)

软路由：红绿发布时，屏蔽差异。

代码生成：契约开发，统一格式。

服务路由：通过一定的规则如条件表达式或者正则表达式来限定服务节点的选择范围（灰度发布：只有一
定比例的人群才会访问新发布的服务节点、就近访问：在选择服务节点时，优先选择同一 IP 段的节点）



![700](%E9%9D%A2%E7%BB%8F.assets/image-20220712163953134.png)

* 节点管理：Directory 负责从注册中心获取服务节点列表，并封装成多个 Invoker。
* 服务路由：Router 负责从多个 Invoker 中按路由规则选出子集（读写分离、机房隔离）
* 负载均衡：LoadBalance 负责从多个 Invoker 中选出某一个用于发起调用

#####  请求重试

- 本地函数调用，通常没有重试意义
- 远程函数调用：由于存在网络抖动、下游负载高、下游机器宕机，重试是有意义的，可以避免偶发性的错误，提高 SLA
- 重试的意义： 降低错误率；降低长尾延时；容忍暂时性错误；避开下游故障实例.

重试风暴：随着调用链路的增加，重试次数呈指数级上升

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706114346682.png)

* 限制重试比例：设定一个重试比例阈值（例如 1%），重试次数占所有请求比例不超过该阈值
* 防止链路重试：返回特殊的 status code，表示“请求失败，但别重试
* Hedged Requests：对于可能超时（或延时高）的请求，重新向另一个下游实例发送一个相同的请求

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706114437334.png)

##### 监控、分层

 QPS（调用量）、AvgTime（平均耗时）以及 P999（99.9% 的请求性能在多少毫秒以内）

覆盖业务埋点、数据收集（主动上报、代理收集）、上传处理中心(UDP、Kafka)、数据处理（计算每秒服务请求量、平均耗时以及成功率等指标），最后到数据展示的全链路功能。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705121831062.png)

主机上使用agent收集机器和服务的日志和指标，大量机器时大量信息使用mq解耦，数据采集后发送到指定的 Topic，然后数据处理单元再订阅对应的 Topic，就可以从 Kafka 消息队列中读取到对应的数据。

elk：展示分析查询日志。influxDB、grafana时间序列数据库呈现和展示。

##### 调用链监控

微服务是分布式复杂系统，调用关系复杂。记录服务调用经过的每一层链路，以便进行问题追踪和故障定位。

优化系统瓶颈；优化链路调用（跨数据中心的调用）；

span：请求进入容器生成一个span，当其调用其它服务时会再生成一个span。span中包含trace id 、当前span id，父span id，其中trace id由root span 生成，用于标识某一次具体的请求 ID，其它span 生成span id，通过 spanId 就可以定位某一次 RPC 请求在系统调用中所处的位置，以及它的上下游依赖分别是谁。通过最开始生成的 id串联所有节点，从而达到服务追踪的目的。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220712153042922.png)



server map：检测服务间依赖关系。心跳监控：检测服务活性。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705123007804.png)

##### 限流、熔断、过载保护、降级

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705225412495.png)

一个请求调用大量后台服务，限流熔断防止雪崩。

- 限流：限制服务处理的最大 QPS，拒绝过多请求
- 熔断：中断请求路径，增加冷却时间从而让故障实例尝试恢复
- 过载保护：在负载高的实例中，主动拒绝一部分请求，防止实例被打挂
- 降级：服务处理能力不足时，拒绝低级别的请求，只响应线上高优请求

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705124737332.png)

电路判断：电路打开直接短路返回，执行降级函数。线程资源不可用，执行降级。执行超时，执行降级。执行失败，执行降级。

电路是否打开、线程资源是否可用、执行是否超时、结果是否成功等指标防窥给计算电路健康中心，由计算电路健康中心控制熔断器，控制电路是否打开。

##### 持续交付

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705130124346.png)

镜像：镜像提供完整运行环境，保证依赖一致。可移植性好，只需要docker runtime 即可运行，与镜像具体执行的任务无关。

流水线式交付：流水线的方式，只有通过当前测试环节才能进入下一环节，质量有保证。

* 蓝绿部署：将服务分成两个部分，分别先后发布；简单、稳定；但需要两倍资源 。
* 灰度发布（金丝雀发布）：先发布少部分实例，接着逐步增加发布比例；不需要增加资源；回滚难度大，基础设施要求高 

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706113830151.png)

##### 容器资源调度与部署

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220705131007453.png)

发布平台查询资源治理中心，获取配合->启动mesos实例->拉取镜像->注册服务->发布平台挑拨流量（蓝绿发布、灰度发布）->网关发现服务-> 流量通过网关访问到服务。

##### 一致性hash

1，普通的hash算法进行路由，将数据映射到具体的节点上，如key%N，key是数据的key，N是机器节点数，如果有一个机器加入或退出这个集群，则所有的数据映射都无效了，如果是持久化存储则要做数据迁移，如果是分布式缓存，则其他缓存就失效了。

2，各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或唯一主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置。将object四个对象通过特定的Hash函数计算出对应的key值，然后散列到Hash环上,然后从数据所在位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。如果此时NodeC宕机了，此时Object A、B、D不会受到影响，只有Object C会重新分配到Node D上面去，而其他数据对象不会发生变化。如果在环境中新增一台服务器Node X，通过hash算法将Node X映射到环中，通过按顺时针迁移的规则，那么Object C被迁移到了Node  X中，其它对象还保持这原有的存储位置，避免了大量数据迁移，减小了服务器的的压力。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220907081305270.png)

2，当服务器节点比较少的时候，会出现一个问题，就是此时必然造成大量数据集中到一个节点上面，极少数数据集中到另外的节点上面。一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220907081356888.png)

##### raft算法

https://zinglix.xyz/2020/06/25/raft/

https://www.cnblogs.com/xybaby/p/10124083.html

1，流程

Raft 中使用 日志 来记录所有操作，所有结点都有自己的日志列表来记录所有请求。算法将机器分成三种角色：Leader、Follower 和 Candidate。正常情况下只存在一个 Leader，其他均为 Follower，所有客户端都与 Leader 进行交互。

所有操作采用类似两阶段提交的方式，Leader 在收到来自客户端的请求后并不会执行，只是将其写入自己的日志列表中，然后将该操作发送给所有的 Follower。Follower 在收到请求后也只是写入自己的日志列表中然后回复 Leader，当有超过半数的结点写入后 Leader 才会提交该操作并返回给客户端，同时通知所有其他结点提交该操作。通过这一流程保证了只要提交过后的操作一定在多数结点上留有记录（在日志列表中），从而保证了该数据不会丢失。

2，选举

初次选举：在算法刚开始时，所有结点都是 Follower，每个结点都会有一个定时器，每次收到来自 Leader 的信息就会更新该定时器。如果定时器超时，说明一段时间内没有收到 Leader 的消息，那么就可以认为 Leader 已死或者不存在，那么该结点就会转变成 Candidate，意思为准备竞争成为 Leader。成为 Candidate 后结点会向所有其他结点发送请求投票的请求（RequestVote），其他结点在收到请求后会判断是否可以投给他并返回结果。Candidate 如果收到了半数以上的投票就可以成为 Leader，成为之后会立即并在任期内定期发送一个心跳信息通知其他所有结点新的 Leader 信息，并用来重置定时器，避免其他结点再次成为 Candidate。

再次选举： 1，Leader 下线，此时所有其他结点的计时器不会被重置，直到一个结点成为了 Candidate，和上述一样开始一轮新的选举选出一个新的 Leader。2，某一 Follower 结点与 Leader 间通信发生问题，导致发生了分区，这时没有 Leader 的那个分区就会进行一次选举。这种情况下，因为要求获得多数的投票才可以成为 Leader，因此只有拥有多数结点的分区可以正常工作。而对于少数结点的分区，即使仍存在 Leader，但由于写入日志的结点数量不可能超过半数因此不可能提交操作。这解释了为何 Raft 至多容忍 (N−1)/2个结点故障。

投票限制：采用先来先得的原则，在一个任期内只可以投票给一个结点，得到超过半数的投票才可成为 Leader，从而保证了一个任期内只会有一个 Leader 产生。在 Raft 中日志只有从 Leader 到 Follower 这一流向，所以需要保证 Leader 的日志必须正确，即必须拥有所有已在多数节点上存在的日志。请求中除了有 Candidate 自己的 term 和 id 之外，还要带有自己最后一个日志条目的 index 和 term。接收者收到后首先会判断请求的 term 是否更大，不是则说明是旧消息，拒绝该请求。如果任期更大则开始判断日志是否更加新。日志 Term 越大则越新，相同那么 index 较大的认为是更加新的日志。接收者只会投票给拥有相同或者更加新的日志的 Candidate。由于只有日志在被多数结点复制之后才会被提交并返回，所以如果一个 Candidate 并不拥有最新的已被复制的日志，那么他不可能获得多数票，从而保证了 Leader 一定具有所有已被多数拥有的日志。

定时器：如果出现平票的情况，那么就延长了系统不可用的时间（没有leader是不能处理客户端写请求的），因此raft引入了randomized election timeouts来尽量避免平票情况。同时，leader-based 共识算法中，节点的数目都是奇数个，尽量保证majority的出现。

3，任期

每一个任期以一次选举作为起点，所以当一个结点成为 Candidate 并向其他结点请求投票时，会将自己的 Term 加 1，表明新一轮的开始以及旧 Leader 的任期结束。所有结点在收到比自己更新的 Term 之后就会更新自己的 Term 并转成 Follower，而收到过时的消息则拒绝该请求。任期是递增的，这就充当了逻辑时钟的作用；

4，日志复制

- Leader 绝不会覆盖或删除自己的日志，只会追加 （**Leader Append-Only**）
- 如果两个日志的 index 和 term 相同，那么这两个日志相同 （**Log Matching**）
- 如果两个日志相同，那么他们之前的日志均相同
- 当接收到该请求后，会先检查 term，如果请求中的 term 比自己的小说明已过期，拒绝请求。

raft算法为了保证高可用，并不是强一致性，而是最终一致性，leader会不断尝试给follower发log entries，直到所有节点的log entries都相同。

##### 架构

单机架构：All in one，所有的东西都在一个进程里，部署在一个机器上。

- 优点：简单；
- 缺点：运维需要停服，用户体验较差承载能力有限。

单体架构：在单机架构的基础上，将进程部署到多个机器上。

- 优点：具备水平扩容能力，运维不需要停服
- 缺点：后端进程职责太多，越来越臃肿；爆炸半径较大，进程中一个很小的模块出现问题，都可能导致整个进程崩溃；团队协作开发成本高（重新编译、完整测试）。

垂直应用架构，在单机架构基础上，将进程按照某种依据（业务）切分开，然后再按照单体模式的思路，部署在多个机器上。

- 优点：一定程度上减少了后端进程职责；一定程度上缩小爆炸半径
- 缺点：没有根本解决单体架构的问题

面向服务架构SOA：服务为一等公民，将进程按照不同的功能单元进行抽象，拆分为『服务』。有了服务之后，SOA 还为服务之间的通信定义了标准，保证各个服务之间通讯体验的一致性。服务化就是把传统的单机应用中通过 JAR 包依赖产生的本地方法调用，改造成通过 RPC 接口产生的远程方法调用。模块信息外界可知（戚风1，戚风2）

- 优点：各服务的职责更清晰；运维粒度减小到服务，爆炸半径可控，模块独立开发、测试、上线和运维（一台物理机上多个 Docker 实例，每个 Docker 实例部署一个微服务的代码），每个微服务都可以交由一个小团队甚至个人来开发、测试、发布和运维，并对整个生命周期负责，按照每个开发人员负责不超过 3 个大的服务为标准，毕竟每个人的精力是有限的，所以在拆分微服务时，可以按照开发人员的总人数来决定。服务拆分粒度更细，只要该模块依赖的资源与其他模块都没有关系，那么就可以拆分为一个微服务。
- 缺点：ESB (企业服务总线) 往往需要一整套解决方案，服务的数量变多，因此需要有统一的服务治理平台，来对各个服务进行管理。

微服务：在 SOA 架构中，ESB 起到了至关重要的作用。但从架构拓扑来看，它更像是一个集中式的模块。有一个SOA 分布式演进的分支，最终的形态便是微服务。纵向拆分：是从**业务维度**进行拆分。标准是按照业务的关联程度来决定，关联比较密切的业务适合拆分为一个微服务，而功能相对比较独立的业务适合单独拆分为一个微服务。横向拆分，是从公共且独立**功能维度**拆分，标准是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合。如果业务比较多分散，适合做纵向拆分。如果多个业务之间有公共模块耦合，适合把公共模块拆分出来，适合做横向拆分。模块信息外界不可知，通过集群的方式接收请求完成功能（戚风集群），适合上云。

- 优点：兼具 SOA 解决的问题；服务间的通信更敏捷、灵活
- 缺点：运维成本

SOA VS MS
1. 服务粒度
SOA：服务粒度较大，通常以业务功能模块为单位（如订单服务、用户服务），服务内部可能包含多个子模块。
微服务：服务粒度更细，按单一职责设计，一个服务只完成一个非常具体的功能。
2. 技术栈
SOA：倾向于统一技术栈，通过企业服务总线（ESB）进行通信，依赖规范化的协议如SOAP。
微服务：鼓励技术多样性，每个服务可以选择最合适的技术栈，通常通过轻量级协议如HTTP/REST或gRPC进行通信。
3. 服务间通信
SOA：通常通过企业服务总线（ESB）实现复杂的通信、路由和转换，ESB是核心组件。
微服务：服务直接通信或通过轻量级网关，避免单点依赖，通常采用点对点方式。
4. 部署方式
SOA：服务更倾向于集中式部署，例如在一个应用服务器中运行多个服务。
微服务：独立部署，每个服务独立运行，通常结合容器技术（如Docker）和编排工具（如Kubernetes）。


##### 云原生与容器

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706155743073.png)



微服务能够实现快速开发迭代，但随之带来的问题是测试和运维部署的成本的提升。

* 弹性资源:基于虚拟化容器以及灵活的编排调度机制，可以为云服务提供快速扩缩容能力，而且极大程度地提高了物理资源的利用率。在这方面，kubernetes 技术已经称为了业界的标准。ECS 通常只包含了基本的操作系统环境，Docker 镜像不光可以打包应用程序本身，而且还可以打包应用程序的所有依赖，甚至可以包含整个操作系统，环境保持一致。

* 微服务架构:微服务架构是云原生的重要基石之一。依托于功能单元解构， 使得云服务具备了快速迭代的可能，业务得以迅速发展;统- -的通信标准能够帮助越来越多的组件加入到云原生的大家庭，同时也使得各组件之间的交互变的更容易

* DevOps:设计- >开发>测试- >交付- >开发>测试>交付，自动化的流程使得软件的工作流程更高效，将微服务架构的优势发挥的淋漓尽致。求开发、测试和发布的流程必须自动化，保证开发人员将自己本地部署测试通过的代码和运行环境，能够复制到测试环境中去，测试通过后再复制到线上环境进行发布。

  DevOps 的关键是如何实现代码开发自测通过，自动部署到测试环境，验证通过后再自动部署到生产环境，小流量验证后再自动发布到线上去。器化正好解决了代码环境的可移植性的问题。

  CI（Continuous Integration），持续集成。自动代码检查、单元测试、打包部署到测试环境，集成测试。

  CD（Continuous Deploy），持续部署。代码测试通过后，能自动部署到类生产环境中进行集成测试，测试通过后再进行小流量的灰度验证，验证通过后代码就达到线上发布的要求。

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706160404985.png)

* 服务网格:控制应用程序不同部分彼此共享数据的方式，负责服务之间的网络调用、限流、熔断和监控。将业务逻辑与网络通信和治理解耦开来，作为微服务间的中间层。微服务中有许多既定的服务实例，它们跨本地和云服务器运行。Service mesh 可以在短时间内自动处理发现和连接服务，而无需开发人员以及各个微服务自行匹配。业务不再需要关心异构系统中RPC中间件治理能力的不统一， 也使得复杂的治理能力的落地成为可能。

##### 资源均衡

* 考虑到在线业务的潮汐性、实时性，物理资源的用量不是一成不变的，离线业务计算密集型、非实时性。离在线资源并池，可以提高物理资源利用率；提供更多的弹性资源。

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706160753294.png)

* 通过将微服务调用形态与资源调度系统结合，将一些调用关系紧密、通信量大的服务部署在同一个机器上，并且使用 IPC 代替 RPC 的方式，降低网络通信带来的开销。

4，cpu负载均衡

打平异构环境算力差异，为自动扩缩容提供正向输入。提供资源探针，动态均衡负载。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706161154321.png)

##### RPC

组件：客户端、服务端和注册中心。

1，原理

* 在本地调用中，函数体是通过函数指针来指定的，远程调用中，函数指针是不行的，因为两个进程的地址空间是完全不一样的。所以函数都有自己的一个ID，在做 RPC的时候要附上这个ID，还得有个 ID 和函数的对照关系表，通过 ID找到对应的函数并执行。
* 在本地调用中，我们只需要把参数压到栈里，然后让函数自己去栈里读就行。但是在远程过程调用时，客户端跟服务端是不同的进程，不能通过内存来传递参数。这时候就需要客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。

2，实现

建立连接后，双方按照某种约定的协议进行网络通信，服务端接收到请求时，需要以某种方式进行处理，处理成功后，把请求结果返回给客户端。

rpc由5个模型组成。完成调用发起->参数打包->调用发送->调用接收->参数拆包->执行调用->结果打包->结果发送->结果接收->结果拆包。

服务端处理请求：同步阻塞方式（BIO），客户端每发一次请求，服务端就生成一个线程去处理，适用于连接数比较小的业务场景。。同步非阻塞方式 (NIO)，客户端每发一次请求，服务端并不是每次都创建一个新线程来处理，而是通过 I/O 多路复用技术进行处理，适用于连接数比较多并且请求消耗比较轻的业务场景。异步非阻塞方式（AIO），客户端只需要发起一个 I/O 操作然后立即返回，等 I/O 操作真正完成以后，客户端会得到 I/O 操作完成的通知，AIO 适用于连接数比较多而且请求消耗比较重的业务场景。

序列化反系列化：文本类如 XML/JSON 等，二进制类如 PB/Thrift。支持数据结构类型的丰富度、跨语言支持、序列化后的压缩比、序列化的速度

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706172104043.png)



3，流程

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706173110731.png)

* IDL通过一种中立的方式来描述接口，描述方法签名个方法参数列表，使得在不同平台上运行的对象和用不同语言编写的程序可以相互通信。

* 通过编译器工具把IDL文件转换成语言对应的静态库，双方依赖同一份IDL文件。

- 从内存中表示到字节序列的转换称为编码，反之为解码，也常叫做序列化和反序列化。解决跨语言数据交换。

- 规范了数据在网络中的传输内容和格式。除必须的请求/响应数据外，通常还会包含额外的元数据。

* 通常基于成熟的网络库走TCP/UDP/http传输（HTTP 通信/ Socket 通信）。
* 客户端：首先根据接口定义，通过 Proxy 层封装好的透明化接口代理，发起调用。->然后在通过 Registry 层封装好的服务发现功能，获取所有可用的服务提供者节点列表。->再根据 Cluster 层的负载均衡算法从可用的服务节点列表中选取一个节点发起服务调用。->通过 Filter 层拦截调用，实现客户端的监控统计。->在 Protocol 层，封装成 Dubbo RPC 请求，发给服务端节点。
* 服务端：首先在 Protocol 层，把网络上的请求解析成 Dubbo RPC 请求->然后通过 Filter 拦截调用，实现服务端的监控统计。->最后通过 Proxy 层的处理，把 Dubbo RPC 请求转化为接口的具体实现，执行调用。

5，优势

* 单一职责，有利于分工协作和运维开发（开发可以采用不同语言；部署及运维都是独立的）

* 可扩展性强，资源使用率更优（压力过大时可以独立扩充资源，底层基础服务可以复用，达到节省资源的目的）

- 故障隔离（一个模块发生故障，不会影响整体，服务的整体可靠性更高）

6，设计

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220706174232511.png)



##### 服务网格

1，一种新型的用于处理服务与服务之间通信的技术，尤其适用以云原生应用形式部署的服务，能够保证服务与服务之间调用的可靠性。在实际部署时，Service Mesh 通常以轻量级的网络代理的方式跟应用的代码部署在一起，从而以应用无感知的方式实现服务治理。通过代理方式实现负载均衡、熔断、超时重试、监控统计以及服务路由等功能。

2，跨语言服务调用的需要，为实现跨语言调用，使用服务化框架，但现有框架要么与特定的语言绑定，比如 Dubbo 和 Spring Cloud 只支持 Java 语言，要么是跟语言无关，比如 gRPC和 Thrift，得定义个 IDL 文件，然后根据这个 IDL 文件生成客户端和服务端各自语言的 SDK，并且服务框架的功能比如超时重试、负载均衡、服务发现等，都需要在各个语言的 SDK 中实现。云原生应用服务治理的需要，对业务代码无侵入的适合云原生应用的服务治理方式。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220712182634359.png)

3，Service Mesh 实现的关键就在于两点：一个是上面提到的轻量级的网络代理也叫 SideCar，它的作用就是转发服务之间的调用，既要作为服务消费者端的正向代理，又要作为服务提供者端的反向代理；一个是基于 SideCar 的服务治理也被叫作Control Plane，它的作用是向 SideCar 发送各种指令，以完成各种服务治理功能，服务发现、服务注册、负载均衡、限流降级、超时熔断、动态路由、监控上报和日志推送等功能。

##### 限流算法

https://segmentfault.com/a/1190000023552181
* 计数限流：保存一个计数器，处理了一个请求，计数器加一，一个请求处理完毕之后计数器减一。无事件区间约束。
* 固定窗口：计数器每过一个时间窗口就重置，在窗口中计数。存在固定窗口临界问题。
* 滑动窗口限流：窗口随时间滑动，在窗口中计数。
* 漏桶算法：服务按照固定的速率处理请求，计算当前时刻与起始时刻之间消耗的请求数，获得当前剩余请求，根据剩余请求+当前新到来请求是否超出阈值来决定是否接受请求。
* 令牌桶：令牌桶是定速地往桶里塞入令牌，然后请求只有拿到了令牌才能通过，之后再被服务器处理。

##### Nginx动静分离

https://cloud.tencent.com/developer/article/1924713

##### 接口变慢排查思路 

https://juejin.cn/post/7064140627578978334
**如果系统中有多个服务的接口都变慢**，那可能是**系统共用的资源不足**导致的，比如数据库连接数太多、数据库有大量慢查询、一些共同依赖的下游服务性能问题等，可以查看系统中调用量激增的服务，它的调用量是否导致数据库的并发达到了瓶颈，它是不是导致共同调用的下游服务出现了性能问题，数据库中是不是有大量这个服务引起的慢查询等，做针对性的优化

- 如果数据库并发达到瓶颈，可以考虑用读写分离、分库分表、加读缓存等方式来解决
- 如果下游接口出现性能问题，需要通知下游服务做优化，同时要加降级开关
- 如果数据库中有大量慢查询，需要改sql或加索引等

**如果是只有一个服务的接口变慢**，那就要针对这个服务做分析，查看它的cpu占用率和gc频率是不是异常，做针对性的优化（cpu占用率飙升的排查解决思路，单独写一篇文章来聊）。也可能是这个服务单独依赖的下游服务性能出现了问题

**如果是只有一个接口变慢**，那就要针对这个接口做分析。可能是这个接口单独依赖的下游服务性能出了问题。也可能是它本身的代码写的有问题，需要优化

- 比如在循环里获取远程数据，可以改成只调用一次，批量获取数据
- 比如在链路中多次调用同一个远程接口获取相同数据，可以第一次调用之后就把数据缓存起来，后续直接从缓存中获取
- 比如为了得到一个复杂的model，需要调多个接口获取信息，但当前接口只需要其中部分比较简单的数据，那么需要根据实际情况，重新写一个简单model的获取方法
- 比如如果多个比较耗时的操作是串行执行的，但它们又没有依赖关系，就可以把串行改成并行，可以用countDownLatch
- 还有如果实在无法再缩短请求处理耗时的话，也可以考虑从产品逻辑上进行优化，比如把原来的同步请求改为异步的，前端再去轮询请求处理结果


##### 超卖

悲观锁（并发限制），乐观锁（版本号比较）

1，库存在Redis中保存；收到请求Redis判断是否库存充足 ,减掉Redis中库存；订单服务创建订单写入数据库,并发送消息；当订单支付成功后，会有一个出库过程，既然有这个过程，就有可能出库失败。

2，库存有两部分：缓存redis层，数据库mysql层

* 时间戳加密发送到服务端，防止用户恶意脚本批量请求。Redis集群，主从同步、读写分离，杠高并发。Nginx负载均衡，机器水平扩展。静态资源放入cdn服务器。前端限流，限时点击，只能点击一次，IP限制请求次数。

* 预热缓存，加载商品库存。同时redis保存已下单成功用户集合，防止重复购买。请求到来时先判断是否已经购买，通过后Lua脚本实现类似Redis事务，保证原子性，先扣redis库存，如果扣除成功，则生成订单进行支付，这个过程不扣除mysql库存。当redis库存扣完，该产品就无法下单了，下单就会失败，就把外层的给挡住了。
* 在扣除redis库存成功后，生成订单，进行支付，支付失败库存+1。
* 出库一个MQ异步解耦的任务队列，这个过程是扣除mysql库存：如果扣mysql库存成功，出库成功，完成下订单整个流程，进入发货状态，当前用户添加到已购买用户集合；如果扣mysql库存失败，出库失败，进行一系列的操作 订单状态改成取消，返还redis库存，退款。

##### 高可用系统

https://www.51cto.com/article/643130.html

1， 设计阶段：

* 避免存在单点：从请求发起侧到服务处理返回的调用全链路的各个环节上避免存在单点(某个环节只由单个服务器完成功能)，避免单个服务器挂掉引发单点故障后进而导致服务整体挂掉的风险。

  在服务逻辑层：跨地、同地多机房部署、同机房多机器部署、分布式任务调度等策略。在数据存储层采用主从备集群、多副本等策略。

* 数据一致性：分布式事务中通过消息触发多系统对账、定时调度对账、子流程失败后主动投递消息延迟重试、消息消费失败后回旋重试、离线全量对账。

* 强弱依赖梳理和降级：避免强依赖(依赖服务挂掉会到自己服务挂掉)，尽可能在对应服务出现问题时做到自动降级处理(弱依赖)或者手工降级，降级后依赖服务功能局部去掉，体验上有部分降级，但不会让主链路和整体功能挂掉。在成本可接受的情况下，同时维护一套保障主链路可用的备用系统和架构。

* 热点或极限值处理：数据热点、数据极度倾斜、少量大客户超过极限阈值使用等极限场景，导致单库抖动，这除了影响大客户自己外也会影响分布在该分库分表上所有普通客户。

  大客户从普通客户分库分表中拆出来隔离建库表。秒杀系统极限值可以考虑消息解耦、部分查询或处理KV存储替代关系型存储、数据提前预热加载、排队、限流策略等策略;

* 资金交易：增加多层级对账、券总额度控制、异常金额限制和报警等资损防控的考量等。全链路的过程数据要做好尽可能持久化和冗余备份，方便后续核对以及基于过程数据进行数据修复。

2， 容量评估设计

* 系统设计整体至少考虑应对5到10倍或近1到3年系统规模增长，要保障后续通过增加机器资源等快速方式能实现系统水平扩容。例如分库分表的规模提前设计好提前量。
* 针对线上流量峰值，建议系统常态保持近期峰值3倍左右容量余量，上线前和上线后要定期做压测摸高。
* 对依赖服务的调用都要评估可极限调研的上限值，通过中间件等合适方式限制超过阈值调用，避免引发雪崩效应。对于超过峰值流量，可以通过消息架构以及合适体验设计做削峰填谷。针对恶意攻击流量也要考虑在入口层部署防DDOS攻击的流量清洗层。

3，运维方案设计

* 可灰度保障及时在小流量情况，发现问题，避免引发大范围故障。不同流量比例、机器分批发布、业务概念相关分组分比例
* 监控项要系统性确认是否完备以及保持更新，可能监控项：接口成功率、机器基础负载相关监控(CPU利用率、cpu Load、内存、IO、网络等)、服务基础监控(端口、进程、状态探活、JVM full gc、OOM等)、数据库负载监控、数据库慢请求、流量同比剧烈变化。
* 新增功能增加配置开关，当线上出现问题时，可通过关闭功能开关，快速下线最新升级 或部分有问题功能。

4，代码实现

* 比较通用保障方式是分支覆盖完备的单元测试 、线上引流回归测试、完备回归测试用例等测试质量保障措施。

* 技术Review，代码Code Review

5，运维

* 定期排查线上隐患、用户问题处理机制、线上问题复盘机制、定期压测机制，报警不要放过
* 日常预案。

##### 接口设计

https://ost.51cto.com/posts/12642

https://www.woshipm.com/pd/2772820.html

##### 限流

https://juejin.cn/post/6870396751178629127

##### token

1. 去中心化的JWT token 

   优点：去中心化，token本身携带信息，自解释，便于分布式系统使用。 基本信息可以直接放在token中。 username，nickname，role 。 功能权限较少的话，可以直接放在token中。

   缺点：服务端不能主动让token失效  ，只能等待token过期。  

2. 中心化的 redis token

   优点：服务端可以删除缓存，主动让token失效        

   缺点：依赖内存或redis存储 ，分布式系统的话，需要redis查询/接口调用增加系统复杂性。

##### 接口幂等

1，数据库悲观锁：select * from t_order where order_id = trade_no for update;`数据会对当前记录加锁，其他线程执行到此行代码的时候，会等待线程A释放锁之后，才可以获取锁，继续后续操作，并发低。

2，数据库唯一主键：利用数据库中主键唯一约束的特性，使用分布式 ID 充当主键。

3，使用版本号或者时间戳，更新一次版本号+1，每次操作带上版本号过滤条件

4，分布式锁：在每次执行方法之前判断，是否可以获取到分布式锁，如果可以，则表示为第一次执行方法，否则直接舍弃请求即可。

##### 单点登录

https://developer.aliyun.com/article/636281

https://zhuanlan.zhihu.com/p/66037342

1，单点登录就是在多个系统中，用户只需一次登录，各个系统即可感知该用户已经登录。

2，粘滞会话、session赋值、集中会话

3，同域下的单点登录：SSO专门用于登录，并且将session放置于公共存储空间，同时将Cookie的域设置为顶域`sso.abc.com->abc.com`，以便于访问`app1.abc.com`也能带上cookie，app1再到公共session中查找用户。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221028124135707.png)

4，不同域下的单点登录

* 系统A用户并没有登录，于是重定向到sso认证中心，用户进行输入用户名和密码进行登录，用户与认证中心建立全局会话（生成一份Token，写到Cookie中，保存在浏览器上）。
* 认证中心重定向回系统A，并把Token携带过去给系统A，系统A去sso认证中心验证这个Token是否正确，验证通过后，A系统将登录状态写入session并设置A域下的Cookie，二次访问A将带上A的cookie免去认证。
* 系统B发现用户并没有登录，于是重定向到sso认证中心，因为之前用户与认证中心已经建立了全局会话，所以重定向到认证中心sso是可以带上Cookie的，完成认证。重定向回系统B，并把Token携带过去给系统B，系统B去sso认证中心验证这个Token是否正确。验证成功后，B将登录状态写入session，并在B域下写入Cookie，二次访问B将带上B的cookie免去认证。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221028124838516.png)

### spring

##### 依赖查找与依赖注入

![700](%E9%9D%A2%E7%BB%8F.assets/clip_image001.png)

##### 构造器注入与set注入

对强制依赖项使用构造函数，对可选依赖项使用 setter 方法或配置方法是一个很好的经验法则。

set注入：

- 优点：getXXX,setXXX方法名准确描述功能；可以设置非必须和默认值，，解决循环依赖。
- 缺点：对象被调用前无法保证set方法被调用，状态不一定。

构造器注入：

- 优点：保证被调用前被完全配置，状态一定；
- 缺点：自文档性更差（swagger可生成构造器解释）；无法解决循环依赖。

https://www.cnblogs.com/think-in-java/p/5474740.html

##### 解决循环依赖

构造函数注入不允许您在 bean 之间创建循环依赖关系：有参构造器相当于将实例化和初始化合并了，不存在早期曝光对象这个中间态，因此后续的依赖调用构造方法的时候并不能从三级缓存中获取到依赖的Bean，因此不能解决。

非单例循环依赖：无法处理，每次调用一次getBean都会执行一次构造方法并且给属性赋值，缓存没意义所以根本没有三级缓存，因此不能解决循环依赖

单例模式下使用 setter 注入时，Spring 可以通过“三级缓存”解决循环依赖。

https://cloud.tencent.com/developer/article/1749830

![700](%E9%9D%A2%E7%BB%8F.assets/clip_image002.png)

一个完整的对象包含三部分：当前对象实例化（构造器）、对象属性的实例化（set方法）以及初始化（xml中的 init方法）。在Spring中，对象的实例化是通过反射实现的，而对象的属性实例化则是在对象实例化之后通过一定的方式设置的。

Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（singletonObjects）缓存完成对象、属性实例化以及初始化的完成品对象，二级缓存为早期曝光对象earlySingletonObjects，完成了对象实例化，未完成属性实例化以及初始化，三级缓存为对象工厂（singletonFactories），该工厂用于创建早期曝光对象。

===>当A、B两个类发生循环引用时，在A完通过对象工厂实例化。

===>当A进行属性注入时，此时就尝试去get(B)，完成对象B的实例化。

===>初始化B时，发现B又依赖了A，得到已经实例化但尚未初始化的A，B完成初始化、放入到一级缓存。

===>当B创建完后，会将B再注入到A中，此时A完成初始化，循环依赖结束。

##### 依赖注入

* 依赖注入和面向接口->松耦合；不强迫实现spring的接口继承spring的类（无侵入）、通过组件扫描（发现应用上下文定义的bean）和自动装配(自动满足依赖关系)来使用自定义的POJO;
* 耦合代码难以测试和复用（四处分布），在对象关系比较复杂时，依赖关系难以维护；
* 将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理（并且管理这些对象的整个生命周期。将对象之间的相互依赖关系交给 IOC 容器来管理，并由 IOC 容器完成对象的注入，松耦合、声明依赖即可，使用者不用创建和管理依赖，组件之间依赖关系由容器在运行期决定，专注本身业务功能，大大增加了项目的可维护性且降低了开发难度、接口（多态、不用知道到底由谁提供服务，通过面向接口编程的方式来是实现对业务组件的动态依赖）。
* 容器：创建、装配、生命周期管理；使用DI管理组件间关连、简洁、重用、易于测试。类别：BeanFactory（是 Spring 里面最底层的接口，包含了各种 Bean 的定义，读取 bean 配置文档，管理 bean 的加载、实例化，控制 bean 的生命周期，维护 bean 之间的依赖关系。简单，提供完整的IoC服务支持、延迟初始化（不能发现一些存在的 Spring 的配置问题）、资源有限，并且功能要求不是很严格）+ApplicationContex（ClassPathXmlApplicationContext、FileSystemXmlApplicationContext，BeanFactory的基础上、框架级、启动之后全部初始化（在容器启动时，我们就可以发现 Spring 中存在的配置错误），资源充足，并且要求更多功能，国际化、从xml、配置类加载配置、getBean(name，Class)）
* 依赖注入的基本原则：应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由 IoC 容器负责，“查找资源” 的逻辑应该从应用组件的代码中抽取出来，交给 IoC 容器负责。容器全权负责组件的装配，它会把符合依赖关系的对象通过属性（JavaBean 中的 setter）或者是构造器传递给需要的对象。
* 优势：让容器全权负责依赖查询，受管组件只需要暴露 JavaBean 的 setter 方法或者带参数的构造器或者接口，使容器可以在初始化时组装对象的依赖关系：查找定位操作与应用代码完全无关；不依赖于容器的 API，可以很容易地在任何容器以外使用应用对象；不需要特殊的接口，绝大多数对象可以做到完全不必依赖容器。
* @Autowired 和 @Resource 之间的区别：Autowired 默认是按照类型装配注入的，默认情况下它要求依赖对象必须存在（可以设置它 required 属性为 false）。@Resource 默认是按照名称来装配注入的，只有当找不到与名称匹配的 bean 才会按照类型来装配注入。

IOC、DI

* ioc是目的，di是手段。ioc是指让生成类的方式由传统方式（new）反过来，将我们设计好的对象交给容器控制，而不是传统的需要时在内部构造直接控制，只需要在 IoC 容器中获取所需对象，全盘由 IoC 容器帮我们创建对象以及注入其所依赖的对象，无需关心创建过程以及其中的依赖对象，把对象的控制权反转给了 IoC 容器，所以称为反转。

##### 生命周期

https://juejin.cn/post/6844904065457979405

1，Bean 容器找到配置文件中Spring Bean的定义，创建一个 Bean 的实例。

2，如果涉及到一些属性值 利用 set()方法设置一些属性值。

3，Aware 接口声明了依赖关系，注入Bean对容器基础设施层面的依赖，来感知到自身的一些属性。如果Bean实现了BeanNameAware接口，调用setBeanName()方法，传入Bean的名字。同样如果 Bean 实现了 BeanFactoryAware 接口，传入 BeanFactory对象的实例。实现了ApplicationContexAware接口，传入ApplicationContex对象的实例。

4，如果有实现了BeanPostProcessor接口的对象对该bean进行进行拦截，执行postProcessBeforeInitialization() 方法，完成 initial 前的自定义逻辑。

5，如果Bean实现了InitializingBean接口，执行afterPropertiesSet()方法，完成一些属性被设定后的自定义的事情。

6，如果存在该Bean种存在@PostConstru注解的方法，则执行该方法。

7，如果有实现了BeanPostProcessor接口的对象对该bean进行进行拦截，执行postProcessAfterInitialization() 方法，做一些 bean 初始化之后的自定义工作。

8，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 自定义的销毁方法。

9，要销毁 Bean 的时候，如果存在该Bean种存在@PreDestroy注解的方法，则执行该方法。

容器上下文被摧毁开始bean的回收。干预节点：@PostConstruct注解、@PreDestroy注解，xml配置（init-method 和 destroy-method），用它们你可以自己定制初始化和注销方法。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220311112905215.png)

##### BeanPostProcessor

spring会自动从它的所有的bean定义中检测BeanPostProcessor类型的bean定义，然后实例化它们，再将它们应用于随后创建的每一个bean实例，在bean实例的初始化方法回调之前调用BeanPostProcessor的postProcessBeforeInitialization的方法（进行bean实例属性的填充），在bean实例的初始化方法回调之后调用BeanPostProcessor的postProcessAfterInitialization的方法（可以进行bean实例的代理封装）

https://www.cnblogs.com/lifullmoon/p/14677287.html

```java
@Override
public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
    if(bean instanceof SomeBean){
        try {
            Field valueField=bean.getClass().getDeclaredField("value);
            valueField.set(bean,"new value);
        } catch (NoSuchFieldException e) {
            e.printStackTrace();
        } catch (IllegalAccessException e) {
            e.printStackTrace();
        }
    }
    return bean;
}
```

```java
@Override
public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) {
    // <1> 如果 bean 不为空则进行接下来的处理
    if (bean != null) {
        // <1.1> 获取这个 Bean 的缓存 Key，默认为 Bean 的名称，没有则取其对应的 Class 对象
        Object cacheKey = getCacheKey(bean.getClass(), beanName);
        /*
         * <1.2> 移除 `earlyProxyReferences` 集合中保存的当前 Bean 对象（如果有的话）
         * 如果 earlyProxyReferences 集合中没有当前 Bean 对象，表示在前面没有创建代理对象
         */
        if (this.earlyProxyReferences.remove(cacheKey) != bean) {
            // 这里尝试为这个 Bean 创建一个代理对象（如果有必要的话）
            // 获取bean对应的Advisor,如果有 Advisor，则利用JDK 动态代理或者 CGLIB 动态代理创建并返回代理对象
            return wrapIfNecessary(bean, beanName, cacheKey);
        }
    }
    // <2> 直接返回 bean 对象
    return bean;
}
```

##### 装配bean的方式

隐式自动化装配：隐式操作降低维护成本；组件扫描发现上下文中的bean（@component+@ComponentScan）;自动装配满足bean之间依赖（@Autowired()修饰构造方法、字段、普通方法，自动运行修饰的方法从容器中查找bean）； 

配置类显示装配：不包含业务逻辑、@Cinfiguration包含创建Bean的细节；方法添加@Bean注解（一次调用、单列，参数为待注入的依赖，返回注入依赖的对象，适用于第三方库）；

XML装配显示装配：构造器注入bean；属性设置；格式复杂且纯字符操作ide的类型检查困难，以后项目结构变化还要手动更新配置。可以和javaconfig合作共同实现装配。

* 环境装配：根据环境决定创建哪个bean；@profile指明该bean在何种条件下被激活（和@Configration和@Bean共同使用）；环境由profile.active和profile.default指定，可激活多个环境。
* 条件装配：条件计算为True才装配；@Condition()参数为实现condition的接口实现类；
* 歧义装配：一个接口多个实现类；指定@Pimary、限定符限定bean、自定义注解（在创建注解时指明他是一个限定注解，在创建Bean时添加上自定义的注解，表明该bean拥有某种属性，装配时添加自定义的注解，表明装配进来的bean要满足某种属性，多个限定自定义注解合作，相较于string的限定符更安全）。
* 运行时注入：@propertySource指定配置文件中的一块区域，其配置项与类字段对应。@value指定常量、配置文件项、bean属性为注入的值。

##### 同名bean

* 同一个配置文件内同名的 Bean，以最上面定义的为准。

* 不同配置文件中存在同名 Bean，后解析的配置文件会覆盖先解析的配置文件。

* 同文件中 ComponentScan 和 @Bean 出现同名 Bean。同文件下 @Bean 的会生效，@ComponentScan 扫描进来不会生效。通过 @ComponentScan 扫描进来的优先级是最低的，原因就是它扫描进来的 Bean 定义是最先被注册的。

##### bean作用域

* 单例：一个bean
* 原型：每次注入都创建新的bean
* 会话：每个会话一个bean,购物车；单例bean依赖会话bean：创建代理类（接口：动态代理，类：cglib）注入到单例类，代理类暴露和会话bean 相同方法，具体调用时间委托给会话作用域内具体的会话bean实现。
* 请求：一个请求一个bean，原题同会话bean
* 全局会话：在一个全局的 HTTP Session 中，一个 bean 定义对应一个实例。该作用域仅在基于 web 的 Spring ApplicationContext 情形下有效。 

##### Bean的线程安全策略

如果单例的Bean是一个无状态（不保存数据，是不变类），只有读操作，而无写操作的Bean，那么这个单例的Bean是线程安全的。若有多个线程同时执行写操作，一般都需要考虑线程同步，否则就可能影响线程安全。如果单例的Bean是一个有状态的Bean，则可以在 Bean 对象中尽量避免定义可变的成员变量（不太现实），在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。

##### 应用上下文

https://www.cnblogs.com/lifullmoon/p/14453083.html

运行环境，保证应用的正常运行，具体就是管理应用所依赖的bean，并在需要该bean的地方注入依赖，容器是Spring框架实现功能的核心，容器不只是帮我们创建了对象那么简单，它负责了对象整个的生命周期的管理——创建、装配、销毁。应用上下文即是Spring容器的一种抽象化表述，ApplicationContext本质上是一维护Bean定义以及对象之间协作关第的高级接口。将需要管理的对象（Spring中我们都称之问bean）、bean之间的协作关系配置好，然后利用应用上下文对象加载进我们的Spring容器，容器就能为你的程序提供你想要的对象管理服务。AnnotationConfigApplicationContext、ClassPathXmlApplicationContext、FileSystemXmlApplicationContext。

DefaultListableBeanFactory：这就是大家常说的 ioc 容器，它里面有很多 map、list。spring 帮我们创建的 singleton 类型的 bean 就存放在其中一个 map 中。扩展点集合：存放 spring 扩展点（BeanPostProcessor）接口的 list 集合。 启动其实就是调用refresh 完成 spring context 的初始化和启动过程：创建 BeanFactory、注册 BeanPostProcessor 等。

##### AOP

* 常用功能分离形成可重用组件（日志），减少系统的重复代码，降低模块间的耦合度，集中管理维护方便，声明式（切面构成、将功能应用到要影响的组件中，无需修改受影响的类）编程较少模板代码，解耦，有利于未来的可拓展性和可维护性；核心代码更关注业务逻辑（高内聚、简单），无感知；

* 静态代理（在编译阶段就可生成 AOP 代理类，AspectJ），动态代理（spring AOP:运行时借助于JDK动态代理、CGLIB等在内存中“临时”生成AOP动态代理类,final修饰的类不能被代理，同样static和final修饰的方法也不会代理，因为static和final方法是不能被覆盖的）

  ![700](%E9%9D%A2%E7%BB%8F.assets/640.jpg)

* 通知（什么+时机）：定义切面功能与出发时机；（bofore,after,around等）。连接点：程序中能够插入切面的点（方法调用、抛出异常），通过切入点添加新功能。切点（何处）：表达式匹配要织入的连接点。切面（是什么+何时+何处）=通知+切点。织入：把切面应用到目标对象并创建代理对象的过程，运行期：创建动态代理、springAOP。

  

##### spring注解AOP

基于jdk动态代理，拦截接口方法，创建接口的代理实例，只支持方法连接点只能拦截方法；代理类包裹目标类，拦截方法调用，执行切面逻辑，转发给真正的bean。核心InvocationHandler接口和Proxy类，InvocationHandler 通过invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；接着，Proxy利用 InvocationHandler动态创建一个符合某一接口的的实例, 生成目标类的代理对象。

cglib代理：目标对象不是接口，字节码生成代理类继承目标类，并覆盖其中特定方法并添加增强代码，所以final修饰的类不能被代理，同样static和final修饰的方法也不会代理。CGLib创建的代理对象性能比JDK动态代理创建的代理对象高很多，但花费的时间多，spectJ需要特定的编译器进行处理，而Spring AOP则无需特定的编译器处理，cglib适合单例的对象代理创建，jdk动态代理合多例的对象代理创建。

只能对IoC容器中的Bean进行增强。

* 切点：切点的定义会匹配通知所要织入的一个或多个连接点，描述要连接的连接点进行匹配，这个点可以是调用方法时、抛出异常时、甚至修改一个字段时。切面代码可以利用这些点插入到应用的正常流程之中，并添加新的行为。spring AOP只能方法拦截(execution)。多条件与或非复杂逻辑，被影响的类无感知。

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220311175300036.png)

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220311174849429.png)

* 通过在代理类中包裹切面，Spring在运行期把切面织入到Spring管理的bean中。代理封装了目标类，并拦截被通知方法的调用，再把调用转发给真正的目标bean。当代理拦截到方法调用时，在调用目标bean方法之前，会执行切面逻辑。

  直到应用需要被代理的bean时，Spring才创建代理对象。如果使用的是ApplicationContext的话，在ApplicationContext从BeanFactory中加载所有bean的时候，Spring才会创建被代理的对象。因为Spring运行时才创建代理对象，所以我们不需要特殊的编译器来织入SpringAOP的切面。

* 新建功能：通过AOP为bean添加新方法；代理类不仅暴漏被包装bean的方法还暴漏新加入接口，一个bean的实现拆分到多个bean中；添加新功能同时不对原bean造成修改、无侵入性；对代理对对象的方法调用会转接给原始bean或者新加入的接口的实现类。@DeclareParents(value,defaultImple)中指明哪种bean要引进该接口以及该接口的实现类。

* Spring AOP 属于运行时增强，动态代理，而 AspectJ 是编译时增强，静态代理。 Spring AOP 基于代理 (Proxying)，而 AspectJ 基于字节码操作 (Bytecode Manipulation)。AspectJ 最完整的 AOP 框架了，可以实现方法、等段等拦截，spring AOP功能受限，但是 Spring AOP 相对来说更简单，如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比 Spring AOP 快很多。

#####  JDK动态代理

可以在运行期动态创建某个`interface`的实例。直接通过JDK提供的一个`Proxy.newProxyInstance()`创建了一个接口对象。1，定义一个InvocationHandler实例，它负责实现接口的方法调用；2，通过Proxy.newProxyInstance()创建interface实例，它需要3个参数：使用的ClassLoader，通常就是接口类的ClassLoader；需要实现的接口数组，至少需要传入一个接口进去；用来处理接口方法调用的InvocationHandler 实例。3，将返回的Object强制转型为接口。`JDK`动态代理执行代理方法时需要通过反射机制进行回调，此时方法执行的效率比较低；

```java
public class DynamicProxy {
    public static void main(String[] args) {
        // 普通学生类
        Student ordinaryStudents = new OrdinaryStudents();
        ordinaryStudents.write();

        /**
         *  InvocationHandler作用就是，当代理对象的原本方法被调用的时候，会重定向到一个方法，
         *  这个方法就是InvocationHandler里面定义的内容，同时会替代原本方法的结果返回。
         *  InvocationHandler接收三个参数：proxy，代理后的实例对象。 method，对象被调用方法。args，调用时的参数。
         */
        InvocationHandler handler = (proxy, method, handlerArgs) -> {
            // 从定义write方法。
            if ("write".equals(method.getName())) {
                System.out.println("增强型学生write()执行前);
                method.invoke(ordinaryStudents, handlerArgs);
                System.out.println("增强型学生write()执行后);
                return null;
            }
            return null;
        };
        /**
         *  对这个实例对象代理生成一个代理对象。
         *  被代理后生成的对象，是通过People接口的字节码增强方式创建的类而构造出来的。它是一个临时构造的实现类的对象。
         *  loader和interfaces基本就是决定了这个类到底是个怎么样的类。InvocationHandler决定了这个代理类到底是多了什么功能.
         *  通过这些接口和类加载器，拿到这个代理类class。然后通过反射的技术复制拿到代理类的构造函数，
         *  最后通过这个构造函数new个一对象出来，同时用InvocationHandler绑定这个对象。
         *  最终实现可以在运行的时候才切入改变类的方法，而不需要预先定义它。
         */
        Student sonOfDistrict = (Student) Proxy.newProxyInstance(ordinaryStudents.getClass().getClassLoader(), ordinaryStudents.getClass().getInterfaces(), handler);
        sonOfDistrict.write();
    }
}
/**
 * 学生接口
 */
interface Student {
    void write();
}
/**
 * 普通学生
 */
class OrdinaryStudents implements Student {
    @Override
    public void write() {
        System.out.println("我在写作文!);
    }
}
```

#####   CGLIB

SpringBoot 2.x 开始，为了解决使用 JDK 动态代理可能导致的类型转化异常而默认使用 CGLIB（接口A，实现类B，动态代理增强B中接口方法得到的代理类为A的实现类，和B同级不存在父子关系）。如果需要默认使用 JDK 动态代理可以通过配置项 spring.aop.proxy-target-class=false来进行修改。

`CGLib`生成代理类的方式是通过操作字节码，这种方式生成代理类的速度要比`JDK`通过反射生成代理类的速度更慢；`CGLib`生成的代理类，和我们自己编写并编译的类没有太大区别，对方法的调用和直接调用普通类的方式一致，所以`CGLib`执行代理方法的效率要高于`JDK`的动态代理；

```java
public class Dao {
    
    public void update() {
        System.out.println("PeopleDao.update());
    }
}

public class DaoProxy implements MethodInterceptor {
    @Override
    public Object intercept(Object object, Method method, Object[] objects, MethodProxy proxy) throws Throwable {
        //Object表示要进行增强的对象
        //Method表示拦截的方法
        //Object[]数组表示参数列表，基本数据类型需要传入其包装类型，如int-->Integer、long-Long、double-->Double
        //MethodProxy表示对方法的代理，invokeSuper方法表示对被代理对象方法的调用
        System.out.println("Before Method Invoke);
        proxy.invokeSuper(object, objects);
        System.out.println("After Method Invoke);
        
        return object;
    }
}

public class CglibTest {

    public void testCglib() {

        DaoProxy daoProxy = new DaoProxy();
        Enhancer enhancer = new Enhancer();
        // setSuperclass表示设置要代理的类
        enhancer.setSuperclass(Dao.class);
        // setCallback表示设置回调即MethodInterceptor的实现类
        enhancer.setCallback(daoProxy);
        // 使用create()方法生成一个代理对象
        Dao dao = (Dao)enhancer.create();
        dao.update();
        dao.select();
    }
    
}
```

##### spring优势

模块化、每个模块多种选择、开箱即用、无模板代码。

##### 事务传播

编程式事务：通过编程的方式实现事务管理，更为灵活，事务管理的范围。

声明式事务：通过声明的方式，在IoC配置中指定事务的边界和事务属性，方法、类上增加@Transactional注解，声明事务的隔离级别、传播机制。

事务的本质是代理，一个类中调用自己的事务方法由于不经过代理类，所有无法实现事务（隐式事务一条一提交）

* TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。默认

* TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。

* TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性）

* TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。

* TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。

* TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。

##### 事务隔离

* TransactionDefinition.ISOLATION_DEFAULT:  使用后端数据库默认的隔离级别，Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别.
* TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读
* TransactionDefinition.ISOLATION_READ_COMMITTED:   允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生
* TransactionDefinition.ISOLATION_REPEATABLE_READ:  对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
* TransactionDefinition.ISOLATION_SERIALIZABLE:   最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

##### MVC

* 流程：HTTP请求->被控制器DispatcherServlet捕获->根据根据请求的信息（方法类型，URL，请求头参数）找到处理器（Handler），最后以`HandlerExecutionChain` 对象的形式返回->提取`Request`中的模型数据，填充`Handler`入参，开始执行`Handler`（`Controller`)->返回一个ModelAndView给DispatcherServlet->逻辑视图名到真实视图对象的解析工作->View对象对ModelAndView中的模型数据进行视图渲染->HTML页面->将渲染结果返回给客户端。

  ![700](%E9%9D%A2%E7%BB%8F.assets/16b27eedc1634c3f_tplv-t2oaga2asx-zoom-in-crop-mark_1304_0_0_0.webp)

* @Controller，返回的是页面；@Controller加@ResponseBody，返回的是JSON、XML或其他文本。用@RestController，意味着这个Controller的所有方法不面都加了@ResponseBody，返回Json或者XML等文本，不会返回页面。

* RequestMap:Get\Post\Put\Delete，对请求根据url、请求参数、请求头中的connettype和accept类型匹配。

* @ResponseBody一般与@Controller组合使用，用来返回JSON字符串。@ResponseStatus一般与RestController组合使用，用来设置请求状态。@RequstBody一般用于修饰方法形参，读取 Request 请求的 body 部分（Json类型参数)数据构建对象作为实参传入方法。

##### 异常处理

前置处理（用于AOP自定义的拦截：before）->请求处理->后置处理（用于AOP自定义的拦截:after）。处理请求时抛出异常跳过后置处理，进入processDispatchResult，如果之前有抛出异常，再进processDispatchException。用户定义的的异常处理Bean会自动注册到ExceptionResolvers中，在processDispatchException中遍历handlerExceptionResolvers，进行异常处理。在exceptionResolver中如果该异常应该由当前resolver处理，则调用doResolveException->doResolverMethodException真正开始处理异常。

ExceptionHandler标注在Conroller的方法中用于处理本Controller抛出的异常；标注在RestControllerAdvice、ControllerAdvice的方法上可以处理全局controller抛出的异常。接手异常处理后方法后全权处理请求的返回，可以自行返回ModelAndView,Json等数据类型，也可以设置返回的状态码。

##### 拦截器

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220311224831946.png)

##### 成熟度模型

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220311225236150.png)

* 识别资源:找到资源（商品、订单）->资源集合（商品集合、订单集合)->复合资源(商品+订当)->处理函数（价格计算）

* 选择合适的资源粒度：网络效率（一次请求完成多个任务），易用性、缓存性（对数据不一致的容忍性）

*  设计 URI：( / ) 来表示资源之间的层次关系，使⽤用“与”符号 ( & ) 来分隔参数，避免出现⽂文件扩展名

*  选择合适的 HTTP ⽅方法和返回码：第二级成熟度

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220311230321385.png)

*  设计资源的表述（json/html）

##### 会话

粘性会话 Sticky Session：尽量让同一个用户的请求落到一台机器上。缺点：如果当前机器下线则用户的信息全部丢失

会话复制 Session Replication：将会话信息复制到所有机器上，无论用户请求落到哪台机器上都能取到之前的会话信息。缺点：复制需要成本，冗余过大，难以保证所有机器上会话信息一致。

集中会话 Centralized Session：JDBC、Redis等集中保存信息，机器需要信息时到JDBC,Redis中取。

##### Actuator

监控并管理理应⽤用程序；HTTP、JMX;endpoint(bean、condition、health、mappings、prometheus（如果添加prometheus 依赖并将监控数据导出到prometheus ，可在此看到所有数据)）。

##### jar

Jar 描述，META-INF/MANIFEST.MF；main-class:通过@SringApplication注解指定start-class,通过start-claa启动spring程序;

Spring Boot Loader，org/springframework/boot/

项⽬目内容，BOOT-INF/classes

项⽬目依赖，BOOT-INF/lib

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220312004421834.png)

##### spring boot优点

* 选择对应的starter（Maven项目对象模型，其他库的传递依赖），自动配置，对主流开发框架的无配置集成，开箱即用。
* 嵌入：Servlet容器，无需WAR包的形式部署到Tomcat，JAR包直接运行。
* 开发场景所需的依赖starter-xxx，下载jar包，版本兼容
* 健康检查和外部化配置，运维。
* 没有冗余代码生成和xml配置的要求

##### 自动装配

Spring Boot通过@EnableAutoConfiguration注解开启自动配置，起步依赖包含需要的第三方依赖，加载spring.factories中注册的各种AutoConfiguration类，当某个AutoConfiguration类满足其注解@Conditional指定的生效条件（Starters提供的依赖、配置或Spring容器中是否存在某个Bean等）时，实例化该AutoConfiguration类中定义的Bean（组件等），并注入Spring容器，就可以完成依赖框架的自动配置。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220315173434349.png)

##### BeanFactory与FactoryBean

BeanFactory是一个接口，它是Spring中工厂的顶层规范，是SpringIoc容器的核心接口，它定义了`getBean()`、`containsBean()`等从Ioc容器管理Bean的通用方法。Spring的容器都是它的具体实现如：XmlBeanFactory、ApplicationContext。

FactoryBean接口，首先是一个Bean，但又不仅仅是一个Bean。它是一个能生产或修饰对象生成的工厂Bean，类似于设计模式中的工厂模式和装饰器模式。FactoryBean表现的是一个工厂的职责，即一个Bean A如果实现了FactoryBean接口，那么A就变成了一个工厂，根据该Bean的ID从BeanFactory中获取的实际上是FactoryBean的getObject()返回的对象，而不是FactoryBean本身，如果要获取FactoryBean对象，请在id前面加一个&符号来获取。FactoryBean为我们实例化Bean提供了一个更为灵活的方式，定制实例化Bean的逻辑，我们可以通过FactoryBean创建出更为复杂的Bean实例。在Spring中最为典型的一个应用就是用来创建AOP的代理对象，动态代理运行时创建的，很符合工厂方法模式。`FactoryBean`本质上还是一个Bean，实现了FactoryBean接口。

https://juejin.cn/post/6844903967600836621

##### Spring 框架中用的设计模式

https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485303&idx=1&sn=9e4626a1e3f001f9b0d84a6fa0cff04a&chksm=cea248bcf9d5c1aaf48b67cc52bac74eb29d6037848d6cf213b0e5466f2d1fda970db700ba41&token=255050878&lang=zh_CN#rd

* 工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。
* 代理设计模式 : Spring AOP 功能的实现；事务实现。
* 单例设计模式 : Spring 中的 Bean 默认都是单例的。对象只能有一个实例，如果制造出多个实例就可能会导致一些问题的产生，比如：程序的行为异常、资源使用过量、或者不一致性的结果。对于频繁使用的对象，可以省略创建对象所花费的时间，这对于那些重量级对象而言，是非常可观的一笔系统开销；由于 new 操作的次数减少，因而对系统内存的使用频率也会降低，这将减轻 GC 压力，缩短 GC 停顿时间。
* 包装器设计模式 :装饰者模式可以动态地给对象添加一些额外的属性或行为，相比于使用继承，装饰者模式更加灵活（$n<2^n-1$）。 需要新功能时设计一个Decorator套在原有代码外面实现在不修改原始代码的基础上实现扩展。我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。我们能根据客户的需求在少修改原有类的代码下动态切换不同的数据源。
* 适配器模式 :适配器模式(Adapter Pattern) 将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。spring MVC 中也是用到了适配器模式适配Controller，Spring MVC 中的 Controller 种类众多，不同类型的 Controller 通过不同的方法来对请求进行处理。如果不DispatcherServlet 直接获取对应类型的 Controller，需要的自行挨个遍历查找来判断，`DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`，之后由`HandlerAdapter` 适配器处理。`HandlerAdapter` 作为期望接口，具体的适配器实现类用于对`Controller` 作为需要适配的类进行适配。

##### 设计模式原则

- 开闭原则：软件应该对扩展开放，而对修改关闭。这里的意思是在增加新功能的时候，能不改代码就尽量不要改，如果只增加代码就完成了新功能，那是最好的，易于扩展复用、封装实现细节、降低耦合度。

  为系统定义一个相对稳定的抽象层，而将不同的实现行为移至具体的实现层中完成。如果需要修改系统的行为，无须对抽象层进行任何改动，只需要增加新的具体类来实现新的业务功能即可(AQS)。

- 里氏替换原则：即如果我们调用一个父类的方法可以成功，那么替换成子类调用也应该完全可以运行。所有基类出现的地方，都可以使用子类进行替换，子类可以扩展父类的功能，但不能改变父类原有的功能。

  尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型，用子类对象来替换父类对象。

- 依赖倒置原则：要依赖于抽象，不要依赖于实现。应当使用接口和抽象类进行变量类型声明、参数类型声明、方法返还类型说明，以及数据类型的转换等。

  上层包含最重要的宏观商务逻辑，是较为稳定。具体层次含有的是一些次要的与实现有关的算法和逻辑，以及战术性的决定，带有相当大的偶然性选择。

- 单一职责原则：一个类只负责一项职责。针对一个类，其承担的职责越多，就意味着这些职责耦合在了一起，若其中一项职责发生变化，就可能会影响其他职责的处理，被复用的可能性就越小，因此要将这些职责进行分离。

- 接口隔离原则：当一个接口太大时，我们需要将它分割成一些更细小的接口，接口中的方法要尽量的少，接口功能要尽量的细分。为了使接口的职责单一，需要将大接口中的方法根据其职责不同分别放在不同的小接口中，以确保每个接口使用起来都较为方便，并都承担某一单一角色。

- 迪米特法则：一个类对自己所依赖的类知道的越少越好，对外通过public(protected可以通过子类访问)方法进行提供服务，否则不对外泄露任何信息，这也体现了数据保密性。

- 组合/聚合复用原则：尽量使用对象的组合/聚合，而不是继承来达到复用的目的。

  聚合（Has a)表示整体与部分的关系，表示“含有”，整体由部分组合而成。新对象通过委派调用已有对象的方法达到复用功能的目的，使得成员对象的内部实现细节对于新对象不可见，所以这种复用又称为“黑箱”复用，相对继承关系而言，其耦合度相对较低，成员对象的变化对新对象的影响不大。

  继承(Is a)使得基类与子类有较强的耦合性，基类的内部细节对子类来说是可见的，这样基类的实现细节会暴露给子类，称为“白箱”复用，破坏了系统的封装性。如果基类发生改变，那么子类的实现也不得不发生改变；

##### 工厂模式

简单工厂模式：定义一个工厂类，根据传入的参数不同返回不同的实例，被创建的实例具有共同的父类或接口。由于工厂类封装了对象的创建过程，所以客户端应该不关心对象的创建。适用于需要创建的对象较少；客户端不关心对象的创建过程。

```java
public interface Reader {
    void read();
}
public class JpgReader implements Reader {
    @Override
    public void read() {
        System.out.print("read jpg);
    }
}
public class PngReader implements Reader {
    @Override
    public void read() {
        System.out.print("read png);
    }
}
 public class Factory {
     public static Reader getReader(String type) {
         if (type.equalsIgnoreCase("jpg)) {
             return new JpgReader();
         } else if (type.equalsIgnoreCase("png)) {
             return new PngReader();
         } 
     }
}
```

工厂方法模式：不再提供一个统一的工厂类来创建所有的对象，而是针对不同的对象提供不同的工厂，每个对象都有一个与之对应的工厂，将生产任务交给不同的派生类工厂，这样不用通过指定类型来创建对象了。让子类工厂决定将哪一个类实例化，让一个类的实例化延迟到其子类。客户端不需要知道它所创建的对象的类，不需要知道每个产品具体叫什么名，只知道创建它的工厂名就完成了创建过程。使得创建对象和使用对象是分离的，并且客户端总是引用抽象工厂和抽象产品，以便工厂方法能随时切换不同的子类返回，却不影响调用方代码。

```java
public interface ReaderFactory {
    Reader getReader();
}
public class JpgReaderFactory implements ReaderFactory {
    @Override
    public Reader getReader() {
        return new JpgReader();
    }
}
public class PngReaderFactory implements ReaderFactory {
    @Override
    public Reader getReader() {
        return new PngReader();
    }
}

Factory factory=new JpgReaderFactory();
Reader  reader=factory.getReader();
reader.read();

Factory factory=new PngReaderFactory();
Reader  reader=factory.getReader();
reader.read();
```

抽象工厂模式：工厂是抽象的，产品是抽象的。这个抽象工厂会对应到多个实际工厂，每个实际工厂负责创建多个实际产品。AbstractFactory（抽象工厂）声明了一组用于创建不同产品的方法。ConcreteFactory（具体工厂）：它实现了在抽象工厂中声明的创建对象的方法，生成一组具体对象。AbstractProduct（抽象产品）：它为每种对象声明接口，在其中声明了对象所具有的业务方法。ConcreteProduct（具体产品）：它定义具体工厂生产的具体对象。

抽象工厂模式是为了让创建工厂和一组产品与使用相分离，并可以随时切换到另一个工厂以及另一组产品；抽象工厂模式实现的关键点是定义工厂接口和产品接口，但如何实现工厂与产品本身需要留给具体的子类实现，客户端只和抽象工厂与抽象产品打交道。

```java
// 抽象工厂
public interface AbstractFactory {
    // 创建Html文档:
    HtmlDocument createHtml(String md);
    // 创建Word文档:
    WordDocument createWord(String md);
}

// 抽象产品
public interface HtmlDocument {
    void save(Path path) throws IOException;
}
public interface WordDocument {
    void save(Path path) throws IOException;
}

// 实际产品
public class FastHtmlDocument implements HtmlDocument {
    public void save(Path path) throws IOException {}
}

public class FastWordDocument implements WordDocument {
    public void save(Path path) throws IOException {}
}
// 实际工厂
public class FastFactory implements AbstractFactory {
    public HtmlDocument createHtml(String md) {
        return new FastHtmlDocument(md);
    }
    public WordDocument createWord(String md) {
        return new FastWordDocument(md);
    }
}

// 实际产品:
public class GoodHtmlDocument implements HtmlDocument {
    public void save(Path path) throws IOException {}
}
public class GoodWordDocument implements HtmlDocument {
    public void save(Path path) throws IOException {}
}

// 实际工厂:
public class GoodFactory implements AbstractFactory {
    public HtmlDocument createHtml(String md) {
        return new GoodHtmlDocument(md);
    }
    public WordDocument createWord(String md) {
        return new GoodWordDocument(md);
    }
}

//使用
// 创建AbstractFactory，实际类型是FastFactory:
AbstractFactory factory = new FastFactory();
// 生成Html文档:
HtmlDocument html = factory.createHtml("#Hello\nHello, world!);
html.save(Paths.get(".", "fast.html));
// 生成Word文档:
WordDocument word = factory.createWord("#Hello\nHello, world!);
word.save(Paths.get(".", "fast.doc));
```

##### 装饰器模式

动态地给一个对象添加一些额外的职责。就增加功能来说，相比生成子类更为灵活。n个功能共产生$C_n^1+C_n^2+...+C_n^n$种组合，需要$2^n-1$个类实现。Decorator模式的目的就是把一个一个的附加功能，用Decorator的方式给一层一层地累加到原始数据源上，最终通过组合获得我们想要的功能。

把核心功能和附加功能给分开了。如果我们要新增核心功能，就增加Component的子类。如果我们要增加附加功能，就增加Decorator的子类。两部分都可以独立地扩展，而具体如何附加功能，由调用方自由组合，从而极大地增强了灵活性。

装饰器模式不是要改变被装饰对象的接口，而是恰恰要保持原有的接口，但是增强原有对象的功能，或者改变原有对象的处理方式而提升性能。

```java
// 创建原始的数据源: 核心功能
InputStream fis = new FileInputStream("test.gz);
// 增加缓冲功能:第一层装饰
InputStream bis = new BufferedInputStream(fis);
// 增加解压缩功能:第二层装饰
InputStream gis = new GZIPInputStream(bis);
```

##### 单列模式

保证一个类仅有一个实例，并提供一个访问它的全局访问点。单例的构造方法必须是`private`，这样就防止了调用方自己创建实例，但是在类的内部，是可以用一个静态字段来引用唯一创建的实例的，供一个静态方法，直接返回实例。

```java
public class Singleton {
    // 静态字段引用唯一实例:
    private static final Singleton INSTANCE = new Singleton();
    // 通过静态方法返回实例:
    public static Singleton getInstance() {
        return INSTANCE;
    }
    // private构造方法保证外部无法实例化:
    private Singleton() {
    }
}
```

延迟加载：即在调用方第一次调用`getInstance()`时才初始化全局唯一实例，在多线程中是错误的，在竞争条件下同时发现实例为空，会创建出多个实例。必须对整个方法进行加锁：`public synchronized static Singleton getInstance() `，但加锁会严重影响并发性能。

双重检查:如果多个线程同时了通过了第一次检查，并且其中一个线程首先通过了第二次检查并实例化了对象，那么剩余通过了第一次检查的线程就不会再去实例化对象。除了初始化的时候会出现加锁的情况，后续的所有调用都会避免加锁而直接返回，解决了性能消耗的问题。

```java
public static Singleton getInstance() {
    if (INSTANCE == null) {
        synchronized (Singleton.class) {
            if (INSTANCE == null) {
                INSTANCE = new Singleton();
            }
        }
    }
    return INSTANCE;
}

// 优化
public class Singleton {
    // 静态字段引用唯一实例:
    private static volatile  Singleton INSTANCE ;
    // 通过静态方法返回实例:
    public static Singleton getInstance() {
        if (INSTANCE == null) {
            synchronized (Singleton.class) {
                if (INSTANCE == null) {
                    // volatile 保证了此行代码不会被重排序，从而保证可以返回一个完整初始化的对象
                    INSTANCE = new Singleton();
                }
            }
        }
        return INSTANCE;
    }
    // private构造方法保证外部无法实例化:
    private Singleton() {
    }
}

```

`INSTANCE = new Singleton();`分配内存空间->初始化对象->将对象指向刚分配的内存空间。但编译器为了性能的原因，可能会将第二步和第三步进行重排序：分配内存空间->将对象指向刚分配的内存空间->初始化对象。当进行完第二步后，另一个线程尝试获取对象现象对象非空，然后获取返回，此时对象还未完成初始化，导致后续产生错误。为此需要在`INSTANCE`前加入关键字`volatile`，重排序被禁止，所有的写（write）操作都将发生在读（read）操作之前。

```java
// 优化
public class Singleton {
    // 不存在静态变量，始化过程就会顺利完成。
    
    // 通过静态方法返回实例:
    public static Singleton getInstance() {
        return Holder.INSTANCE;
    }
    // private构造方法保证外部无法实例化:
    private Singleton() {
    }
    // 定义在类里面的静态类holder直到JVM确定holder一定会被执行时才会去初始化。当静态方法getInstance调用时，静态类LazyHolder才会被执行
    private static class Holder{
        private static final Singleton INSTANCE=new Singleton();
    }
}
```

如果没有特殊的需求，使用Singleton模式的时候，最好不要延迟加载，这样会使代码更简单。

对于Web程序大部分服务类都应该被视作Singleton，如果全部按Singleton的写法写，会非常麻烦，所以，通常是通过约定让框架（例如Spring）来实例化这些类，保证只有一个实例，调用方自觉通过框架获取实例而不是`new`操作符。

##### 模板模式

定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。定义一个操作中的算法的骨架，对于某些暂时确定不下来的步骤，就留给子类去实现好了，这样不同的子类就可以定义出不同的步骤，使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤，同时公用顶层部分。

扩展性好，对不变的代码进行封装，对可变的进行扩展；可维护性好，因为将公共代码进行了提取，使用的时候直接调用即可；

为了防止子类重写父类的骨架方法，可以在父类中对骨架方法使用`final`。对于需要子类实现的抽象方法，一般声明为`protected`，使得这些方法对外部客户端不可见。Java标准库也有很多模板方法的应用，`AbstractQueuedSynchronizer`都定义了很多通用操作，子类只需要实现某些必要方法。

##### 观察者模式

定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。观察者模式（Observer）又称发布-订阅模式（Publish-Subscribe：Pub/Sub）。它是一种通知机制，让发送通知的一方（被观察方）和接收通知的一方（观察者）能彼此分离，互不影响。

通知者不能直接引用被通知者，不然耦合度太高，新加被通知者就要修改通知者代码。它引用一个`Observer`接口对象的集合，任何想要得到通知的对象，只要实现该接口，并且把自己注册到通知者即可，每当要发通知时，通知者遍历集合给被通知者发送消息。

广义的观察者模式包括所有消息系统。所谓消息系统，就是把观察者和被观察者完全分离，通过消息系统本身来通知：消息发送方称为Producer，消息接收方称为Consumer，Producer发送消息的时候，必须选择发送到哪个Topic。Consumer可以订阅自己感兴趣的Topic，从而只获得特定类型的消息。

![700](%E9%9D%A2%E7%BB%8F.assets/v2-b6ed65f370a766620718ad4227d5d4e5_r.jpg)

异步通知：使得所有观察者可以并发同时处理。多线程方式，对每个观察者开一个线程发送通知，缺点开销大，使用线程池，重用线程，限制线程数，使用集合保存submit（）返回的Future对象，然后遍历该集合,使用带超时参数的get，如果超时还未成功返回，直接取消执行，防止卡死。

##### 适配置模式

将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。Adapter的步骤如下：实现目标接口A；内部持有一个待转换接口B的引用；在目标接口A的实现方法内部，调用待转换接口B的方法。适配器模式的意义是要将一个接口转变成另一个接口，它的目的是通过改变接口来达到重复使用的目的。 

```java
public BAdapter implements B {
    private A a;
    public BAdapter(A a) {
        this.a = a;
    }
    public void b() {
        a.a();
    }
}
```

FutureTask 

```java
public class FutureTask<V> implements RunnableFuture<V> {
	private Callable<V> callable;
    public FutureTask(Callable<V> callable) {
        this.callable = callable;
    }
    public void run() {
        try {
            Callable<V> c = callable;
            V result;
            boolean ran;
            try {
                result = c.call();
                ran = true;
            } catch (Throwable ex) {
                result = null;
                ran = false;
                setException(ex);
            }
            if (ran)
                set(result);
        } finally {
        }
    }
}
```

用一个代理来隐藏具体实现类的实现细节，通常还用于在真实的实现的前后添加一部分逻辑。适配器模式做的就是，有一个接口需要实现，但是我们现成的对象都不满足，需要加一层适配器来进行适配。比较这两种模式，其实是比较对象适配器模式和代理模式，在代码结构上，它们很相似，都需要一个具体的实现类的实例。装饰器模式往往就是**添加小功能**这种，代理模式就可以实现功能的增强，但是代理不容易实现多个功能的增强，使用代理包装代理的方式，但是那样的话代码就复杂了。

##### 代理模式

为其他对象提供一种代理以控制对这个对象的访问。在代理类中实现权限检查等额外功能。对被代理类无改变，职责清晰：一个类只负责一件事；易于测试：一次只测一个功能。

```java
public AProxy implements A {
    private A a;
    public AProxy(A a) {
        this.a = a;
    }
    public void a() {
        doSomethingBrfore();
        this.a.a();
        doSomethingAfter();
    }
}
```

虚代理：Virtual Proxy：它让调用者先持有一个代理对象，但真正的对象尚未创建。如果没有必要，这个真正的对象是不会被创建的，直到客户端需要真的必须调用时，才创建真正的对象。JDBC的连接池返回的JDBC连接（Connection对象）就可以是一个虚代理，即获取连接时根本没有任何实际的数据库连接，直到第一次执行JDBC查询或更新操作时，才真正创建实际的JDBC连接。

保护代理：Protection Proxy，它用代理对象控制对原始对象的访问，常用于鉴权。

智能引用：Smart Reference，它也是一种代理对象，如果有很多客户端对它进行访问，通过内部的计数器可以在外部调用者都不使用后自动释放它。

装饰器模式关注于在一个对象上动态地添加方法，而代理模式关注于控制对对象的访问。装饰器模式强调的是增强自身，在被装饰之后你能够在被增强的类上使用增强后的功能，增强后你还是你，只不过能力更强了而已；代理模式目的是控制对真实对象的访问吧，强调要让别人帮你去做一些本身与你业务没有太多关系的职责（记录日志、设置缓存）。

##### 策略模式

针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换，替换if else 语句写法，并且可以随时相互替换。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221027174547483.png)

- 环境角色(Context)：根据特定的任务，持有一个具体策略类的引用，提供给客户端使用。
- 抽象策略角色(Strategy)：这是一个抽象角色，通常由一个接口或抽象类实现。作为环境角色的字段，保存具体的策略。
- 具体策略角色(ConcreteStrategy)：包装了相关的算法或行为。

扩展性好，可以在不修改对象结构的情况下，为新的算法进行添加新的类进行实现；灵活性好，可以对算法进行自由切换；如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为；



##### 事件

* 上下文更新事件（ContextRefreshedEvent）：在调用 ConfigurableApplicationContext 接口中的 refresh() 方法时被触发。
* 上下文开始事件（ContextStartedEvent）：当容器调用 ConfigurableApplicationContext 的 Start() 方法开始 / 重新开始容器时触发该事件。
* 上下文停止事件（ContextStoppedEvent）：当容器调用 ConfigurableApplicationContext 的 Stop() 方法停止容器时触发该事件。
* 上下文关闭事件（ContextClosedEvent）：当 ApplicationContext 被关闭时触发该事件。容器被关闭时，其管理的所有单例 Bean 都被销毁。
* 请求处理事件（RequestHandledEvent）：在 Web 应用中，当一个 http 请求（request）结束触发该事件。如果一个 bean 实现了 ApplicationListener 接口，当一个 ApplicationEvent 被发布以后，bean 会自动被通知。

##### AOP实现

https://www.jianshu.com/p/eea9a3acbaad

1，AspectJAwareAdvisorAutoProxyCreator：postProcessBeforeInstantiation：主要是处理使用了@Aspect注解的切面类，然后将切面类的所有切面方法根据使用的注解生成对应Advice，并将Advice连同切入点匹配器和切面类等信息一并封装到Advisor。

2，AspectJAwareAdvisorAutoProxyCreator：postProcessAfterInitialization：主要负责将Advisor注入到合适的位置，创建代理（cglib或jdk)，为后面给代理进行增强实现做准备。

如果bean被子类标识为代理，则获取所有切面类的切面方法生成Advisor，通过切点匹配找到这些Advisor中能够应用于beanClass的Advisor，使用配置的拦截器创建一个代理。

cglib方式：增强逻辑（MethodInceptor）+被代理类+被拦截的方法拦截器共同构建被代理类。

jdk动态代理方式：接口+增强逻辑（InvocationHandler）+类加载器共同构建被代理类。



生成时：cglib 需要构建字节码，还会额外生成一个fastclass文件，该文件记录各个method的class索引，较慢；jdk代理基于反射调用，原来的接口上修改，拼接，较快。运行时：jdk带来基于反射较慢，cglib通过fastclass索引机制，后者实现执行效率更高。随着版本更迭动态代理的性能得到了显著的提升。

A结构的实现类B，现在对B的接口方法增强。`A a`无论cglib还是jdk都正常；`B b`由于jdk基于接口实现，返回的时A的实现类，无法赋值给B，而cglib返回B的子类，子类对象赋值给父类应用，正常。



##### Spring事务AOP实现

https://juejin.cn/post/7030789599110627365

spring事务其实就是根据事务注解生成代理类，然后在前置增强方法里获取connection，设置`connection`到`threadlocal`，开启事务。再执行原始方法，最后在后置增强方法中判断有无异常来进行事务回滚或提交，再释放连接。

–>定义切面拦截有Transactional注解的方法，并对切点进行@Around增强，构建该类的增强器。

–>定义类实现了`BeanPostProcessor`接口，在它的`postProcessAfterInitialization`方法，先获取BeanFactory中所有对应Advisor.class的类名，获得所有增强器实例，然后根据匹配原则判断当前bean的所有方法中是否存在一个方法，能匹配某个增强器Pointcut中的规则，遍历当前bean的全部方法和所有增强器获得匹配当前 Bean 的所有增强器，创建代理类并返回用于替代原始类。
		–>代理对象的事务拦截处理在 TransactionInterceptor 拦截器中，实现了 MethodInterceptor 方法拦截器。根据事务传播级别决定受否创建一个事务并返回 TransactionInfo 事务信息对象（包含一个 DefaultTransactionStatus 事务状态对象），将TransactionInfo 绑定在 ThreadLocal 中继续执行方法调用器（执行方法）如果捕获到指定的异常，则在这里完成事务，进行回滚否则提交。

##### Interceptor

https://www.jianshu.com/p/61eae2ad7320

https://segmentfault.com/a/1190000024464165

https://www.cnblogs.com/itlihao/p/14329905.html

SpringMVC中的Interceptor拦截器用于拦截Controller层接口，表现形式有点像Spring的AOP，但是AOP是针对单一的方法。Interceptor是针对Controller接口以及可以处理request和response对象。通过配置指定拦截器要拦截的请求路径。

preHandle:在访问到达Controller之前执行。postHandle:在执行完Controller方法之后,渲染视图之前执行。afterCompletion:调用完Controller接口，渲染View页面后调用。

每次请求都会先经过DispatcherServlet这个入口的处理才能到达目标资源。遍历所有的拦截器, 把所有匹配当前请求的所有拦截添加到拦截器队列。preHandle->Controller->postHandle->processDispatchResult->afterCompletion。

当多个拦截器同时工作时，它们的preHandle()方法会按照配置文件中拦截器的配置顺序执行，而它们的postHandle()方法和afterCompletion()方法则会按照配置顺序的反序执行。责任链模型。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221008193957428.png)

##### 过滤器、拦截器、AOP

https://www.cnblogs.com/itlihao/p/14329905.html

https://www.jianshu.com/p/e6080716405f

* 过滤器过滤的对象是客户端访问的web资源。Filter是依赖于Servlet的，需要有Servlet的依赖。Filter可以拦截所有请求。包括静态资源。过滤器是在请求进入容器后，但请求进入servlet之前进行预处理的。过滤器是JavaEE标准，只需依赖servlet api ，不需要依赖spring，无法获取请求要访问的类与方法和参数。过滤器只在容器初始化时被调用一次。

  对传入的request提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者Controller进行业务逻辑操作。通常用的场景是：在过滤器中修改字符编码（CharacterEncodingFilter）、在过滤器中修改HttpServletRequest的一些参数，如：过敏感词等。

  ```java
  @Component
  @WebFilter(value = "/hello)
  public class HelloFilter2 implements Filter {
      public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse,
              FilterChain filterChain){}
  }
  ```

  

* 拦截器是依赖于SpringMVC的，需要有mvc的依赖。拦截器只能拦截action请求，不包括静态资源。因为拦截器是spring提供并管理的，拦截器可以获取IOC容器中的各个bean，在拦截器里注入一个service，可以调用业务逻辑。可以获取请求访问的类与方法 , 但是无法获取请求参数的值。基于Java的反射机制，属于面向切面编程（AOP）的一种运用。拦截器可以被多次调用。

  拦截器适合于日志等。
  
  ```java
  @Component
  public class InterceptorDemo implements HandlerInterceptor {
          @Override
      public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
          return true;
      }
      public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
          
      }
      public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
          
      }
  }
  
  @Bean
  WebMvcConfigurer createWebMvcConfigurer(@Autowired HandlerInterceptor[] interceptors) {
      return new WebMvcConfigurer() {
          public void addInterceptors(InterceptorRegistry registry) {
              for (var interceptor : interceptors) {
                  registry.addInterceptor(interceptor);
              }
          }
      };
  }
  ```
  
  
  
* AOP可以获取访问的类、方法以及参数值，对方法进行统一的处理。可以具体的拦截到方法，只能拦截Spring管理Bean的访问（业务层Service）。

  



![700](%E9%9D%A2%E7%BB%8F.assets/image-20221008201539599.png)

Filter的执行由Servlet容器回调完成，而拦截器通常通过动态代理（反射）的方式来执行。Filter的生命周期由Servlet容器管理，而拦截器则可以通过IoC容器来管理，因此可以通过注入等方式来获取其他Bean的实例，因此使用会更方便。在编写相对比较公用的代码时，优先考虑过滤器，然后是拦截器，最后是aop。



##### SpringBootApplication

`SpringBootApplication`是一个"三体"结构，重要的只有三个Annotation：

- `@Configuration`：标注当前类是配置类， 并会将当前类内声明的一个或多个以@Bean注解标记的方法的实例纳入到spring容器中。
- `@EnableAutoConfiguration`：将所有符合条件的@configuration都加载到当前的SpringBoot创建并使用的Ioc容器。
- `@ComponentScan`：自动扫描并加载符合条件的组件或bean定义，最终将这些bean定义加载到容器中。默认从声明@ComponentScan所在类的package进行扫描。

##### 自定义starter

https://developer.aliyun.com/article/855869

https://juejin.cn/post/6979845038347927583#heading-11

* 命名遵循的格式为 spring-boot-starter-{name}
* pom导入依赖
* 定义配置文件类，定义自动条件配置类
* 配置 META-INF/spring.factories

##### Bean注解

https://www.shouxicto.com/article/2076.html

##### 扫码登录

https://www.cnblogs.com/huanshilang/p/12365376.html

* 首先用户打开网站的登录页面的时候，向浏览器的服务器发送获取登录二维码的请求。服务器收到请求后，随机生成一个uuid，将这个id作为key值存入redis服务器，同时设置一个过期时间，过期后用户登录二维码需要进行刷新重新获取。
* 将这个uuid值生成一个二维码的图片返回给用户浏览器。
* 浏览器拿到二维码和uuid后，会每隔一秒向服务器发送一次请求，根据redis中key是否存在合法value来判断登录是否成功的请求。如果不存在key则说明二维码已过期，需要重新获取。
* 用户拿出手机扫描二维码，就可以得到一uuid。由于手机端已经进行过了登录，存在用户的token，手机端将解析到的uuid和用户token一起作为参数，向服务器发送验证登录请求。
* 服务器拿到uuId和根据token得到的userId后，将用户的userid作为value值存入redis中以uuid作为key的键值对中。
* 浏览器再次发送请求的时候，根据redis中uuid获得用户Id，并调用登录的方法声成一个浏览器端的token，将用户信息返回给浏览器，登录成功。

![700](%E9%9D%A2%E7%BB%8F.assets/1643577-20200226094531549-13062519.png)

##### 性能优化

https://juejin.cn/post/7062548565800779789

https://developer.aliyun.com/article/2599

1，监控：actuator、Prometheus暴露数据(bean、condition、health、mappings、GC、内存、磁盘、CPU)，自定义统计数据如缓冲命中率，定义健康检查判断运行状态。AlertManager告警、Grafana可视化。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221020120728523.png)

2，火焰图：纵向表示的是调用栈的深度；横向表明的是消耗的时间。格子的宽度越大，越说明它可能是一个瓶颈。Skywalking是使用探针技术，查找响应比较慢QPS又比较高的的接口，进行专项优化。

3，比较大的文件，尽量使用CDN；HTTP头`Cache-Control`使用浏览器缓存；资源进行压缩；使用keepalive；

4，Controller层：json大结果集不仅会影响解析时间，还会造成内存浪费，或者返回对象的嵌套层次太深、引用了不该引用的对象（比如非常大的byte[]对象），造成了内存使用的飙升。

5，service层：涉及多个组件，分布式事务性能差，CA->BASE柔性事务，完成最终一致性。缓存减少数据库压力。微服务横向扩容。异步，并行。

6，Dao层：在JPA中，如果加了一对多或者多对多的映射关系，而又没有开启懒加载，级联查询的时候就容易造成深层次的检索，造成了内存开销大、执行缓慢的后果。分库分表后涉及多表查询汇总性能差。建索引；建联合索引。

##### spring 启动

https://juejin.cn/post/7035910505810100255

0，由启动主类调用main()方法开始。

1，初始化`SpringApplication`：配置基本的环境变量、构造器、监听器，为运行`SpringApplication`实例对象启动环境变量准备。

* 根据classpath里面是否存在某个特征类：NONE、SERVLET、REACTIVE。

* 从`spring.factories`文件中找出Key为`ApplicationContextInitiallizer`的类并实例化，然后调用设置到`SpringApplication`的`initiallizer`属性中，找到它所有应用的初始化器。接着设置应用监听器，这个过程可以找到所有应用程序的监听器。

2，run()方法运行`SpringApplication`：启动流程监控模块、配置环境加载模块、上下文环境加载模块，自动化配置模块加载。

* 加载`META-INF/spring.factories`文件的配置，实现自动配置核心功能。

![image-20221020164537496](%E9%9D%A2%E7%BB%8F.assets/image-20221020164537496.png)

##### 创建Bean 

https://www.jianshu.com/p/a1bcbbf4c5dc

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221027105921547.png)

`new ApplicationContext`初始化容器id, name, 状态 以及资源解析器，加载XML配置方式里的Bean定义的资源，向IoC容器注册解析的BeanDefinition。

容器扫描 BeanDefinitionRegistry 中的BeanDefinition；调用InstantiationStrategy 进行Bean实例化的工作；使用 BeanWrapper 完成Bean属性的设置工作；

单例Bean缓存池：Spring 在DefaultSingletonBeanRegistry类中提供了一个用于缓存单实例 Bean 的缓存器，它是一个用HashMap实现的缓存器，单实例的 Bean 以beanName为键保存在这个HashMap中。

1，流程

===>初始化 IoC 容器

```java
// beanName和实例化之后的对象。
private static final ConcurrentHashMap<String,Object> beanMap = new ConcurrentHashMap<>();
// 名称和对象对应的数据结构的映射
private static final ConcurrentHashMap<String,BeanDefinition> beanDefineMap= new ConcurrentHashMap<>();
```

===>读取xml配置文件，获得bean定义与依赖关系。

```json
  {
    "name": "mouth",
    "className": "org.example.entity.Mouth",
    "constructorArgs": [
      {
        "index": 1,
        "name": "name",
        "value": "hello"
      }
    ]
  }
```

===>将配置文件转换为容器识别对的数据结构 BeanDefinition，保存到beanDefineMap中。

```java
public class BeanDefinition {
    private String name;
    private String className;// 全类型名称，用户通过classloader获得Class对象
    private List<ConstructorArg> constructorArgs;// 构造函数的传参的列表 constructorArgs 
    private List<PropertyArg> propertyArgs;// 需要注入的参数列表propertyArgs
}
public class ConstructorArg {
    private int index;
    private String ref;
    private String name;
    private Object value;
}
public class PropertyArg {
    private String name;
    private String value;
    private String typeName;
}
```

===>利用数据结构依次实例化相应的对象，注入对象之间的依赖关系，放入缓存单实例 Bean 的缓存器

```java
public Object getBean(String name) throws Exception {
    //查找对象是否已经实例化过
    Object bean = beanMap.get(name);
    if(bean != null){
        return bean;
    }
    //如果没有实例化，那就需要调用createBean来创建对象
    bean =  createBean(beanDefineMap.get(name));
    if(bean != null) {
        //对象创建成功以后，注入对象需要的参数
        populatebean(bean);
        //再把对象存入Map中方便下次使用。
        beanMap.put(name,bean);
    }
    //结束返回
    return bean;
}
private Object createBean(BeanDefinition beanDefinition) throws Exception {
    // 获得bean定义
    String beanName = beanDefinition.getClassName();
    // 根据全限定类名加载类
    Class clz = ClassUtils.loadClass(beanName);
    if(clz == null) {
        throw new Exception("can not find bean by beanName);
    }
    List<ConstructorArg> constructorArgs = beanDefinition.getConstructorArgs();
    // 通过反射+构造方法实例化对象
    if(constructorArgs != null && !constructorArgs.isEmpty()){
        List<Object> objects = new ArrayList<>();
        for (ConstructorArg constructorArg : constructorArgs) {
            // 参数为基本类型直接获取值
            if (constructorArg.getValue() != null) {
                objects.add(constructorArg.getValue());
            // 参数为其它bean，去容器中获取
            } else {
                objects.add(getBean(constructorArg.getRef()));
            }
        }
        // cglib通过有参数构造方法构造对象
        return BeanUtils.instanceByCglib(clz,clz.getConstructor(),objects.toArray());
    }else {
        // cglib通过无参数构造方法构造对象
        return BeanUtils.instanceByCglib(clz,null,null);
    }
}

private void populatebean(Object bean) throws Exception {
    // 获得bean字段
    Field[] fields = bean.getClass().getSuperclass().getDeclaredFields();
    // 根据属性名称从容器中获得对应的bean，再通过反射注入
    if (fields != null && fields.length > 0) {
        for (Field field : fields) {
            String beanName = field.getName();
            beanName = StringUtils.uncapitalize(beanName);
            if (beanNameSet.contains(field.getName())) {
                // 根据属性名称从容器中获得对应的bean
                Object fieldBean = getBean(beanName);
                if (fieldBean != null) {
                    // 通过反射注入
                    ReflectionUtils.injectField(field,bean,fieldBean);
                }
            }
        }
    }
}
```

```java
////////////////////////////////////////////////////////////
public class ClassUtils {
    public static ClassLoader getDefultClassLoader(){
        return Thread.currentThread().getContextClassLoader();
    }
    // 根据全限定类名完成类加载
    public static Class loadClass(String className){
        try {
            return getDefultClassLoader().loadClass(className);
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        }
        return null;
    }
}
////////////////////////////////////////////////////////////
public class BeanUtils {
    // cglib通过构造方法构造对象
    public static <T> T instanceByCglib(Class<T> clz,Constructor ctr,Object[] args) {
        Enhancer enhancer = new Enhancer();
        enhancer.setSuperclass(clz);
        enhancer.setCallback(NoOp.INSTANCE);
        if(ctr == null){
            return (T) enhancer.create();
        }else {
            return (T) enhancer.create(ctr.getParameterTypes(),args);
        }
    }

}
////////////////////////////////////////////////////////////
public class ReflectionUtils {
	// 通过反射注入字段值
    public static void injectField(Field field,Object obj,Object value) throws IllegalAccessException {
        if(field != null) {
            field.setAccessible(true);
            field.set(obj, value);
        }
    }
}

```

##### 定时任务

https://juejin.cn/post/6844903924936212494

* `@EnableScheduling`启用定时任务，`@Scheduled`定义任务，支持fixedDelay、fixedRate、cron表达式。

* BeanPostProcessor的后置方法中查找被Scheduled注解标注的类，封装Runnable接口的对象初始化任务放入tasks。
* 底层依赖于`ScheduledThreadPoolExecutor`实现，使用优先队列作为延迟队列，且容量为无限，按照任务的下一次执行实践决定优先级，优先队列使用柱塞获取，如果队列为空则在condition上等待，如果任务时间未到则在condition上等待固定时间。获取任务执行后计算下一次执行时间，返回队列，并唤醒condition上等待线程。

### Redis

性能优秀，数据在内存中，读写速度非常快。单进程单线程，是线程安全的。丰富的数据类型，支持字符串 (strings)、散列(hashes)、列表(lists)、集合(sets)、有序集合(sorted sets) 等。支持数据持久化,可以将内存中数据保存在磁盘中，重启时加载。主从复制，哨兵，高可用。

Redis 是使用了一个「哈希表」保存所有键值对，哈希桶存放的是指向键值对数据的指针（dictEntry*）， key 指向的是 String 对象。

void * key 和 void * value 指针指向的是 Redis 对象。Redis 中的每个对象都由 redisObject 结构表示：type，标识该对象是什么类型的对象（String 对象、 List 对象、Hash 对象、Set 对象和 Zset 对象）；encoding，标识该对象使用了哪种底层的数据结构；ptr，指向底层数据结构的指针。

![700](%E9%9D%A2%E7%BB%8F.assets/58d3987af2af868dca965193fb27c464.png)

##### 数据类型

* String 数据结构是简单的 key-value 类型，value 其实不仅可以是 String，可以包含任何数据，比如 数字、jpg 图片或者序列化的对象。

  redis使用简单动态字符串（simple dynamic string，SDS） 的数据结构来表示字符串。 O（1)复杂度获取字符串长度的时候；有个专门的 len 成员变量来记录长度，`buf[]`字符数组，用来保存实际数据，所以可存储包含 “\0” 的数据，可以保存任意格式的二进制数据；通过 `alloc - len` 计算出剩余的空间大小，可以用来判断空间是否满足修改需求，避免缓冲区溢出；flags 成员变量指明数据类型，保存不同大小的字符串时选择不同类型，从而数据结构中的 len 和 alloc 成员变量的数据类型不同，字符越短len 和 alloc数据类型范围越小(uint32_t->uint16_t)，结构头占用空间也比较少，从而有效节省内存空间。

  ![700](%E9%9D%A2%E7%BB%8F.assets/516738c4058cdf9109e40a7812ef4239.png)

  

* Hash 是一个 string 类型的 field 和 value 的映射表，Key仍然是设定的值，采用「链式哈希」来解决哈希冲突 ，value是一个Map，这个Map的key是成员的属性名，value是属性值 。特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。避免取出、保存完整对象的开销，同时避免了序列化、反序列化开销。

  扩容时使用两个哈希表，给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；将「哈希表 1 」的数据迁移到「哈希表 2」 中；迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备。如果「哈希表 1 」的数据量非常大，那么在迁移至「哈希表 2 」的时候，因为会涉及大量的数据拷贝。

  渐进式 rehash 给「哈希表 2」 分配空间；在 rehash 进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，Redis 除了会执行对应的操作之外，还会顺序将「哈希表 1 」中索引位置上的所有 key-value 迁移到「哈希表 2」 上；随着处理客户端发起的哈希表操作请求数量越多，最终在某个时间，会把「哈希表 1 」的所有 key-value 迁移到「哈希表 2」，从而完成 rehash 操作。渐进式 rehash 进行期间，哈希表元素的删除、查找、更新等操作都会在这两个哈希表进行，新增一个 key-value 时会被保存到「哈希表 2 」里面，而「哈希表 1」 则不再进行任何添加操作，这样保证了「哈希表 1 」的 key-value 数量只会减少。

  触发 rehash 操作的条件，主要有两个：当负载因子大于等于 1 ，并且 Redis 没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作；当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，强制进行 rehash 操作。

* Redis list 的实现为一个双向链表/压缩列表/quicklist/listpack。

  双向列表可以支持反向查找和遍历，O(1)复杂度获取长度和首尾节点，listNode 链表节使用 void* 指针保存节点值，可以指向各种类型数据。链表每个节点之间的内存都是不连续的，意味着无法很好利用 CPU 缓存；头信息、前后节点指针带来了部分额外的内存开销。

  ![700](%E9%9D%A2%E7%BB%8F.assets/cadf797496816eb343a19c2451437f1e.png)

  压缩列表的最大特点，就是它被设计成一种内存紧凑型的数据结构，占用一块连续的内存空间，不仅可以利用 CPU 缓存，而且会针对不同长度的数据，进行相应编码，这种方法可以有效地节省内存开销。头尾节点可以查询列表头轻松获得，查找其他元素时，由于每个节点大小各异，只能逐个查找，此时的复杂度就是 O(N) 了，因此压缩列表不适合保存过多的元素。新增或修改某个元素时，压缩列表占用的内存空间需要重新分配，节点中使用字段prevlen记录了「前一个节点」的长度，同时会根据数据的大小，prevlen使用不同空间大小，当新插入的元素较大时，可能会导致后续元素的 prevlen 占用空间都发生变化，从而引起「连锁更新」问题，导致每个元素的空间都要重新分配，造成访问压缩列表性能的下降。

  ![700](%E9%9D%A2%E7%BB%8F.assets/a3b1f6235cf0587115b21312fe60289c.png)

  quicklist 就是「双向链表 + 压缩列表」组合，因为一个 quicklist 就是一个链表，而链表中的每个元素又是一个压缩列表。通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。

  ![700](%E9%9D%A2%E7%BB%8F.assets/f46cbe347f65ded522f1cc3fd8dba549.png)

  listpack：quicklist 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患。

  ![700](%E9%9D%A2%E7%BB%8F.assets/c5fb0a602d4caaca37ff0357f05b0abf.png)

* set 元素是没有顺序的，通过 HashMap 实现的，只是 value永远为null，通过计算key的hash的方式来快速去重。

* sorted set 和 set 相比，增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列。内部使用 HashMap 和跳跃表/压缩列表（但元素个数较少时使用压缩列表，较多时使用调表） 来保证数据的存储和有序，跳跃表/压缩列表按score从小到大保存所有集合元素。而字典则保存着从member到score的映射。

  插入元素时产生一个随机数k，就把这个结点添加到第一级到第K级这K级索引中。

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220914102734926.png)

  选择调表+哈希表：在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。在skiplist上只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。平衡树的插入和删除操作可能引发子树的调整，而skiplist的插入和删除只需要修改相邻节点，skiplist的操作显然更加局部性一些，锁需要盯住的节点更少。跳表比平衡树要简单得多，内存占用上更少。
  
  跳表是在链表基础上改进过来的，实现了一种「多层」的有序链表，有序+多层索引，跳表的优势是能支持平均 O(logN) 复杂度的节点查找。跳表的相邻两层的节点数量最理想的比例是 2:1(k=2)，查找复杂度O(log_k(N)+K)->O(logN)。如果采用新增节点或者删除节点时，来调整跳表节点以维持比例的方法的话，会带来额外的开销。
  
  场景：热榜，延时任务
  
  ![700](%E9%9D%A2%E7%BB%8F.assets/ce2f31795435746a1f609015b2e04737-16508964422011.png)
  
  

##### 有效期

Redis 中有个设置缓存时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。`redisTemplate.opsForValue().set(key, value, 20, TimeUnit.SECONDS);`

* 定期删除：redis 默认是每隔 100ms 就随机抽取(降低遍历开销)一些设置了过期时间的 key，检查其是否过期，如果过期就删除。
* 惰性删除：定期删除可能会导致很多过期 key 到了时间并没有被删除掉，假如过期 key，靠定期删除没有被删除掉，还停留在内存里，除非手动去查一下那个 key，才会被 redis 给删除掉。对于cpu来说是友好的，cpu不需要维护其它额外的操作，但是对于内存来说是不友好的。
* 定时删除：创建一个定时器，定时的执行对key的删除操作。对于内存来说是友好的，定时清理出干净的空间，但是对于cpu来说并不是友好的。

##### 内存淘汰机制

如果定期删除漏掉了很多过期 key，然后也没及时去查，也就没走惰性删除，如果大量过期 key 堆积在内存里，导致 redis 内存块耗尽。

* volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
* volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
* volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
* allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key
* allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
* no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

##### 内存满

1，redis.conf配置文件中配置内存大小`maxmemory 100mb`。

2，选择合适内存淘汰机制。`redis.conf`配置文件中配置`maxmemory-policy allkeys-lru`。假如数据有一部分是热点数据，而剩下的数据是冷门数据，可以使用`allkeys-lru`。假如所有的数据访问的频率大概一样，就可以使用`allkeys-random`的淘汰策略。

3，使用定期删除策略，并提高抽样频率，或者使用定时删除策略。增加了cpu负担，但内存回收效率高于懒惰回收。

4，缩短key的过期时间。

##### 持久化机制

https://i4t.com/2808.html

1，只追加文件（append-only file，AOF）：类似mysql的基于语句的binlog方式，每执行一条会更改 Redis 中的数据的命令，先执行写操作命令后，再将该命令记录到 AOF 日志里的（避免额外的语法检查开销，不会阻塞当前写操作命令的执行）。

当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有丢失的风险。写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是可能会给「下一个」命令带来阻塞风险（写操作和日志是同步的，上一次的写日志会阻塞下一次的写数据）。

Redis 执行完写操作命令后，会将命令追加到 server.aof_buf 缓冲区->然后通过 write() 系统调用，将 aof_buf 缓冲区的数据拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘->具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。写文件频率可以根据需求调节，高性能VS高可靠：总是、每秒、被动由OS决定，三种策略只是将内核缓冲区写入文件的频率不同。

![700](%E9%9D%A2%E7%BB%8F.assets/98987d9417b2bab43087f45fc959d32a.png)

重写机制：尽管某个键值对被多条写命令反复修改，最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这样就减少了 AOF 文件中的命令数量。最后在重写工作完成后，将新的 AOF 文件覆盖现有的 AOF 文件。重写的过程是由后台子进程完成的，这样可以使得主进程可以继续正常处理命令。

用 AOF 日志的方式来恢复数据其实是很慢的，因为 Redis 执行命令由单线程负责的，而 AOF 日志恢复数据的方式是顺序执行日志里的每一条命令，如果 AOF 日志很大，这个「重放」的过程就会很慢了。 

2，快照（snapshotting，RDB）：Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本，内容是二进制数据。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。

在 Redis 恢复数据时，直接将 RDB 文件（二进制文件）读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令的步骤才能恢复数据。执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。

执行快照时，数据被修改：如果主线程（父进程）要修改共享数据里的某一块数据（比如键值对 A）时，就会发生写时复制，于是这块数据的物理内存就会被复制一份（键值对 A'），然后主线程在这个数据副本（键值对 A'）进行修改操作。与此同时，bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件。

3，混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。AOF内容写入成本底，可以频繁写入，可以使得数据更少的丢失。

##### 缓存雪崩

为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，缓存同一时间大面积的失效或者 Redis 故障宕机，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决办法：宕机：1，尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上；2，对请求限流 ，避免 MySQL在redis崩溃后也崩掉，只要数据库正常工作，就可以处理用户请求，保证系统仍然可用。缓失效：1，把每个 Key 的失效时间都加个随机值，保证数据不会再同一时间大面积失效。2，对请求限流 。3，对缓存数据可以使用两个 key，一个是主 key，会设置过期时间，一个是备 key，不会设置过期，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本。4，让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新。

当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，同时更新「主 key 」和「备 key 」的数据。3，选择合适的内存淘汰策略，防止爆内存。5，利用 redis 持久化机制保存的数据尽快恢复缓存。

![700](%E9%9D%A2%E7%BB%8F.assets/14534869-cefa2f5519af3a09-16508964422012.png)

##### 缓存击穿

缓存击穿是指一个 Key 非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个 Key 在失效的瞬间，持续的大并发直接落到了数据库上，就在这个 Key 的点上击穿了缓存。

解决办法：1，设置热点数据永不过期，由后台异步更新缓存。2，在访问数据据时加上互斥锁，保证同一时间只有一个业务线程更新缓存。

##### 缓存穿透

黑客恶意攻击时请求大量既不在缓存中，也不在数据库中的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。

解决办法：1，在接口层增加校验，比如用户鉴权，参数做校验；2，采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，用于快速判断出 Key 是否在数据库中存在，一个一定不存在的数据会被这个 bitmap 拦截掉，这个恶意请求就会被提前拦截，从而避免了对DB的查询压力。3，如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。4，在访问数据据时加上互斥锁。

![700](%E9%9D%A2%E7%BB%8F.assets/061e2c04e0ebca3425dd75dd035b6b7b.png)

##### 快

Redis 单进程单线程的模型，因为 Redis 完全是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章的采用单线程的方案了。

a.基于内存操作：Redis的所有数据都存在内存中，因此所有的运算都是内存级别的，所以它的性能比较高。

b.数据结构简单：Redis的数据结构比较简单，是为Redis专门设计的，而这些简单的数据结构的查找和操作的时间复杂度都是O(1)。

c.多路复用和非阻塞IO：Redis使用IO多路复用功能来监听多个socket连接的客户端，这样就可以使用一个线程来处理多个情况，从而减少线程切换带来的开销，同时也避免了IO阻塞操作，从而大大提高了Redis的性能。

d.避免上下文切换：因为是单线程模型，因此就避免了不必要的上下文切换和多线程竞争，这就省去了多线程切换带来的时间和性能上的开销，而且单线程不会导致死锁的问题发生。

##### 主从复制

* 全量同步
  Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。

  1，从服务器连接主服务器，间其注册为从从服务器，之后发送SYNC命令； 
  2， 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件，并使用缓冲区记录此后执行的所有写命令(不阻塞主服务器端)； 
  3， 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 
  4， 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 从复制对于从redis服务器来说也是非阻塞的，进行主从复制过程中也可以接受外界的查询请求，只不过这时候从redis返回的是以前老的数据，
  5， 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
  6， 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；

  ![700](%E9%9D%A2%E7%BB%8F.assets/ea4f7e86baf2435af3999e5cd38b6a26.png)
  
* 增量同步
  Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

##### redis和数据库一致性

http://kaito-kidd.com/2021/09/08/how-to-keep-cache-and-consistency-of-db/

1，双写：无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，因为两个请求执行更新的顺序是不可预测的（DB：0->1->2，缓存：0->2->1），可能会出现缓存和数据库中的数据不一致的现象，第二部操作失败也会导致数据不一致。

每次数据发生变更，都更新缓存，导致缓存中可能存放了很多不常访问的数据，浪费缓存资源。数据库和缓存双写，就必然会存在不一致的问题。如果对数据有强一致性要求，不能放缓存。

如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。为解决数据不一致：在更新缓存前先加个分布式锁，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响；在更新完缓存时，给缓存加上较短的过期时间，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。

2，删除更新：在更新数据时，只更新数据库，不更新缓存，而是删除缓存中的数据。读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。

* 先删除缓存，再更新数据库：写请求删除缓存旧值，写入新值到DB间发生读请求。更新请求A将缓存删除之后，数据写入DB之前，读请求B到来，缓存未命中，读取DB中旧值，并写入缓存，请求A再更新DB为新值->数据不一致，读写分离场景下在新数据未同步到从数据库时发生读取操作，将从从数据库读取旧值，也将导致不一致。延迟双删：加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完（延时消息），再删除缓存，延迟时间在单机场景下下要大于 读取数据库 + 写入缓存的时间，读写分离场景下延迟时间要大于「主从复制」的延迟时间。延迟时间很难评估。

  ```text
  #删除缓存
  redis.delKey(X)
  #更新数据库
  db.update(X)
  #睡眠,请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。
  Thread.sleep(N)
  #再删除缓存
  redis.delKey(X)
  ```

* 先更新数据库，再删除缓存：某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中->数据不一致。

  在实际中，这个问题出现的概率并不高。因为缓存的写入通常要远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。

  保证两个操作都能执行成功：删除缓存（第二个操作）的时候失败了，导致缓存还是旧值，而数据库是最新值。

  > 1，重试机制：可以引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，保证消息成功投递。
  >
  > ![700](%E9%9D%A2%E7%BB%8F.assets/image-20221019223016194.png)
  >
  > 2，订阅 MySQL binlog，再操作缓存：策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除。
  >
  > MySQL主备复制原理:MySQL master 将数据变更写入binlog， MySQL slave 将 master 的 binlog 拷贝，重放 binlog 拷贝，将数据变更反映它自己的数据。canal 伪装自己为 MySQL slave ，向 MySQL master 发送dump 请求，获得并解析binary log 备份。自行建立canal客户端，从canal中获取数据，并将数据更新至Redis.
  >
  > 无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有.自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列。
  >
  > ![700](%E9%9D%A2%E7%BB%8F.assets/image-20221019223152503.png)

如果一致性不是太高可以采取正确更新策略，先更新数据库，再删缓存，并且给缓存数据加上了「过期时间」，就算在这期间存在缓存数据不一致，有过期时间来兜底，这样也能达到最终一致。

3，强一致： 2PC、3PC、Paxos、Raft 这类一致性协议，但它们的性能往往比较差。

##### 工作模式

* 单机：一个节点、简单低成本、数据一致、可靠性差、性能有限。
* 主从复制：master只写、slave只读；master到slave单向复制保证一致性；数据冗余、master宕机选取新master、读取分流高性能、master宕机后要通知外界新master地址，并复制新master数据到slave上，写能力受单个master限制。
* 哨兵模式：自动化的故障恢复、哨兵节点（不存储数据）和数据节点（主节点和从节点），访问redis集群的数据都是通过哨兵集群的，哨兵监控整个redis集群，新master产生不对外界产生影响，哨兵维护集群信息。哨兵定时发送询问信号监控其它哨兵和数据节点，主节点下线进行选取和数据复制。主从复制优点、健康监控、对外界屏蔽内部信息，难支持在线扩容。
* 集群： 高可用、可扩展性、分布式、容错。分布式：集群的键空间被分割为多个hash槽，通过hash的方式将数据分到不同的分片上的，每个分片认为主从结构，读请求分配给slave节点，写请求分配给master，数据同步从master到slave节点，高并发。可扩展：master节点可以做扩充，从新分配每个分片对应的hash值范围，数据迁移redis内部自动完成。容错：master故障，其slave节点选取产生新master节点并完成数据复制。

##### 分布式锁

Redis因为单进程、性能高的特点，它还经常被用于做分布式锁，用来控制分布式系统之间同步访问共享资源。

1，`SETEX key seconds value`如果不存在就设定键值对，并添加过期时间，两步动作是原子性的，会在同一时间完成，防止加锁成功后设置有效时间失败导致其它线程永远获取不到锁，最后返回1，如果已经存在直接返回0。获得锁就尝试设置某个key，成功后当过期时间到或者手动删除键值对表示释放锁，如果设置失败，表示有其它地方占据该锁需要等待对方释放。

2，缺陷

* 锁误解除：如果线程 A 成功获取到了锁，x线程任务耗时长，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 任务尚未执行完成，线程 A 实际释放的线程 B 加的锁。

  解决方法：通过在 value 中设置当前线程加锁的标识，在删除之前验证 key 对应的 value 判断锁是否是当前线程持有。

* 客户端长时间阻塞导致锁失效问题，业务程序还没执行完锁就过期了，如果其它线程拿到锁，可能会导致线程安全的问题。

  解决方案：将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间

* redis服务器时钟漂移问题，服务器时钟比客户端快，导致key在服务端失效，而客户端端锁却未过期，可能导致多个客户端同时持有同一把锁。

* 因为redis的主从同步是异步进行的，可能会出现客户端1设置完锁后，master挂掉，slave提升为master，因为异步复制的特性，客户端1设置的锁丢失了，这时候客户端2设置锁也能够成功，导致客户端1和客户端2同时拥有锁。

3，RedLock算法：Redis必须是多节点部署的，可以有效防止单点故障。

流程：

* 获取当前时间戳（ms）；
* 先设定key的有效时长（TTL），client尝试使用相同的key和value对所有redis实例进行设置，每次链接redis实例时设置一个比TTL短很多的获取锁超时时间，这是为了不要过长时间等待已经关闭的redis服务。
* 将有效时常减去获取锁的耗时，还有redis服务器的时钟漂移误差，得到这正可用的时长，并且成功设置锁的实例数>= N/2 + 1
* 如果客户端由于某些原因获取锁失败，便会开始解锁所有redis实例。

缺点：

* 如果获取锁时由于网络问题导致耗时太长，最终留给锁的有效时长就会大大减少，客户端访问共享资源的时间很短，很可能程序处理的过程中锁就到期了。
* 服务器的时钟漂移难以确定。
* 如果有节点发生崩溃重启的话，有可能出现多个客户端同时获取锁的情况：A、B、C、D、E，客户端1和2分别加锁->客户端1成功锁住了A，B，C，获取锁成功->节点C的master挂了，然后锁还没同步到slave，slave升级为master后丢失了客户端1加的锁->客户端2这个时候获取锁，锁住了C，D，E，获取锁成功。

##### Redisson

https://www.51cto.com/article/682636.html

redisson 是 Redis 官方的分布式锁组件。实现了可重入锁(Reentrant Lock)、公平锁(Fair Lock、联锁(MultiLock)、 红锁(RedLock)、 读写锁(ReadWriteLock)等，还提供了许多分布式服务。

1，普通锁：`RLock lock = redisson.getLock("myLock); `继承自 JDK 的 Lock 接口，指定加锁等待时间和持有锁时间， 实质是异步执行加锁Lua脚本 ，提供了可重入、续期和柱塞特性。

2，RedLock：构建多个 RLock ，然后根据多个 RLock 构建成一个 RedissonRedLock，解决容错性问题，部分实例异常，剩下的还能加锁成功。

##### 缓存更新

1、Cache aside
读取：
失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
命中：应用程序从cache中取数据，取到后返回。
更新：先把数据存到数据库中，成功后，再让缓存失效。

2，Read/Write Through Pattern
我们可以看到，在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。
 2、Read Through
Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。
 3、Write Through
Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）
 4、Write Behind Caching Pattern
Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。

##### 线程模型

Redis 是单线程，主要是指 Redis 在网络 IO和键值对读写是采用一个线程来完成的，这也是 Redis 对外提供键值存储服务的核心流程。但对于 Redis 的其他功能来说，比如持久化、异步删除、集群数据同步等，其实都是由额外的线程执行的。

在Redis6.0中新增了多线程的功能来提高IO的读写性能，它的主要实现思路是将主线程的IO读写任务拆分给一组独立的线程去执行，这样就可以使用多个socket的读写并行化了，但Redis的命令依旧是主线程串行执行的。

https://juejin.cn/post/6844903970511519758

https://www.cnblogs.com/mrmirror/p/13587311.html

https://www.cnblogs.com/mrmirror/p/13587311.html



### 消息队列

##### 特性

* 异步：同步下调用链路长、响应就慢了，异步减少请求的等待，还能让服务异步并发处理，提升系统总体性能。
* 解耦：解决上下游之间耦合的问题，订单服务把订单相关消息塞到消息队列中，下游系统谁要谁就订阅这个主题，下游变更不影响上有服务。
* 削峰：请求先放入消息队列中，后端服务尽自己最大能力去消息队列中消费请求，超时的请求可以直接返回错误。一些服务特别是某些后台任务，不需要及时地响应，并且业务处理复杂且流程长，那么过来的请求先放入消息队列中，后端服务按照自己的节奏处理。

##### 丢失检测

利用消息队列的有序性来验证是否有消息丢失。在Producer端给每个发出的消息附加一个连续递增的序号，然后在Consumer端来检查这个序号的连续性。

##### 有序

rabbitMQ：不保证多线程消费同一个队列的消息是顺序的。而不保证的原因，是因为多线程时，当一个线程消费消息报错的时候，RabbitMQ 会把消费失败的消息再入队，此时就可能出现乱序的情况。一生产者只向特定队列发送消息，需要每个Producer分别生成各自的消息序号，每个队列只有一个接收者，在每个队列单独检测消息序号的连续性。

Kafka 的发布订阅并不会复制消息，无论是多少消费者，他们只需要主动去找到消息在文件中的位置即可。Kafka 不会出现消费者出错后，把消息重新入队的现象。

##### 可靠传递：

https://juejin.cn/post/6977981645475282958

* 生产阶段：1，在生产阶段通过最常用的请求确认机制，来保证消息的可靠传递（异步性能损耗较小）：可以开启 `confirm` 模式，每次写的消息都会分配一个唯一的 id，如果成功写入了 RabbitMQ 中，会回传一个 `ack` 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调 `nack` 接口，告诉你这个消息接收失败，可以重试。2，选择用 RabbitMQ 提供的事务功能（同步降低吞吐量），就是生产者发送数据之前开启 RabbitMQ 事务`channel.txSelect`，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务`channel.txRollback`，然后重试发送消息；如果收到了消息，那么可以提交事务`channel.txCommit`。

  ```java
  
  //confirm 监听，当消息成功发到交换机 ack = true，没有发送到交换机 ack = false
  //correlationData 可在发送时指定消息唯一 id
  rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> {
      if(!ack){
          //记录日志、发送邮件通知、落库定时任务扫描重发
      }
  });
  
  //当消息成功发送到交换机，但没有路由到队列触发此监听
  rabbitTemplate.setReturnsCallback(returned -> {
      //记录日志、发送邮件通知、落库定时任务扫描重发
  });
  ```

* 存储阶段：对于单个节点的RabbitMQ ，需要配置RabbitMQ 参数，将 queue 的持久化标识 durable 设置为 true，在收到消息后将消息写入磁盘后再给Producer返回ack确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息。即使是在持久化到磁盘之前，RabbitMQ 崩溃，内存数据丢失，生产者收不到 `ack`，可以进行重发的。

* 消费阶段：客户端从RabbitMQ 拉取消息后，执行用户的消费业务逻辑成功后，才会给RabbitMQ 发送消费确认响应。如果RabbitMQ 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息。

  ```java
  @RabbitListener(queues = "queue)
  public void listen(String object, Message message, Channel channel) {
      long deliveryTag = message.getMessageProperties().getDeliveryTag();
      try {
          // 执行业务代码
          channel.basicAck(deliveryTag, false);
      } catch (IOException e) {
          channel.basicNack(deliveryTag, false, true);
      }
  }
  ```

  

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220828214124078.png)

##### 重复消费

若ack消息在网络传输过程发送错误，由于发送方收不到确认，会通过重发保证消息不丢失。发送消息阶段，发送重复的消息；消费消息阶段，消费重复的消息。前端用户重复提交；后端用户恶意刷单。

业务端去重（发送消息时的MQ，接收消息时的消费者）：一般消息中都会存在个唯一性东西，只要消费过该消息，将消息以K-V（< id,message>）形式写入redis，消费消息之前，根据key去redis查询是否有对应记录，无记录则操作完成后添加该记录。为数据添加版本号，在操作数据库时条件带上版本号，在消息中指定被操作的数据的当前版本号，消息被执行后版本+1,如果重复到达消息，第二个消息版本将无法匹配。

##### 消息挤压

producer端生产速度 > consumer端消费速度（生产端并发量飙升如抢购，消费端有很多消费失败，导致消费性能下降）。

紧急措施：对生产者发消息接口进行适当限流；水平扩容：写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue，接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据，这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据增加消费端的并发数。跳过非重要消息：发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。

消息积压过期丢失： 消息持久化，手动去查询丢失的那部分数据，然后将消息重新发送到mq里面，把丢失的数据重新补回来。

后续修复：对消费者程序进行性能优化提升处理能力；增加校验逻辑，拒绝异常请求。

##### 点对点、发布订阅

https://www.cnblogs.com/gaopengpy/p/11994984.html

多个生产者可以向同一个消息队列发送消息；但是，一个消息在被一个消息者处理的时候，这个消息在队列上会被锁住或者被移除并且其他消费者无法处理该消息。也就是说一个具体的消息只能由一个消费者消费。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220928114031856.png)

发布/订阅（pub/sub）模式中，单个消息可以被多个订阅者并发的获取和处理。RabbitMQ使用消息交换器来实现发布/订阅模式。每一个订阅了交换器的消费者都会创建一个队列；然后消息交换器会把生产的消息放入队列以供消费者消费。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220928114042278.png)

通过订阅模式将消息发布到多个队列，订阅者以组队的方式然后在组内以竞争关系作为消费者去处理某个具体队列上的消息，这种由订阅者构成的组我们称为消费者组。实现发布/订阅模式，同时也能够很好的伸缩（scale-up）订阅者去处理收到的消息。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220928114154887.png)

##### RabbitMQ、Kafa

https://cloud.tencent.com/developer/article/1602531

https://www.zhihu.com/question/275090117

1，rabbitMQ是消息中间件，Kafka是分布式流式系统。

2，RabbitMQ使用消息交换器来实现发布/订阅模式。每一个订阅了交换器的消费者都会创建一个队列；然后消息交换器会把生产的消息放入队列以供消费者消费。

Kafka的存储层是使用分区事务日志来实现的。Kafka没有实现队列这种东西。相应的，Kafka按照类别存储记录集，并且把这种类别称为主题。Kafka为每个主题维护一个消息分区日志。每个分区都是由有序的不可变的记录序列组成，并且消息都是连续的被追加在尾部。

建立主从节点，Leader状态的Broker接收消息，写入到相应topic中Leader状态的Broker接收完毕以后，传给Follow状态的Broker作为副本备份。每个Broker上的同一主题可以分多个Partition，如partition1存放1、3、5消息，partition2存放2、4、6消息，提高并发读写效率。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220928134346209.png)

消费者通过维护分区的偏移（或者说索引）来顺序的读出消息，然后消费消息。消费同一个主题的多个消费者构成的组称为消费者组。通过Kafka提供的API可以处理同一消费者组中多个消费者之间的分区平衡以及消费者当前分区偏移的存储。每一个消费者组都可以独立的伸缩去处理相应的负载。



![700](%E9%9D%A2%E7%BB%8F.assets/image-20220928115359730.png)

3，RabbitMQ无序；Kafka有序： 发布订阅并不会复制消息，无论是多少消费者，他们只需要主动去找到消息在文件中的位置即可，Kafka 不会出现消费者出错后，把消息重新入队的现象。

4，RabbitMQ路由匹配灵活，在消息中添加 routing_key 或者自定义消息头，然后通过一些特殊的 Exchange，很简单的就实现了消息匹配分发。Kafka消费者端必须先把所有消息都取出来，再根据业务需求，自己去实现各种精准和模糊匹配。

5，RabbitMQ 的消息自带手表，在发送消息的时候，把消息发往一个特殊的 Exchange。同时，在消息头里指定要延迟的时间。收到消息的 Exchange 并不会立即把消息放到队列里，而是在消息延迟时间到达后，才会把消息放入。

Kafka 先需要把消息先放入一个临时的 topic。然后得自己开发一个做中转的消费者。让这个中间的消费者先去把消息从这个临时的 topic 取出来。把没有到时间的消息存入到数据库里。存入数据库中的消息需要在时间到了之后再放入到 Kafka 里。

6，kafka当单个分区中的消息一旦出现消费失败，就只能停止而不是跳过这条失败的消息继续消费后面的消息。即不允许消息空洞。 RabbitMQ 呢，它由于会在消息出问题或者消费错误的时候，可以重新入队或者移动消息到死信队列，继续消费后面的，会省心很多。

7，Kafka 是每秒几十万条消息吞吐，配置复杂、维护复杂。而 RabbitMQ 的吞吐量是每秒几万条消息，简单够用。

### Nginx

1，快

https://juejin.cn/post/6847902216662024199

https://zhuanlan.zhihu.com/p/109953289

采用的是多进程 & 多路IO复用模型，并发事件驱动的服务器。

Nginx 在启动后，会有一个 master 进程和多个相互独立的 worker 进程。master 接收来自外界的信号，向各 worker 进程发送信号，每个进程都有可能来处理这个连接。master 进程能监控 worker 进程的运行状态，当 worker 进程退出后(异常情况下)，会自动启动新的 worker 进程。

多进程模式，不仅能提高并发率，而且进程之间相互独立，一个 worker 进程挂了不会影响到其他 worker 进程。master进程充当整个进程组与用户的交互接口，同时对进程进行监护，它不需要处理网络事件，不负责业务的执行。一个请求完全由 worker 进程来处理，而且只能在一个 worker 进程中处理，所有 Worker 进程都是平等的，一般设置为核心数，避免进程竞争 CPU 资源。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221019171911637.png)

IO多路复用模型epoll：Nginx 通过注册事件来完成通知，避免多线程阻塞。如注册新连接请求到来事件，只有连接请求到来，服务器才会执行 accept() 来接收请求；如缓冲区满事件，事件发生后再去读取数据。

2，惊群

主进程（master 进程）首先通过 socket() 来创建一个 sock 文件描述符用来监听，然后fork生成子进程（workers 进程），子进程将继承父进程的 sockfd（socket 文件描述符），之后子进程 accept() 后将创建已连接描述符（connected descriptor），然后通过已连接描述符来与客户端通信。由于父子进程间共享文件描述符，那么当连接进来时，所有子进程都将收到通知并“争着”与它建立连接，这就叫“惊群现象”。大量的进程被激活又挂起，只有一个进程可以accept() 到这个连接，这当然会消耗系统资源。

Nginx 提供了一个 accept_mutex 这个东西，这是一个加在accept上的一把共享锁。即每个 worker 进程在执行 accept 之前都需要先获取锁，获取不到就放弃执行 accept()。有了这把锁之后，同一时刻，就只会有一个进程去 accpet()。

3，作为服务器最大连接数：Worker 进程数量 x 单个 Worker 进程的最大连接数。作为反向代理服务器：(Worker 进程数量 x 单个 Worker 进程的最大连接数)/ 2，会建立 Client 的连接和后端 Web Server 的连接，占用 2 个连接。


### Git

##### 基础

1，多次add（把文件修改添加到暂存区）一次commit（把暂存区的所有内容提交到当前分支)，修改版本清晰。

2，`diff filename`查看修改，`status`参看文件变更记录，`git diff`：比较工作区与暂存区，`git diff HEAD`：比较工作区与当前已提交分支，`git diff -- cached`：比较暂存区与当前已提交分支。

3，`log`：查看提交记录，如果回退会丢失回退到的节点后内容；`git reflog`用来记录每一次命令；head指向当前版本，`reset —hard HEAD^`：回到上一个版本，上上版本就是`HEAD^^`,`reset --hard 1094a`：回退到指定版本，版本号可由log或者reflog获得。

3，撤回修改：

工作区已修改且未`add：checkout -- filename`：让工作区文件回到最近一次`git commit`（暂存区无修改）或者`git add `（暂存区有修改）时的状态。

工作区已修改且已add：`git reset HEAD <file>`：把暂存区的修改回退到工作区，就回到了工作区已修改且未add，`add：checkout -- filename`：让工作区文件回到最近一次`git commit`时的状态。

工作区已修改且已add并commit：版本回退`reset —hard soneid`。

4，远程仓库：

关联远程：`git remote add origin git@github.com:michaelliao/learngit.git`

`git push origin master`命令把当前分支`master`推送到远程（第一次推送`master`分支时加上了`-u`参数，把本地的`master`分支和远程的`master`分支关联起来）

` git remote rm origin`：解除了本地和远程的绑定关系

##### 分支

1，分支管理：可以存在多个分支，每个人都在`dev`分支上干活，每个人都有自己的分支，时不时地往`dev`分支上合并,最终将合并到master。通过head指向当前所在分支，分支指向最新提交。在dev分支上开发，完成后合并到maste分支。`git branch dev`：创建分支，`git switch dev`:head指向dev分支，以后的修改都在dev上延申。开发完成后切换回主分支`switch master` 此时工作区还原到master下，dev修改未体现，把`dev`分支的工作成果合并到`master`分支上`git merge dev`，dev上修改体现在master上，删除无用分支：`git branch -d dev`，丢弃一个没有被合并过的分支，可以通过`git branch -D <name>`强行删除。`merge`默认使用fast forwad模式将master直接指向dev指向的节点，当dev分支删除时将丢失分支信心。通过禁用`Fast forward`模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息` git merge --no-ff -m "merge with no-ff" dev`。

2，冲突管理：dev和master分支都对同一个文件修改，导致无法合并。手动将两个分支发生冲突的文件修改为一致再合并。git pull 将远程仓库的代码拉取下来->执行git diff查看冲突文件->和更改此文件的人沟通，看看需要保留谁的更改->再add commit push。

3，暂存工作区：当前dev分支未完成，无法提交，接到紧急任务需要立即处理，可以将当前dev分支暂存` git stash`，dev分支变为clwean tree，切换到master分支创建紧急任务分支，紧急任务完成后切换后dev分支并恢复环境`git stash pop`。在master分支上修复的bug，同样存在于dev分支中，想要合bug修改到当前dev分支，可以用`git cherry-pick bug-commit-id`命令，把bug提交的修改“复制”到当前分支，避免重复劳动。

4，merge:` git merge main` 自动根据两个分支的共同祖先的最后一个commit和两个分支的最新提交进行一个三方合并，然后将合并中修改的内容在当前分支(dev)生成一个新的merge commit。`dev` 分支每次需要合并上游更改时，它都将产生一个额外的合并提交。保留了两个分支历史信息，如果`main` 提交非常活跃，这可能会严重污染 dev 分支历史记录。

rebase:`git rebase main` 会从两个分支的共同祖先开始提取当前分支(dev)上的修改,再将修改应用到目标分支(main)的后面。同时两个分支的最新指向不变。rebase 通过为原始分支(dev)中的每个提交创建全新的 commits 来重写项目历史记录。rebase 的主要好处是可以获得更清晰的项目历史。它消除了 `git merge` 所需的不必要的合并提交；其次rebase 会产生完美线性的项目历史记录，但是丢失了分支的原始信息。永远不要在公共分支上使用它`git rebase dev`会将所有 master 分支上的提交移动 dev分支的顶端,导致本地master分支历史与其他人的历史不同。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220312163120359.png)

5，合并多个cmoomit:`git rebase -i commit-id`，`commit-id`为想要合并的多个提交的最前面提交的commit id，即[1,2,3,4]，如果commit-id=1，即把2,3,4合并得到新的2，最终得到[1,2]。





### 仿B站

RSA非对称加密，公钥用于数据加密，私钥用于数据解密。客户获取服务端公钥，对生成的密钥加密，传输到服务端，服务端使用私钥解密得到与客户端相同的密钥，完成密钥协商，安全+复杂，后续数据加密（密码）使用该密钥进行对称加密，快速。

注册：接收用户传递Json对象，判断手机号是否存在，为防止服务端数据库中直接存储密码泄露，被冒充登录，使用用户密码+盐使用md5，构建签名，由于md5单向算法无法由盐+签名还原用户密码，阻止冒充登录。最后将签名和盐保存到数据库中。

登录：将收到密码解密后，与数据库中相同手机号的用户的`salt`构建签名，再将签名与数据库中签名比较以完成认证。成功后根据用户ID生成`accessToken,refreshToken`返回给用户用于后续请求认证，同时将`refreshToken`保存在数据库中用于后续刷新。

双token：token=用户标识+有效期；用户保存数据，分布式；用户状态变化（删除，禁用，注销等）影响到业务而Token仍然有效时，仍然能利用token完成认证；当token过期后需要用户重新登录，用户体验差。accessToken （负责后端业务验证，有效期端10分钟）+ refreshToken（负责续签验证，有效期长， 7 天）。认证后返回 accessToken + refreshToken，并保存在本地，服务端保存refreshToken，请求时只用 accessToken，客户端在 accessToken 在失效前主动发起请求用 refreshToken 返回一个新的 accessToken，用户无感提高用户体验。退出时客户端删除accessToken + refreshToken，服务端删除refresh-token，由于accesstoken有效期短，即使accesstoken被泄露，也会很快过期。

访问权限：哪些页面可以访问、哪些页面元素可见等等；操作权限：如页面按钮是否可点击、是否可以增删改查等等；接口与数据权限：接口是否可以调用、接口具体字段范围等等。

RBAC权限模型核心授权逻辑如下：某用户是什么角色；某角色具有什么权限；通过角色的权限推导用户的权限。核心表：用户表存储用户（`id`，`phone`）；角色表存储可选的用户等级（lv0，lv1，lv2）；页面元素操作表存储可对前端页面上某个元素进行的操作(比如可点击的上传视频按钮)；页面访问表存储页面（比如购买邀请码的页面）。连接表：用户-角色关联表`t_user_role`存储用户与角色的关联关系（指明用户所处等级）；角色-元素操作关联表`t_auth_role_element_operation`存储角色与页面元素操作间关联（指明不同等级与不同可操作元素间关系，比如lv0不能点击视频上传按钮，lv1可以点击）；角色-页面关联表`t_auth_role_menu`存储角色与可访问页面的关系(指明角色与页面间的可访问关系，比如lv0不能访问邀请码购买页面，lv1可以正常访问)。后续权限变更只需要更改连接表，关键信息表不变，方便拓展。

根据用户ID获得用户角色(等级)信息`userRoleList`、所拥有的页面元素操作权限`RoleEleOps`与后台数据操作权限`RoleMeau`。在获取到用户角色信息(等级信息)、页面元素操作权限信息、菜单操作权限信息后，前端就可以对按钮是否可点击做出限制，后端就可以根据预设权限规则对用户操作进行鉴权、拦截。

权限验证使用广泛，使用面向切面编程，将通用功能抽取，降低模块间的耦合度，避免重复代码，使被影响代码更加专注于业务逻辑的处理，被影响模块无感知。

lv1及以上用户页面上发表动态按钮才是可点击的，可能存在用户绕过前端无法点击按钮的限制直接访问接口的情形。定义注`ApiLimit`，用于根据用户等级拦截用户对接口的访问，注解加在添加动态的API上，参数为被拦截的用户等级。定义切面`ApiLimiteAspect`拦截有`ApiLimit`注解的方法，在进行业务的执行之前根据传入注解的限制等级集合，验证当前用户所在等级是否在黑名单中，如果在将报异常，否则正常进行后续流程。

FastDFS的二个角色：跟踪服务器（Tracker）、存储服务器（Storage）。跟踪服务器：主要做调度工作，起到负载均衡的作用。存储服务器：主要提供容量和备份服务。

文件整体传输时，如果文件较大，则会长时间占用网络带宽，挤占其它应用网络；同时当传输被迫中断时，之前传输数据将被丢弃，并从头开始传输。通过对文件分片，按照一定间隔传输分片，不会长时间占据带宽，并且如果传输中断，只会从被中断分片开始传输，之前分片不会重复传输。

上传第一个分片时会在文件服务器上创建一个新的文件，并返回访问路径，上传后续分片时，依据文件路径和偏移量，直接在原始文件的后面添加。

在对文件分片上传时，服务端接收分片文件和完整文件的md5值，上传第一个分片时会在文件服务器上创建一个新的文件，并返回访问路径，使用redis暂存文件信息，其中key为文件md5，value为文件路径和已上传比特数。后续上传比特时根据文件md5取出缓存中的文件路径和以上传比特数，之后以已上传比特数为偏移，直接向路径中的文件添加数据。当所有分片传输完成后返回文件在文件服务器中的相对路径给用户，最后把文件路径、md5摘要等信息存入数据库。

对要保存的完整文件生成MD5摘要，MD5摘要之和文件内容相关，与文件名无关，将生成的摘要与已经保存过的文件的摘要进行对比，如果存在匹配项则表示相同文件已经存在，不必重复上传，直接返回已保存文件路径即可，防止保存重复数据。

在线播放最简单的形式就是直接向客户端发送完整链接地址，其缺点是向外界暴露了文件所处位置，用户可以绕过登录等权限控制，直接访问视频文件。

在线播放建议采用分片传输比特流的形式，客户端向服务器发起对某一个分段数据获取请求，并请求头中通过`<Range,bytes=start_byte-end_byte>`，指明当前分片请求的开始和结束比特数，其中相对地址指明的视频并不在接收请求的服务器上，当前服务端接受请求再去文件存储服务器查找文件，最终根据用户要求的数据范围以比特流的形式将数据写入http响应，这样外界无法知道文件具体位置，避免文件暴露，同时分片的方式使得断点续传得以实现。

当用户在观看视频时，如果客户端针对某一视频创建了弹幕，发送后端进行处理，后端需要对所有正在观看该视频的用户推送该弹幕。HTTP协议是一个请求－响应协议，请求必须先由浏览器发给服务器，服务器才能响应这个请求，故必须不停连接后端轮询的效率低或者 HTTP 连接始终打开（长连接存在一个保持时间限制，一个HTTP连接在长时间没有数据传输的情况下，链路上的任何一个网关都可能关闭这个连接，而网关是我们不可控的，必须定期发一些ping数据表示连接“正常工作”，虽然可以在一次 TCP 连接中完成多个 HTTP 请求，但是对每个请求仍然要单独发 header，要大量交换 HTTP header 40字节，比弹幕本身还大），非常浪费资源。

采用WebSocket进行前后端通信，建立持久的双边通信通道。WebSocket协议是基于TCP的一种新的网络协议，它实现了浏览器与服务器全双工(Full-Duplex)通信，WebSocket允许服务端主动向客户端推送数据。由于HTTP是非状态性的，每次都要重新传输鉴别信息，Websocket的整个通讯过程是建立在一次连接/状态中，服务端会一直知道对方信息，这就使得其成为一种有状态的协议，之后通信时可以省略部分状态信息。

在建立连接时获得会话信息，将会话加入当前bean类得静态ConcurrentHashMap中，保存用户连接信息，key为sessionid，value为会话，每新建一个连接就添加新的连接信息，断开连接就删除连接信息。静态变量：当前bean非单列的，没新建一个连接就会建立一个bean，静态变量使得当前视频连接下所有bean公用，保证数据一致和正确。

收到新弹幕时，ConcurrentHashMap获取当前在线用户，为每一个用户构建弹幕发送任务，弹幕推送任务为一个map，key为接收用户会话id，value为弹幕信息。再将任务发送到特定exchange，将消息投递到特定队列。消息接收者监听消息队列，从消息队列中获取消息，更绝会话id拿到会话，再发送给指定用户。将任务的调用方与真正执行任务方解耦。

数据保存到数据库时，由于弹幕的保存对用户无感，且操纵耗时，可以使用异步操作；本质基于动态代理实现：Spring容器启动初始化bean时，判断类中是否使用了@Async注解，创建切入点和切入点处理器，根据切入点创建代理，在调用@Async注解标注的方法时，会调用代理，执行切入点处理器invoke方法，根据要执行的任务创建`Callable`接口对象，将方法的执行提交给线程池，实现异步执行。

使用redis保存新添加弹幕，下次读取弹幕直接从redis中读取，避免访问数据库，降低数据库压力，向redis写入当弹幕数据时，由于redis读写快速，可以使用同步操作，同时也是为了保证下一次查询数据时，即使数据还没落盘，也能在redis中找到。存储的key为`dm-video-videoId`，value为当前视频对应的弹幕列表。

##### 权限模型

1，自主访问控制DAC模型，系统会识别用户，然后根据被操作对象的权限控制列表或者权限控制矩阵的信息来决定用户是否能对其进行哪些操作，DAC 最大的缺陷就是对权限控制比较分散不便于管理。（微软NTFS）

2， 强制访问控制 MAC 模型，每一个对象都有一些权限标识，每个用户同样也会有一些权限标识，而用户能否对该对象进行操作取决于双方权限标识的关系（对象指明两级以上用户才有权限）

3，基于角色的访问控制RBAC模型，给用户定义角色，通过角色来控制权限。用户拥有角色，且可拥有多个角色，而每个角色对应不同权限。不必为每一个用户去配置权限，拥有极大的灵活性和便利性。

4，基于属性访问控制ABAC，Attribute-based Access Control. 基于属性的访问控制。系统根据一组或多组属性是否满足预设规则来动态的控制，谁可以访问哪些功能数据和操作。（某种等级的用户，在规定的时间和地点，拥有某种权限）

##### 推送

https://quericy.me/blog/861/

https://www.cnblogs.com/sunli/archive/2010/08/24/twitter_feeds_push_pull.html

* 结构：每个用户一个收Feed有序集用于存放接收到的好友动态ID。有序集key名包含UID，成员为动态记录(动态ID和动态发布者UID的封装)，分数为时间戳。每个用户一个发Feed有序集用于存放该用户自己发的动态ID。有序集key名包含UID，成员为动态ID，分数为时间戳。
  一个动态发布处理队列，用于在用户发帖时处理动态推送
  一个关注取关处理队列，用于在用户关注/取关时处理动态的增减

* 发动态：动态发布处理队列发现新消息时，取队首消息出队列。根据消息中的发布者UID，遍历其粉丝列表(当以后全站粉丝量较大时，可扩展为选择性推送)。给每个粉丝推送一条动态，将动态ID和时间戳写入粉丝的收Feed有序集中。消息处理完成，检查队列是否还有消息，无则阻塞。
* 加关注、取关：关注取关处理队列发现新消息时，取队首消息出队列。根据动作标识判断是关注还是取关操作。如果是关注，拉取关注者的发Feed有序集中的动态，将最近的动态ID写入用户自己的收Feed中。如果是取关，遍历用户自己的收Feed，剔除其中取关UID的动态记录。消息处理完成，检查队列是否还有消息，无则阻塞。
* 队列最大长度为300，丢弃老旧内容。key设置过期时间，防止占据大量内存。

```java
redisTemplate.opsForZSet().add(key, value, score);// 添加
redisTemplate.opsForZSet().remove(key, value);//删除
redisTemplate.opsForZSet().zCard(key);//集合大小
redisTemplate.opsForZSet().range(key, start, end);//查询集合中指定排序区间的值
redisTemplate.opsForZSet().reverseRange(key, start, end);//查询逆序后集合中指定排序区间的值
redisTemplate.opsForZSet().incrementScore(key, value, score);//修改score
redisTemplate.opsForZSet().expire(K key, long timeout, TimeUnit unit);// 过期时间
```

##### 大文件上传

https://www.upyun.com/tech/article/679/%E5%A6%82%E4%BD%95%E8%AE%A9%E4%BD%A0%E7%9A%84%E5%A4%A7%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E5%8F%98%E5%BE%97%E5%8F%88%E7%A8%B3%E5%8F%88%E5%BF%AB%EF%BC%9F.html

https://developer.aliyun.com/article/856731

https://developer.aliyun.com/article/788388?spm=a2c6h.12873639.article-detail.38.243417e8QCmymE&scm=20140722.ID_community@@article@@788388._.ID_community@@article@@788388-OR_rec-V_1

https://developer.aliyun.com/article/852531?spm=a2c6h.12873639.article-detail.35.243417e8QCmymE

https://www.jianshu.com/p/360e37539266

前端使用百度的webuploader组件完成文件分片和md5计算。携带数据+比特偏移+MD5+当前分片编号+总的分片数

服务端接收并发请求，指定分片的偏移量通过随机读写的方式并发上传文件，提高速率，返回当前分片上传是否成功。所有分片上传完毕后将分片文件依次写入FASTDFS中。使用字符串记录分片上传情况，字符串长度与分片数相同，0未上传，1已上传。判断所有分片是否上传完毕。

断点续传：根据md5查询文件哪些分片上传完成，哪些未完成，继续上次传输。

并发+断点续传+秒传

网络好：分片大+并发线程多，网络差：分片小，并发线程小。

### 抖音后端

##### 数据库设计

用户表：

```sql
    `id`
    `user_name`
    `salt` 防止数据库泄露后根据加密后密码还原出原始密码，加盐后(salt+pd)->npd更难以破解
    `password`
    PRIMARY KEY (`id`)
```

关注表：

```sql
    `user_id`  ,
    `follow_id`,
    PRIMARY KEY (`user_id`,`follow_id`),  COMMENT '联合主键保证关注不重复，便于查询当前用户关注的用户'
    INDEX `idx_relation_fans` (`follow_id`, `user_id`) COMMENT '便于查询当前用户的粉丝'
```

视频表

```sql
    `id`
    `author_id` 
    `play_url`   
    `cover_url`   
    `favorite_count` 
    `comment_count` 
    `title`         
    `created_at`   
    PRIMARY KEY (`id`),
    INDEX `idx_author_id` (`author_id`), 便于查询发布列表
    INDEX `idx_video_created_at` (`created_at`)，便于时间逆序会的视频流
```

点赞表

```sql
    `user_id`  
    `video_id` 
    PRIMARY KEY (`user_id`, `video_id`) COMMENT '联合主键保证用户点赞某个视频不会重复，便于查询用户点赞视频列表'
```

评论表

```sql
`id`         
`user_id`    
`video_id`    
`content`    
`create_date` 
PRIMARY KEY (`id`),
INDEX `idx_comment_video_id` (`video_id`,`create_date` desc) 便于查询视频所属的评论集合
```

##### 视频上传

视频上传模块：先本地保存文件，生成视频封面时，由于视频解码耗时较长，创建截图任务放入channel，指明视频文件路径，和要保存的图片路径，通过Go程异步适用ffmpeg解码生成封面，保存视频数据到数据库，然后以静态资源形式开放视频、封面文件访问。如果缓存中存在当前用户的作品集合，将当前视频加入缓存。

##### 发布列表

获得发布列表模块：先查缓存获得videoId，不存在则查数据库，然后放入缓存。在构建响应式需要用户信息（基本信息，关注数、粉丝数、是否关注），视频信息（基本信息，点赞数、评论数、是否点赞），上述信息是独立的，可以通过WaitGroup构建一组任务，Go程并行调用视频、点赞、评论、关注以及用户服务，将原有流程异步化，缩短响应信息拼装时间。



##### 视频推荐

依据用户的视频点赞记录，推测用户喜好，完成视频推荐。机器学习算法，但是缺少真实的用户行为数据，所以使用基于用户的协同过滤算法。物以类聚、人以群分。物以类聚，视频A，B相似，喜欢A的也大概率喜欢B，基于物品的协同过滤。人以群分，用户A，B相似，A喜欢的视频B也大概率喜欢，基于用户的协同过滤。

视频网站视频数大于用户数，所以选择基于用户的协同过滤，减少计算量。根据用户-视频的点赞矩阵，计算当前用户与其它用户的余弦相似度，以相似度为权值，将其他用户对某视频喜爱程度的加权和，作为当前用户对该视频的喜爱程度。有了用户对每个视频的评分，基于评分降序排列，就可以取topN推荐给用户了。

视频点赞操作模块：添加点赞和取消点赞的记录<user,video>同时存入数据库和缓存，并在缓存中维护视频点赞数；构建用户响应时，通过Go程并行调用视频、点赞、评论、关注以及用户服务，将原有流程异步化，缩短响应信息拼装时间。

##### 获取点赞列表

先查缓存获得videoId，不存在则查数据库，然后放入缓存。在构建响应式需要用户信息（基本信息，关注数、粉丝数、是否关注），视频信息（基本信息，点赞数、评论数、是否点赞），上述信息是独立的，可以通过WaitGroup构建一组任务，Go程并行调用视频、点赞、评论、关注以及用户服务，将原有流程异步化，缩短响应信息拼装时间。

##### 缓存模块

缓存中维护用户发布视频集合、用户间关注关系集合、用户点赞视频集合、视频评论集合，通过缓存提升整体性能，平稳数据库流量，保证系统高可用与高可靠。

##### Set数据结构

##### 一致性问题

### Java Vs Go

1，Go不像Java、C++有类的概念，但可以基于结构体来实现类和类的方法的概念。

2， Go协程用起来比线程更加简单，占用的资源也更少，避免了内核态和用户态的切换导致的成本。Java并没有从语言层面默认提供协程的实现，主要使用线程。

3，Go首字母大写是公有的（public），首字母小写是私有的（private）。Java则是通过访问修饰符（public、private、protected)来控制变量、方法或类的访问权限。

4，Go编译型语言，无法跨平台。Java编译型+解释型语言，运行在JVM上，跨平台。

5，Java的继承通过extends关键字完成，不支持多继承；Go语言的继承通过匿名组合完成：基类以Struct的方式定义，子类只需要把基类作为成员放在子类的定义中，支持多继承。

6，Java 语言需要在类的定义上显式地使用关键字实现了某些接口（implements）， Go 语言的接口是隐式的，只要结构体上定义的方法在形式上（名称、参数和返回值）和接口定义的一样，那么这个结构体就自动实现了这个接口。

7，java中不存在显式的指针，而Golang中存在显式的指针操作，注意，java和golang都是只存在值传递。

Java中无论传递的参数类型是值类型还是引用类型，都会在调用栈上创建一个形参的副本。不同的是，对于值类型来说，复制的就是整个原始值的复制。而对于引用类型来说，由于在调用栈中只存储对象的引用，因此复制的只是这个引用，而不是原始对象。

Go中传值是浅拷贝，传指针则拷贝指针，只是形参、实参指针指向同一个内容。

8，在Java中，通常借助于共享内存（全局变量）作为线程间通信的媒介，通过共享内存通信；在Golang中使用的是通道（channel）作为协程间通信的媒介，通过通信来共享内存。



### 并发

##### go协程

线程池有效的减少线程创建和销毁所带来的开销。若 worker 线程执行的 G 任务中发生系统调用，则操作系统会将该线程置为阻塞状态，浪费线程资源，线程池消费任务队列的能力变弱了。增加线程池中线程数量可以一定程度上提高消费能力，但随着线程数量增多，过多线程会争抢 CPU，线程数过多，那么操作系统会频繁的切换线程，频繁的上下文切换就成了性能瓶颈。

- 进程: 进程是具有一定独立功能的程序，由程序+数据集合+进程控制块组成，程控制块（PCB）来描述进程，进程是系统资源分配的最小单位。每个进程都有自己的独立内存空间，独立的堆栈、由操作系统调度（抢占式调度）、切换开销大(栈、寄存器、虚拟内存、文件句柄等)、稳定安全、不同进程通过进程间通信来通信。
- 线程: 线程是进程的一个实体,线程是内核态,而且是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位。独立的栈和程序计数器和共享的代码段、数据段、打开的文件等资源、地址空间等，由操作系统调度（抢占式调度），线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。多核并行高性能、适合IO密集型、通信不需要OS干预。
- 协程: 协程是组织好的代码流程，是一种用户态的轻量级线程，协程的调度完全是由用户来控制的，内存占用小2KB 。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，对内核透明，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快，难以实现强制的 CPU 控制权切换，需要协程自己主动把控制权转让出去之后，其他协程才能被执行到。
- goruntime ：Golang 从语言层面支持了协程，在 runtime、系统调用等多方面对 goroutine 调度进行了封装和处理。网络编程： 高并发、程序生命期短、高IO，低计算。适配协程特点。

##### CSP并发机制

以通信的⽅式来共享内存。Golang内部有三个对象：

* P对象(processor) 代表上下⽂，包含运行 Go 代码的必要资源，代表了真正的并发度，即有多少个 goroutine 可以同时运行，数量由启动时环境变量决定，一般设置为 CPU 的核数，使 Go 程序能充分利用 CPU。在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。

* M(work thread)代表⼯作线程，一个M阻塞了，P会创建新的M，运行时动态创建，M与P的数量没有绝对关系。

* G对象（goroutine，Goroutine 是Golang实际并发执⾏的实体，它底层是使⽤协程(coroutine)实现并发，coroutine是⼀种运⾏在⽤户态的⽤户线程）。M必须拥有P才可以执行G中的代码，P含有一个包含多个G的队列，P可以调度G交由M执行。

  ```go
  struct G
  {
      uintptr    stackguard;    // 分段栈的可用空间下界
      uintptr    stackbase;    // 分段栈的栈基址
      Gobuf    sched;        //进程切换时，利用sched域来保存上下文
      uintptr    stack0;
      FuncVal*    fnstart;        // goroutine运行的函数
      void*    param;        // 用于传递参数，睡眠时其它goroutine设置param，唤醒时此goroutine可以获取
      int16    status;        // 状态Gidle,Grunnable,Grunning,Gsyscall,Gwaiting,Gdead
      int64    goid;        // goroutine的id号
      G*    schedlink;
      M*    m;        // for debuggers, but offset not hard-coded
      M*    lockedm;    // G被锁定只能在这个m上运行
      uintptr    gopc;    // 创建这个goroutine的go表达式的pc
      ...
  };
  ```

每⼀个线程（M0）维护⼀个上下⽂（P），任何时刻，⼀个上下⽂中只有⼀个Goroutine，其他Goroutine在上下文对应的runqueue中等待。

队列轮转：每个 P有个局部队列，局部队列保存待执⾏的 goroutine(流程2)，当 M绑定的 P的的局部队列已经满了之后就会把 goroutine 放到全局队列(流程2-1)。P 会周期性的将G调度到M中执行，执行一段时间后，保存上下文，将G放到队列尾部，然后从队列中再取出一个G进行调度。当 M绑定的 P的局部队列为空时，M会从全局队列获取到本地队列来执⾏，全局队列中 G 的来源，主要有从系统调用中恢复的 G，防止全局队列中的 G 被“饿死”。

工作窃取：多个 P 中维护的 G 队列有可能是不均衡的。当从全局队列中没有获取到可执⾏的 G时候，M会从其他 P 的局部队列中偷取 G来执⾏(流程3.2)。确保了每个 OS 线程都能充分的使用

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220816104936249.png)

系统调用：一般 M 的个数会略大于 P 的个数，多出来的 M 会在 G 产生系统调用时发挥作用。当G0即将进入系统调用时，M0将释放P，进而某个空闲的M1获取P，继续执行P队列中剩下的G。当G0系统调用结束后，如果有空闲的P，则获取一个P，继续执行G0。如果没有，则将G0放入全局队列，等待被其他的P调度，然后M0将进入缓存池睡眠。

 阻塞：当 G因 channel 或者 network I/O 阻塞时，不会阻塞 M，M会寻找其他 runnable 的 G；当阻塞的 G恢复后会重新进⼊ runnable 进⼊ P队列等待执⾏。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220812225206078.png)

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220812221636833.png)

线程实现，m内核线程：n用户线程

* m=1多对一，用户态切换开销小；一个用户线程阻塞，使得全部用户线程阻塞。
* n=n1对1，用户线程间独立，可实现多核并行；核心态下切换
* n>=m多对多，并发高，防止一个用户进程占据大量内核线程。

##### Mutex

正常模式(⾮公平锁)：正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的 goroutine 不会直接拥有锁，⽽是会和新请求锁的 goroutine 竞争锁的拥有。新请求锁的 goroutine 具有优势：它正在 CPU上执⾏，⽽且可能有好⼏个，所以刚刚唤醒的 goroutine 有很⼤可能在锁竞争中失败。如果⼀个等待的 goroutine 超过1ms没有获取锁，那么它将会把锁转变为饥饿模式。

饥饿模式(公平锁)：为了解决了等待 G队列的⻓尾问题，饥饿模式下，直接由 unlock 把锁交给等待队列中排在第⼀位的 G(队头)，同时，饥饿模式下，新进来的 G不会参与抢锁也不会进⼊⾃旋状态，会直接进⼊等待队列的尾部,这样很好的解决了⽼的 g ⼀直抢不到锁的场景。

对于两种模式，正常模式下的性能是最好的，goroutine 可以连续多次获取锁，免去上下文切换开销，饥饿模式解决了取锁公平的问题，但是性能会下降，其实是性能和公平的⼀个平衡模式。

sync.Mutex互斥锁，使同一时刻只能有一个协程执行某段程序，其他协程等待该协程执行完再依次执行。

```go
var sum = 0
var lock = sync.Mutex{}
var msgChan = make(chan struct{})
func main() {
	//开启100个协程来让 sum + 1
	for i := 1; i <= 1000; i++ {
		go add()
	}
	for i := 1; i <= 1000; i++ {
		<-msgChan
	}
	fmt.Println(sum)
}
func add() {
	lock.Lock()
	defer lock.Unlock()
	sum += 1
	msgChan <- struct{}{}
}
```



##### RWMutex

RWMutex 是单写多读锁，适⽤于读多写少的场景，通过记录 readerCount 读锁的数量来进⾏控制，当有⼀个写锁的时候，会将读锁数量设置为负数1<<30。⽬的是让新进⼊的读锁等待写锁释放之后再获取读锁。同样的写锁也会等待之前的读锁都释放完毕，才会开始进⾏后续的操作。

写锁释放完之后，会将值重新加上1<<30,并通知刚才新进⼊的读锁(rw.readerSem)，所有因操作锁定读锁⽽被阻塞的 goroutine 会被唤醒，并都可以成功锁定读锁。读锁被解锁后，在没有被其他读锁锁定的前提下，所有因操作锁定写锁⽽被阻塞的 goroutine，其中等待时间最⻓的⼀个 goroutine 会被唤醒。

sync.RWMutex，写所互斥，读锁不互斥

```go
var sum = 0
var lock = sync.RWMutex{}
var msgChan = make(chan struct{})
func main() {
	//开启100个协程来让 sum + 1
	for i := 0; i <= 64; i++ {
		go add()
	}
	for i := 0; i <= 64; i++ {
		go get()
	}
	for i := 0; i <= 64; i++ {
		<-msgChan
	}
	fmt.Println(sum)
}
func add() {
	// 获得写锁
	lock.Lock()
	defer lock.Unlock()
	sum += 1
	msgChan <- struct{}{}
}
func get() {
	// 获得读锁
	lock.RLock()
	defer lock.RUnlock()
	fmt.Println(sum)
}
```

##### WaitGroup

https://zhuanlan.zhihu.com/p/344973865

⼀个 WaitGroup 对象可以等待⼀组协程结束。调⽤ wg.Add(delta int)设置 worker 协程的个数，然后创建 worker 协程；worker 协程执⾏结束以后，都要调⽤ wg.Done()；main 协程调⽤ wg.Wait()且被 block，直到所有 worker 协程全部执⾏结束后返回。

WaitGroup 主要维护了2 个计数器，⼀个是请求计数器 v，⼀个是等待计数器 w，⼆者组成⼀个64bit 的值，请求计数器占⾼32bit，等待计数器占低32bit。每次 Add执⾏，请求计数器 v 加1，Done⽅法执⾏，请求计数器减1，v 为0 时通过信号量唤醒 Wait()。

sync.WaitGroup等待多个任务执行完毕

```go
var sum = 0
var lock = sync.Mutex{}
var wg = sync.WaitGroup{}
func main() {
	// 添加64个任务
	wg.Add(64)
	//开启100个协程来让 sum + 1
	for i := 0; i < 64; i++ {
		go add()
	}
	// 等待任务执行完毕
	wg.Wait()
	fmt.Println(sum)
}
func add() {
	// 获得写锁
	lock.Lock()
	defer lock.Unlock()
	sum += 1
	// 剩余任务减一
	wg.Done()
}
```

实现

```go
type WaitGroup struct {
    noCopy noCopy
    state1 [3]uint32
}
```

`state1 [3]uint32` 字段中包含了 WaitGroup 的所有状态数据。当 state1 变量是 64 位对齐时，也就意味着数组前两位作为 64 位整数时，自然也可以保证 64 位对齐了，最后一个元素作为信号量。

`counter` 和 `waiter` 在改变时需要保证并发安全。最简单的做法是，搞一个 `Mutex` 或者 `RWMutex` 锁, 在需要读写 `counter` 和 `waiter` 的时候，加锁就完事，必然会造成额外的性能开销。WaitGroup 直接把 `counter` 和 `waiter` 看成了一个统一的 64 位变量。通过 CAS 操作 state，实现无锁编程。`[state1[0],state1[1]]==>state;state1[2]==>sema`

![700](%E9%9D%A2%E7%BB%8F.assets/image-20221030220237107.png)

- `counter` 代表目前尚未完成的个数。`WaitGroup.Add(n)` 将会导致 `counter += n`, 而 `WaitGroup.Done()` 将导致 `counter--`，都是通过CAS更改state的高32位。当counter=0时唤醒等待携程。
- `waiter` 代表目前已调用 `WaitGroup.Wait` 的 goroutine 的个数。通过CAS更改state的低32位，并休眠当前线程。

##### Context 包

1，`Context `包提供上下文机制在 `goroutine `之间传递 deadline、取消信号（cancellation signals）或者其他请求相关的信息。

```go
type Context interface {
     Deadline() (deadline time.Time, ok bool)
     Done() <-chan struct{}
     Err() error
     Value(key interface{}) interface{}
}
```

* 服务器程序通过 `context.Background()`为每个接受的请求创建一个 `Context `实例，称为`rootContext`。

* 之后的 `goroutine `中将`rootContext `作为参数通过调用 `context.WithCancel `、`context.WithDeadline`、`context.WithTimeout`方法，创建的子 `context`。

  ```go
  // 返回的 cancelFunc，如果被调用，会导致 Done channel 关闭
  func WithCancel(parent Context) (ctx Context, cancel CancelFunc)
  // 到达指定的截至时间或者cannelFunc被调用，将关闭消息通道
  func WithDeadline(parent Context, d time.Time) (Context, CancelFunc)
  // 经过指定的时间间隔或者cannelFunc被调用，将关闭消息通道
  func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)
  // 用于在不同goroutine间传递数据(签名、trace_id)，类似Java中的ThreadLocal。ctx.Value(k)
  func WithValue(parent Context, key, val interface{}) Context
  ```

  ![700](%E9%9D%A2%E7%BB%8F.assets/image-20220817203814319.png)

* `goroutine `通过 `context.Done()` 方法监听取消信号。`func Done() <-chan struct{}` 返回一个只读channel，用于接收取消信号。（可以借助 select 语句，如果收到取消信号，就退出 `goroutine`；否则，默认子句是继续执行 `goroutine`）；

* 关闭消息通道条件：当一个 `Context `被取消（比如执行了 `cancelFunc()`）；`WithDeadline `创建的 context，deadline 到期；`WithTimeout` 创建的 context，timeout 到期。

  ```go
  func Stream(ctx context.Context, out chan<- Value) error {
      for {
          v, err := DoSomething(ctx)
          if err != nil {
              return err
          }
          select {
          case <-ctx.Done():
              return ctx.Err()
          case out <- v:
          }
      }
  }
  ```

##### once

sync.Once在高并发的场景下，来保证代码只执行一次， 适合用于创建单例、只加载一次资源等只需要执行一次的场景。

```go
var once = sync.Once{}
func doInit() {
	fmt.Println("init done)
}
func main() {
	//开启100个协程来让 sum + 1
	for i := 0; i < 64; i++ {
		go func() {
			once.Do(doInit)
		}()
	}
}
```

启动时没有任何go程被执行完毕，标志位为0，多个go程竞争一个同步锁，竞争成功的go程获得同步锁，其它线程阻塞，在他执行完毕后将执行标志位写为1并释放锁，其他go程再次开始竞争锁，拿到锁后检查标志位，发现标志位为1，直接返回并释放锁。

```go
func (o *Once) Do(f func()) {
	if atomic.LoadUint32(&o.done) == 0 {
		o.doSlow(f)
	}
}

// 使用lock和在执行完f后再设置标志位是为了保证f执行成功，如果f执行失败，将不更新标志位，并释放锁，其它等待锁的go程继续尝试执行f。
// 如果使用CAS，如果第一个执行失败，当时由于标志位已被修改，其它go程无法继续尝试完成f。
// if atomic.CompareAndSwapUint32(&o.done, 0, 1) {
//      f()
//  }
func (o *Once) doSlow(f func()) {
	o.m.Lock()
	defer o.m.Unlock()
	if o.done == 0 {
		defer atomic.StoreUint32(&o.done, 1)
		f()
	}
}
```

##### Cond

条件变量 sync.Cond，基于互斥锁的基础上，增加了一个通知队列，协程刚开始是等待的，通知的协程会从通知队列中唤醒一个或多个被通知的协程。

```go
func main() {
	// 3个工人共享一个话筒，同一时刻只能有一个发言
	// 阻塞等待通知的操作以及通知解除阻塞的操作就是基于sync.Mutex来实现
	cond := sync.NewCond(&sync.Mutex{})
	var wg sync.WaitGroup
	// 3工人+1指令员
	wg.Add(4) 
	for i := 1; i <= 3; i++ {
		go func(num int) {
			defer wg.Done()
			// 获得话筒
			cond.L.Lock()
			fmt.Println(num, "就绪)
			// 阻塞当前协程，并释放锁资源，直到被其他协程调用 Broadcast 或者 Signal 方法唤醒，使用的时候需要加锁
			cond.Wait()
			fmt.Println(num, "运行中)
			// 释放话筒
			cond.L.Unlock()
		}(i)
	}
	//等待所有goroutine都进入wait状态
	time.Sleep(2 * time.Second)
	go func() {
		defer wg.Done()
		fmt.Println("开始运行)
		// 广播通知，唤醒所有等待的协程
		cond.Broadcast() 
	}()
	//防止函数提前返回退出
	wg.Wait()
}
```

```go
func (c *Cond) Wait() {
	c.checker.check()
    // 把调用它的 goroutine（也就是当前的 goroutine）加入到当前条件变量的通知队列中。
	t := runtime_notifyListAdd(&c.notify)
    // 解锁当前的条件变量基于的那个互斥锁。
	c.L.Unlock()
    // 让当前的 goroutine 处于等待状态，等到通知到来时再决定是否唤醒它。此时，这个 goroutine 就会阻塞在调用这个Wait方法的那行代码上。
	runtime_notifyListWait(&c.notify, t)
    // 如果通知到来并且决定唤醒这个 goroutine，那么就在唤醒它之后,尝试重新锁定当前条件变量基于的互斥锁，成功后返回。
	c.L.Lock()
}
```

##### select

`select` 语句使一个 Go 程可以等待多个通信操作。每个`case`表达式中都必须包含通道的读或者写；`select`语句会查看哪些case的读写操作能成功执行，然后开始选择能成功执行的候选分支，进行读写操作，执行对应case内容，然后结束当前select ；当多个分支都准备好时会随机选择一个执行case，而随机的引入就是为了避免饥饿问题的发生，然后结束当前select 。如果所有的候选分支都不满足选择条件，那么默认分支就会被执行，如果这时没有默认分支，那么`select`语句就会立即进入阻塞状态，直到至少有一个候选分支满足选择条件为止。

```go
//break 方式
loop:
    for {
        select { 
        case _, ok := <-ch1: //ch1非空或许信道被关闭且没有值时执行此语句
            if !ok {
                ch1 = nil //ch1已经关闭且没有值，将他设置为nil，以屏蔽ch1
            }
            fmt.Println("ch1)
        case _, ok := <-ch2: //ch2非空或许信道被关闭且没有值时执行此语句
            if !ok {
                break loop //跳出for循环
            }
            fmt.Println("ch2)
        default: // 所有分支都阻塞时执行此分支
            time.Sleep(50 * time.Millisecond)
        }
    }
    fmt.Println("END)
```

##### 并发限制

```go
// 通过有限容量的管道，限制并发数
// 为每个进入的请求都创建了新的Go程,只是只有MaxOutstabding个操作同时进行，其它Go程被阻塞。若请求来得很快,该程序就会无限地消耗资源
var sem = make(chan int, MaxOutstanding)
func handle(r *Request) {
    sem <- 1 // 往信道中写数据，标志占用一个资源
    process(r)  // 可能需要很长时间。
    <-sem    // 往信道中取数据，标志释放一个资源
}
func Serve(queue chan *Request) {
    for {
        req := <-queue
        go handle(req)  // 无需等待 handle 结束。
    }
}
```

```go
// 通过有限容量的管道，限制并发数
func Serve(queue chan *Request) {
    for req := range queue {
        sem <- 1
        go func(req *Request) { //默认情况下闭包类变量只在被执行时才求值，可能导致变量值与创建闭包时的变量不一致。将当前req与函数绑定，立即执行求值。
            process(req)
            <-sem
        }(req)
    }
}
```

```go
// 启动固定数量的 handle Go程，一起从请求信道中读取数据。
func handle(queue chan *Request) {
    // 从quene中取出还没被处理的请求，quene长度减一
    for r := range queue { 
        process(r)
    }
}
func Serve(clientRequests chan *Request, quit chan bool) {
    // 启动处理程序
    for i := 0; i < MaxOutstanding; i++ {
        // MaxOutstanding个handle同时从clientRequests获取任务处理请求
        go handle(clientRequests) 
    }
    <-quit  // 等待通知退出。
}
```

##### 函数传参

因为拷贝的内容有时候是非引用类型（int、string、struct等这些），这样就在函数中就无法修改原内容数据；有的是引用类型（指针、map、slice、chan等这些），这样就可以修改原内容数据。

- 传值（值传递）：将实际参数拷贝（浅拷贝）一份传递到函数中，独立变化。Go里面函数传参只有值传递一种方式。
- 传指针：传递指针的拷贝，形参、实参的值虽然相同，但是存放这两个指针的内存地址是不同的，因此这是两个不同的指针。任何存放在内存里的东西都有自己的地址，指针也不例外，它虽然指向别的数据，但是也有存放该指针的内存。
- 传引用（引用传递）：在调用函数时将实际参数的地址传递到函数中，在函数中对参数所进行的修改，将影响实际参数。

### 内存管理

##### 垃圾回收

“⾮分代的、⾮移动的、并发的、三⾊的”标记清除垃圾回收算法。

整个进程空间⾥申请每个对象占据的内存可以视为⼀个图，初始状态下每个内存对象都是⽩⾊标记。

1. 做⼀些准备⼯作：收集根对象（全局变量，和G stack），开启写屏障。全局变量、开启写屏障需要STW（暂停所有正在执行的用户线程/协程）。然后取消STW，将扫描任务作为多个并发的goroutine⽴即⼊队给调度器，进⽽被CPU处理。
2. 第⼀轮先并发扫描root对象（全局指针和 goroutine 栈上的指针），从根出发扫描所有可达对象，标记为灰色，放入待处理队列，并把root标记为黑色。第⼆轮从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。循环往复，最后队列为空时，标记完成后只有黑色和白色对象，黑色代表使用中对象，白色对象代表垃圾，并使用写屏障最终变化的引用关系。
3. 第三轮再次STW，重新扫描全局变量，和上一轮改变的stack（写屏障），完成标记工作。标记结束阶段的最后会关闭写屏障，然后关闭STW，唤醒熟睡已久的负责清扫垃圾的goroutine。
4. 清扫goroutine是应用启动后立即创建的一个后台goroutine，它会立刻进入睡眠，等待被唤醒，然后执行垃圾清理：把白色对象挨个清理掉，清扫goroutine和应用goroutine是并发进行的。清扫完成之后，它再次进入睡眠状态，等待下次被唤醒。

GC有3种触发方式：

1. 辅助GC：在分配内存时，会判断当前的Heap内存分配量是否达到了触发一轮GC的阈值（每轮GC完成后，该阈值会被动态设置），如果超过阈值，则启动一轮GC。

2. 调用runtime.GC()强制启动一轮GC。

3. 当超过 forcegcperiod (2分钟)没有运行GC会启动一轮GC。

Dijistra写屏障：满足强三色不变性：黑色节点不允许引用白色节点 当黑色节点新增了白色节点的引用时，将对应的白色节点改为灰色。

混合写屏障：满足弱三色不变性：黑色节点允许引用白色节点，但是该白色节点有其他灰色节点间接的引用（确保不会被遗漏），当白色节点被删除了一个引用时，悲观地认为它一定会被一个黑色节点新增引用，所以将它置为灰色。减少了第二次STW的时间。

##### 内存分配

Go语⾔的运⾏环境（runtime）会在goroutine需要的时候动态地分配栈空间。

分块式的栈：初始分配⼀个8KB的内存空间来给goroutine的栈使⽤。每个Go函数的开头都有⼀⼩段检测代码。这段代码会检查我们是否已经⽤完了分配的栈空间。如果是的话，它会调⽤morestack函数。morestack函数分配⼀块新的内存作为栈空间，并且在这块栈空间的底部填⼊各种信息（包括之前的那块栈地址）。在分配了这块新的栈空间之后，它会重试刚才造成栈空间不⾜的函数。这个过程叫做栈分裂（stack split）。新分配的栈底部，还插⼊了⼀个叫做lessstack的函数指针。当从刚才造成栈空间不⾜的那个函数返回时做准备的。当我们从那个函数返回时，它会跳转到lessstack。lessstack函数会查看在栈底部存放的数据结构⾥的信息，如果新栈已空，然后调整栈指针（stack pointer）。这样就完成了从新的栈块到⽼的栈块的跳转。接下来，新分配的这个块栈空间就可以被释放掉了。

按照需求来扩展和收缩栈的⼤⼩。 热分裂问题：缩减栈空间是⼀个开销相对较⼤的操作。如果在⼀个循环⾥有栈分裂，那么它的开销就变得不可忽略了。⼀个函数会扩展，然后分裂栈。当它返回的时候⼜会释放之前分配的内存块。

栈复制法：当goroutine运⾏并⽤完栈空间的时候，栈溢出检查会被触发。会分配⼀个两倍⼤的内存块并把⽼的内存块内容复制到新的内存块⾥。这样做意味着当栈缩减回之前⼤⼩时，我们不需要做任何事情。栈的缩减没有任何代价。⽽且，当栈再次扩展时，运⾏环境也不需要再做任何事。它可以重⽤之前分配的空间。

存储在栈上的变量的地址可能已经被使⽤到。也就是说程序使⽤到了⼀些指向栈的指针。当移动栈的时候，所有指向栈⾥内容的指针都会变得⽆效。当我们移动栈的时候，我们可以更新栈⾥的指针让它们指向新的地址，使⽤了垃圾回收的引用关系信息来复制栈。

##### 逃逸

1，堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。

- 如果分配在栈中，则函数执行结束可自动将内存回收；
- 如果分配在堆中，则函数执行结束可交给GC（垃圾回收）处理

逃逸分析的好处应该是尽量将变量分配到栈上，栈的分配比堆快，性能好，可以避免 Go 频繁地进行垃圾回收。

2，编译器在编译阶段完成，根据变量是否被外部引用来决定是否逃逸：

* 指针逃逸：返回局部变量指针被外界引用。
* 栈空间不足逃逸：当栈空间不足以存放当前对象时或无法判断当前切片长度时会将对象分配到堆中。
* 动态类型逃逸：空接口 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。
* 闭包引用对象逃逸：返回函数中引用局部变量，以致产生逃逸：

##### 内存管理

1，结构

- 程序文件段（.text），包括二进制可执行代码；
- 已初始化数据段（.data），包括初始化的静态常量；
- 未初始化数据段（.bss），包括未初始化的静态变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；进程的堆区这是所有线程共享的，需要一套机制来进行分配（考虑内存碎片、公平性、冲突解决）。
- 栈段，包括局部变量和函数调用的上下文等，每个线程的栈空间是独立的，但是都位于进程的栈区域中。线性内存，管理简单，分配比堆上更快。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220817212827790.png)

2，Go通过细致的对象划分、极致的多级缓存+无锁策略缓存、精确的位图管理来进行精细化的内存管理和性能保障。Go中把所有对象分为三个层级：

- 微小对象（0,16byte）：分配流程为，mcahe->mcentral->mheap位图查找->mheap基数树查找->操作系统分配
- 小对象 [16byte, 32KB]：分配流程与微小对象一样
- 大对象(32KB以上)：分为流程为，mheap基数树查找->操作系统分配（不经过mcache和mcentral）

3，mspan 是一分配内存的单位。，mcache、mcentral、mheap 起到了内存池的作用，会被预分配内存，当有对应大小的对象需要分配时会先到它们这一层请求。如果这一层内存池不够用时，会按照下面的顺序一层一层的往上申请内存：mcache -> mcentral-> mheap -> 操作系统。

* page：一个page大小为8kb（为操作系统中页的两倍），下图中一个浅蓝色的长方形代表一个page

* mspan是Go中内存管理的基本单位，span的大小是page的倍数，表示一组连续的页面。一共划分了67级的mspan，每一级mspan设定拥有的page数和要存储对象的大小，通过精细化分配能有效地减少内存碎片；下图中一个淡紫色的长方形为一个span。
* mcache：每个层级的span都会在mcache中保存一份，当前最多有GOMAXPROCS个线程在运行，所以最多需要GOMAXPROCS个mcache就可以保证各线程对mcache的无锁访问；每个逻辑处理器P会有自己的mcache，对这部分区域的访问是无锁的。每个类别的mspan对象对应两个mspan，一个分配给含有指针的的对象，一个分配给不含有指针的对象，共计134个span类别，这样垃圾回收时，针对无指针对象的span区域不需要进行复杂的标记处理，提升效果。
* mcentral是所有线程共享的的缓存，需要加锁访问；它的主要作用是为mcache提供切分好的mspan资源。每个spanClass对应一个级别的mcentral；mcentral整体是在mheap中管理的，它之中包含两个mspan链表，分别为partial代表经过gc后至少有1个空闲的对象空间span，用于为mcache分配可用mspan、full代表无空闲区域的span列表，mcache将已满的mspan交由mcentral，进行垃圾回收。
* mheap代表Go中所持有的堆空间。当mcentral没有空闲span时，会向mheap申请，如果mheap中也没有资源了，会向操作系统来申请内存。向操作系统申请是按照页为单位来的（4kb），然后把申请来的内存页按照page（8kb）、span（page的倍数）、chunk（512kb）、heapArena（64m）这种级别来组织起来。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220818110446803.png)

##### 

### 数据结构

##### Map实现

1，结构体，map是个指针，底层指向hmap，所以是个引用类型

```go
type hmap struct {
   // 键值对的数量
 	count     int 
   // 标记当前是否有协程在写，或遍历
 	flags     uint8
   // 桶数组长度 = 2 ^ B。当n=3时，桶数组长度=8
   B         uint8  
   // 溢出桶的大概数量
 	noverflow uint16 
   // hash种子，新建map时生成。每个map的hash种子都是随机生成，同样的key在两个map中大概率定位到不同的桶，以保证随机性。
 	hash0     uint32 
   // 指向桶数组
 	buckets    unsafe.Pointer 
   // 指向老桶数组，扩容时用。渐进式扩容，需要同时保存老桶和新桶，两个桶同时用于查找，遍历等操作，当扩容完毕删除oldbuckets。老的buckets数组大小是新的buckets的1/2;非扩容状态下，它为nil。
 	oldbuckets unsafe.Pointer 
   // 表示扩容进度，小于此地址的buckets代表已搬迁完成。
 	nevacuate  uintptr        
 	extra *mapextra // optional fields
}
```

```go
type bmap struct {
    // 根据hash值的高8位来决key到底落入桶内的哪个位置，用来快速定位key是否在这个bmap中
    topbits  [bucketCnt]uint8   // bucketCnt = 8，一个桶最多存储8个键值对，
    keys     [bucketCnt]keytype
    values   [bucketCnt]valuetype
    pad      uintptr
    // 指向溢出桶，用到溢出桶需要一个桶8位塞满8个元素，这在其他语言发生概率较低，比如java的hashmap，默认装置因子0.75表示平均一个桶有0.75个元素就要发生扩容，但go map的扩容条件比较苛刻，装载因子为6.5，因此有一定的概率使用溢出桶若超过8个元素都被定位到该桶时，需建新桶，挂到前一个桶的overflow上
    overflow uintptr
}
```

<img src="%E9%9D%A2%E7%BB%8F.assets/image-20220817124751333.png" alt="700" style="zoom: 50%;" />

2，定位

===>计算hash(key)，每种类型的哈希方法由系统初始化，再加上随机种子` hash := alg.hash(key, uintptr(h.hash0))`

===>定位桶：根据hash值（64位机下共 64 个 bit 位）的后B位定位桶，` b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + (hash&mask)*uintptr(t.bucketsize)))`。如果map未在扩容或者当前bucket已经完成扩容，在当前bucket中查找，若当前bucket正在扩容，则到老bucket查找。

===>定位槽：每个key生成了一个tophash，取值为hash值前8位。先和tophash的每个值比较，若不等，则key一定不在该槽，若相等，进一步调用` alg.equal(key, k)`方法验证。

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220817125258218.png)

===>当前桶遍历完没有key时，若bmap.overflow不为空，需要继续寻找溢出桶，定位方式和之前一样。

3，扩容

触发：元素个数大于8且元素个数大于 6.5 * 桶的数量；溢出桶过多（此时哈希表中可能元素不多，但有大量桶，且有大量空槽，这种场景出现的原因一般是先大量添加元素，再大量删除，再插入很多元素，就会留下一些空洞，定位key需要额外扫描空的位置，降低性能，需要进行处理）。

若为元素过多，则将数组容量翻倍。否则是溢出桶过多，采用原桶容量（元素不多，不需要更大的容量，只是需要重新整合，消除溢出桶）

渐进式扩容，在插入、修改或者删除时，使用(oldbuckets != nil )触发搬迁数据，每次搬迁2个桶到新桶上，其中一个是key所在的桶，和一个另外的桶，新桶下标计算与java相同。这样扩容的好处是将扩容的复杂度均摊到每次操作，保证在map操作上耗时稳定，缺点是实现复杂。

在扩容过程中，写入数据时会把该key对应的老bucket迁移，并将数据写入新桶；遍历时key对应的老桶还没被搬迁，则需要到老桶上找元素。

4，遍历

随机性：每次for-range遍历map的顺序不一样。开始遍历的桶startBucket不一样，且遍历每个桶时开始位置offset也不同（不同rang的offset不同，同一个range内全部桶得offset相同）。编程语言没有定义map的迭代顺序，不同平台的遍历顺序可能不一样，这导致基于特定顺序的代码在不同平台之间的运行结果可能不一致，另外map扩容后，一个bucket的数据会分散到两个bucket，也会导致顺序产生变化，因此为了防止程序员依赖特定的迭代顺序，map的迭代就不可预测。如果想顺序遍历 map，需要对 map key 先排序，再按照 key 的顺序遍历 map。

```go
// 实现有序遍历
var sl []int
// 把 key 单独取出放到切片
for k := range m {
    sl = append(sl, k)
}
// 排序切片
sort.Ints(sl)
// 以切片中的 key 顺序遍历 map 就是有序的了
for _, k := range sl {
    t.Log(k, m[k])
}
```

考虑扩容：由于是渐进式扩容，可能遍历的过程中同时扩容也在进行，有些bucket可能已经被搬到新map，有些没有。因此遍历时需要考虑在新老哪个map取数据。

map无法并发读写，需要对写和读操作进行加锁，或者使用使用sync.Map。

```go
// fatal error: concurrent map read and map write
m := make(map[int]int)
go func() {
    for {
        _ = m[1]
    }
}()
go func() {
    for {
        m[2] = 2
    }
}()
```

```go
// 1.19前解决办法：加全局读写锁，或者根据hash值分片加读写锁
var counter = struct{
    sync.RWMutex
    m map[string]int
}{m: make(map[string]int)}
// 读数据加读锁,读锁减少读写的时候因为锁带来的性能
counter.RLock()
n := counter.m["some_key"]
counter.RUnlock()
fmt.Println("some_key:", n)
// 读数据加写锁
counter.Lock()
counter.m["some_key"]++
counter.Unlock()
```

##### sync.Map 

* 空间换时间。通过冗余的两个数据结构(read、dirty)，读写操作分开，读+更新+删除相关的操作尽量通过不加锁的 read 实现，写+新增相关的操作通过 dirty 加锁实现。实现加锁对性能的影响。
* 使用只读数据(read)，避免读写冲突。
* 动态调整，新写入的 key 都只存在 dirty 中，如果 dirty 中的 key 被多次读取，dirty 就会上升成不需要加锁的 read。
* double-checking。
* 延迟删除。删除一个键值只是打标记，dirty 上升成 read 的时候，标记删除的 key 被批量移出 map。这样的好处是 dirty 变成 read 之前，这些 key 都会命中 read，而 read 不需要加锁。

```go
type Map struct {
	// 当涉及到dirty数据的操作的时候，需要使用这个锁
	mu Mutex
	// 一个只读的数据结构，因为只读，所以不会有读写冲突。它包含的元素其实也是通过原子操作更新的。
	read atomic.Value 
	// 包括所有在read字段中但未被expunged（删除）的元素以及新加的元素。虽有冗余，但是提升dirty字段为read的时候非常快，不用一个一个的复制，而是直接将这个数据结构作为read字段的一部分。
	// 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争。
	dirty map[interface{}]*entry
	// 当从Map中读取entry的时候，如果read中不包含这个entry,会尝试从dirty中读取，这个时候会将misses加一，
	// 当misses累积到 dirty的长度的时候， 就会将dirty提升为read,避免从dirty中miss太多次。因为操作dirty需要加锁。
	misses int
}
```

虽然read和dirty有冗余数据，但这些数据是通过指针指向同一个数据，所以尽管Map的value会很大，但是冗余的空间占用还是有限的。read的数据结构是：

```go
type readOnly struct {
	m       map[interface{}]*entry
	amended bool // 如果Map.dirty有些数据不在中的时候，这个值为true。如果从Map.read找不到数据的话，还要进一步到Map.dirty中查找。
}
```

readOnly.m和Map.dirty存储的值类型是*entry,它包含一个指针p, 指向用户存储的value值。

```go
type entry struct {
	p unsafe.Pointer // *interface{}
}
```

1，加载方法，也就是提供一个键key,查找对应的值value,如果不存在，通过ok反映：

```go
func (m *Map) Load(key interface{}) (value interface{}, ok bool) {
	// 1.首先从m.read中得到只读readOnly,从它的map中查找，不需要加锁
	read, _ := m.read.Load().(readOnly)
	e, ok := read.m[key]
	// 2. 如果没找到，并且m.dirty中有新数据，需要从m.dirty查找，这个时候需要加锁
    // 这两行语句并不是一个原子操作，需要双检查
	if !ok && read.amended {
		m.mu.Lock()
		// 双检查，避免加锁的时候m.dirty提升为m.read,这个时候m.read可能被替换了。
		read, _ = m.read.Load().(readOnly)
		e, ok = read.m[key]
		// 如果m.read中还是不存在，并且m.dirty中有新数据
		if !ok && read.amended {
			// 从m.dirty查找
			e, ok = m.dirty[key]
			// 不管m.dirty中存不存在，都将misses计数加一
			// missLocked()中满足条件后就会提升m.dirty
			m.missLocked()
		}
		m.mu.Unlock()
	}
	if !ok {
		return nil, false
	}
	return e.load()
}
```

如果我们查询的键值正好存在于m.read中，无须加锁，直接返回，理论上性能优异。即使不存在于m.read中，经过miss几次之后，m.dirty会被提升为m.read，又会从m.read中查找。所以对于更新／增加较少，加载存在的key很多的case,性能基本和无锁的map类似。

2，missLocked方法中可能会将m.dirty提升。

```go
func (m *Map) missLocked() {
	m.misses++
	if m.misses < len(m.dirty) {
		return
	}
    // 将m.dirty作为readOnly的m字段，原子更新m.read
	m.read.Store(readOnly{m: m.dirty})
    // m.dirty、m.misses重置
	m.dirty = nil
	m.misses = 0
}
```

##### 切片实现

1，使用指针指向底层数组，作为参数传递时指针作为值被复制，由同一个数组生成的两个切片是两个不同的变量，只有通过array指针指向同一个底层数组。当切片作为参数时，其实也是切片的拷贝，在拷贝的切片中其包含的指针成员变量的值是一样的，也就是说它们指向的数据源是一样

```go
type slice struct {
	array unsafe.Pointer
	len   int
	cap   int
}
```

2，初始化

```go
// 内存空间大小 = 切片中元素大小 * 容量大小
// 计算根据cap需要分配的内存空间和内存是否有溢出
mem, overflow := math.MulUintptr(et.size, uintptr(cap))
// 如果cap溢出，计算根据len需要分配的内存空间和内存是否有溢出
em, overflow := math.MulUintptr(et.size, uintptr(len))
// 分配内存
mallocgc(mem, et, true)
```

3，扩容，扩容切片指向新开辟的数组，而对于上层切片来说是没有变化的。

```go
newcap := old.cap
doublecap := newcap + newcap
//这个cap为old.cap+新加元素数量，即至少扩容值
// 如果两倍扩容达不到这个cap，新数组的容量就为这个cap
if cap > doublecap {
    newcap = cap
} else {
    // 如果两倍扩容达到了这个最小值,且老数组长度小于1024，就正常扩容两倍。
    if old.len < 1024 {
        newcap = doublecap
    } else {
        // 如果两倍扩容达到了这个最小值,且老数组长度大于等于1024，就循环扩容1.25倍，直到达到或者超过cap
        for newcap < cap {
            newcap += newcap / 4
        }
    }
}
```

slice是并发不安全的。slice在并发执行中不会报错，但是数据会丢失，可以在写入数据时加锁，保证同一时间只能有一个在执行写操作。或者将要写入的数据写入channel，由另一个独立的协程负责向切片写入数据。

```go
lock.Lock()
defer lock.Unlock()
slc = append(slc, a)
```

```go
type ServiceData struct {
	ch   chan int // 用来 同步的channel
	data []int    // 存储数据的slice
}
func (s *ServiceData) Schedule() {
	// 从 channel 接收数据
	for i := range s.ch {
		s.data = append(s.data, i)
	}
}
func (s *ServiceData) AddData(v int) {
	s.ch <- v // 发送数据到 channel
}
```

##### channel

用于在协程间传递消息，收发遵循先进先出 FIFO，golang实现基于通信的资源内存，可实现生产者、消费者模型，以及多协程间的并发控制（缓存区大小即为资源数，占用资源时就可以向channel写入，结束资源占用就从channel读出，缓冲区满其它写入协程将阻塞）。

1. 给⼀个 nil channel 发送、接收数据，造成永远阻塞
2. 给⼀个已经关闭的 channel 发送数据，引起 panic 
3. 从⼀个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回⼀个零值，非空返回缓冲区值
4. ⽆缓冲的 channel 是同步的，⽽有缓冲的 channel 是⾮同步的
5. 关闭⼀个 nil channel 将会发⽣ panic

channel 中使⽤了 ring buffer(环形缓冲区)来缓存写⼊的数据。

```golang
type hchan struct {
     qcount   uint  // 队列中的总元素个数
     dataqsiz uint  // 环形队列大小，即可存放元素的个数
     buf      unsafe.Pointer // 环形队列指针，固定长度的双向循环列表
     elemsize uint16  //每个元素的大小
     closed   uint32  //标识关闭状态
     elemtype *_type // 元素类型
     sendx    uint   // 下一个可接收发送数据的索引，buf[sendx]=newData
     recvx    uint   // 下一个可读取数据的索引,data=buf[recvx]
     recvq    waitq  // 等待读消息的goroutine队列，如果缓冲空，将当前 goroutine 加入 recvq ，进入睡眠，等待被写 goroutine 唤醒。
     sendq    waitq  // 等待写消息的goroutine队列。若缓冲区中没有空余位置，则将发送数据写入 G，将当前 G 加入 sendq ，进入睡眠，等待被读 goroutine 唤醒。若等待接收队列 recvq 不为空，则缓冲区中无数据或无缓冲区，将直接从 recvq 取出 G ，并把数据写入，最后把该 G 唤醒，结束发送过程。
     lock mutex  //互斥锁，chan不允许并发读写
}
// 等待读写的队列数据结构，保证先进先出
type waitq struct {
  first *sudog
  last  *sudog
}
```

![700](%E9%9D%A2%E7%BB%8F.assets/image-20220817164544863.png)

* 初始化：

  ===> 缓冲区大小：`buff_size = elem.size* size`

  ===>`buff_size`为0或者每个元素占用的大小为0（无缓冲区或者重送空结构体，不占据内存）,只需要分配hchan结构体本身占用的大小。`c = (*hchan)(mallocgc(hchanSize, nil, true))`

  ===>传送内容为指针对象，为buf单独开辟mem大小的空间，用来保存所有的数据。`c = new(hchan)`，`c.buf = mallocgc(buff_size , elem, true)`

  ===>传送内容不是指针对象，占据空间为`hchanSize+buff_size`，其中`hchanSize`为hchan自身占据的空间。`c = (*hchan)(mallocgc(hchanSize+mem, nil, true))`

* 向 channel 写数据:

1. 若等待接收队列 recvq 不为空，则缓冲区中无数据或无缓冲区，将直接从 recvq 取出 G ，并把数据写入，最后把该 G 唤醒，结束发送过程。
2. 若等待接收队列 recvq 空，缓冲区中有空余位置，则将数据写入缓冲区，结束发送过程。
3. 若等待接收队列 recvq 空，缓冲区中没有空余位置，则将要发送的数据和当前的Groutine打包成Sudog对象放入sendq，并将groutine置为等待状态，等待被读 goroutine 唤醒。

* 从 channel 读数据

1. 若等待发送队列 sendq 不为空，且没有缓冲区，直接从 sendq 中取出 G ，把 G 中数据读出，最后把 G 唤醒，结束读取过程。
2. 如果等待发送队列 sendq 不为空，且缓冲区已满，从缓冲区中首部读出数据，把 G 中数据写入缓冲区尾部，把 G 唤醒，结束读取过程。
3. 若等待发送队列 sendq 空，且缓冲区中有数据，则从缓冲区取出数据，结束读取过程。
4. 若等待发送队列 sendq 空，且缓冲区空，则阻塞该Groutine，并将groutine打包为sudogo加入到recevq等待队列中，等待被写 goroutine 唤醒。

* 关闭：唤醒所有等待读取chanel的协程；所有等待写入channel的协程，抛出异常
* 并发安全：指针一段写入一段读取，防止随意未知写入数据造成竞争；每次读取或者写入数据都要加锁，同一时刻最多只有一个读或者写；



面向过程是一种以事件为中心的编程思想，编程的时候把解决问题的步骤分析出来，然后用函数把这些步骤实现，在一步一步的具体步骤中再按顺序调用函数。优：流程化使得编程任务明确，在开发之前基本考虑了实现方式和最终结果，具体步骤清楚，便于节点分析。缺：代码重用性低，扩展能力差，后期维护难度比较大。

面向对象对流程进行抽象，把要解决的问题分解成各个对象，建立对象的目的不是为了完成一个步骤，而是为了描叙某个对象在整个解决问题的步骤中的属性和行为。优：易扩展，代码重用率高，耦合度低，缺：代码复杂，抽象不合理。

### 智力题

https://www.nowcoder.com/discuss/353157075649896448

https://www.bmabk.com/index.php/post/122985.html

https://www.mianshi.online/1126.html
